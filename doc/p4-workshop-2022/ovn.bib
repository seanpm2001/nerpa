@string{HotSDN = "Workshop on Hot Topics in Software Defined Networks (HotSDN)"},
@string{CoNEXT = "Conference on emerging Networking EXperiments and Technologies (Co-NEXT)"},
@string{SIGCOMM = "SIGCOMM"},
@string{CCR =    "SIGCOMM Computer Communication Review (CCR)"},
@string{SOSR =   "ACM Symposium on SDN Research (SOSR)"},
@string{ApNet =  "Asia-Pacific Workshop on Networking (ApNet)"},
@string{HOTNETS= "ACM Workshop on Hot Topics in Networks (HotNets)"},
@string{DISC=    "International Symposium on Distributed Computing (DISC)"},
@string{NSDI=    "USENIX Symposium on Networked Systems Design and Implementation (NSDI)"},
@string{CCS =    "ACM Conference on Computer and Communication Security (CCS)"},
@string{SAT =    "International Conference on Theory and Applications of Satisfiability Testing (SAT)"},
@string{WWW =    "International conference on World Wide Web (WWW)"},
@string{SIGMETRICS = "International Conference on Measurement & Modeling of Computer Systems (SIGMETRICS)"},
@string{ISPASS= "IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)"},
@string{LICS=   "IEEE Symposium on Logic In Computer Science (LICS)"},
@string{FAST=   "USENIX Conference on File and Storage Technologies (FAST)"},
@string{WDDD=   "Workshop on Duplicating, Deconstruction and Debunking (WDDD)"},
@string{PODS=   "Symposium on Principles of Database Systems (PODS)"},
@string{WASP=   "Workshop on Application-Specific Processors (WASP)"},
@string{OOPSLA=	"Object Oriented Programming: Systems, Languages, and Applications (OOPSLA)"},
@string{POPL=	"ACM Symposium on Principles of Programming Languages (POPL)"},
@string{PLDI=	"ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)"},
@string{ISCA=	"International Symposium on Computer Architecture (ISCA)"},
@string{DAC=	"Design Automation Conference (DAC)"},
@string{DATE=   "Design, Automation and Test in Europe (DATE)"},
@string{RAW=    "Reconfigurable Architectures Workshop (RAW)"},
@string{ASPLOS= "International Conference on Architectural Support for Programming Languages and
                  Operating Systems (ASPLOS)"},
@string{FCCM=   "IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM)"},
@string{FPGA=   "ACM/SIGDA International Symposium on Field Programmable Gate Arrays (FPGA)"},
@string{CAV=    "Computer-Aided Verification (CAV)"},
@string{CODES=  "International Symposium on Hardware/Software Codesign (CODES)"},
@string{FPL=    "International Conference on Field Programmable Logic and Applications (FPL)"},
@string{EUROPAR="European Conference on Parallel Processing (EUROPAR)"},
@string{CGO=    "International ACM/IEEE Symposium on Code Generation and Optimization (CGO)"},
@string{PPOPP=  "ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP)"},
@string{CC=     "International Conference on Compiler Construction (CC)"},
@string{PACT=   "International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
@string{LCPC=   "Workshop on Languages and Compilers for Parallel Computing (LCPC)"},
@string{ICCAD=  "IEEE/ACM International Conference on Computer-aided design (ICCAD)"},
@string{MICRO=  "IEEE/ACM International Symposium on Microarchitecture (MICRO)"},
@string{SAS=    "International Static Analysis Symposium (SAS)"},
@string{TACAS=  "International Conference on Tools and Algorithms for the
                 Construction and Analysis of Systems (TACAS)"},
@string{CASES=  "International Conference on Compilers, Architecture,
                 and Synthesis for Embedded Systems (CASES)"},
@string{HPCA=   "International Symposium on High-Performance Computer Architecture (HPCA)"},
@string{ASYNC=  "International Symposium on Advanced Research in Asynchronous Circuits and Systems (ASYNC)"},
@string{ICS=    "{ACM} International Conference on Supercomputing (ICS)"},
@string{ICCD=   "International Conference on Computer Design (ICCD)"},
@string{SIGGRAPH="Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH)"},
@string{SOSP=   "ACM Symposium on Operating Systems Principles (SOSP)"},
@string{FPT=    "IEEE International Conference on Field-Programmable Technology (FPT)"},
@string{SPAA=   "ACM Symposium on Parallel Algorithms and Architectures (SPAA)"},
@string{OSDI=   "Symposium on Operating System Design and Implementation (OSDI)"},
@string{ISLPED= "International Symposium on Low-Power Design (ISLPED)"},
@string{IWLS=   "International Workshop on Logic synthesis (IWLS)"},
@string{VLSI=   "International Conference on VLSI Design (VLSI)"},
@string{ISCAS=  "IEEE International Symposium on Circuits and Systems (ISCAS)"},
@string{USENIX= "USENIX Annual Technical Conference (USENIX)"},
@string{ISSCC=  "IEEE International Solid-State Circuits Conference (ISSCC)"},
@string{LCTES=  "ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems(LCTES)"},
@string{ICFP=   "International Conference on Functional Programming (ICFP)"},
@string{NDSS=   "Network and Distributed System Security Symposium (NDSS)"},
@string{USS=    "USENIX Security Symposium (USS)"},
@string{ISSP=   "IEEE Symposium on Security and Privacy (ISSP)"},
@string{SIGMOD= "ACM SIGMOD International conference on Management of data (SIGMOD)"},
@string{VLDB=   "International Conference of Very Large Data Bases (VLDB)"},
@string{CIDR =  "Conference on Innovative Data Systems Research (CIDR)"},

%Journals
@string{JPDC=	"Journal of Parallel and Distributed Computing (JPDC)"},
@string{CACM=	"Communications of the ACM (CACM)"},
@string{JACM=	"Journal of the ACM (JACM)"},
@string{TCS=    "Transactions on Computer Systems (TOCS)"},
@string{TOCS=   "Transactions on Computer Systems (TOCS)"},
@string{TOC=    "IEEE Transactions on Computers (TOC)"},
@string{TOPLAS= "ACM Transactions on Programming Languages and Systems (TOPLAS)"},
@string{JSSC=   "IEEE Journal of Solid-State Circuits (JSSC)"},
%Others
@string{LNCS=	"Lecture Notes in Computer Science (LNCS)"},
@string{springer="Springer Verlag"}


@Misc{antrea,
  title =        {Antrea},
  howpublished = {https://github.com/vmware-tanzu/antrea},
  note =         {Retrieved April 2021},
  abstract =     {Antrea is a Kubernetes networking solution intended
                  to be Kubernetes native. It operates at Layer 3/4 to
                  provide networking and security services for a
                  Kubernetes cluster, leveraging Open vSwitch as the
                  networking data plane.}
}

@PhdThesis{acar-phd05,
  author =       {Umur Acar},
  title =        {Self-Adjusting Computation},
  school =       {Carnegie Mellon University},
  year =         2005}

@inproceedings{ceri-vldb91,
  author =       {Ceri, Stefano and Widom, Jennifer},
  title =        {Deriving Production Rules for Incremental View
                  Maintenance},
  year =         1991,
  address =      {San Francisco, CA, USA},
  booktitle =    VLDB,
  pages =        {577–589},
  numpages =     13,
  abstract =     {It is widely recognized that production rules in
                  database systems can be used to automatically
                  maintain derived data such as views. However,
                  writing a correct set of rules for efficiently
                  maintaining a given view can be a difficult and
                  ad-hoc process. We provide a facility whereby a user
                  delines a view as an SQL select expression, from
                  which the system automatically derives set-oriented
                  production rules that maintain a materialization of
                  that view.  The maintenance rules are triggered by
                  operations on the view’s base tables. Generally, the
                  rules perform incremental maintenance: the
                  materialized view is modified according to the sets
                  of changes made to the base tables, which are
                  accessible through logical tables provided by the
                  rule language.  However, for some operations
                  substantial recomputation may be required. We give
                  algorithms that, based on key information, perform
                  syntactic analysis on a view definit,ion to
                  determine when efficient maintenance is possible.}
}

@inproceedings{ongaro-atc14,
  author =       {Diego Ongaro and John Ousterhout},
  title =        {In Search of an Understandable Consensus Algorithm},
  booktitle =    USENIX,
  year =         2014,
  address =      {Philadelphia, PA},
  pages =        {305--319},
  url =          {https://www.usenix.org/conference/atc14/technical-sessions/presentation/ongaro},
  publisher =    {{USENIX} Association},
  month =        jun,
  abstract =     {Raft is a consensus algorithm for managing a
                  replicated log. It produces a result equivalent to
                  (multi-)Paxos, and it is as efficient as Paxos, but
                  its structure is different from Paxos; this makes
                  Raft more understandable than Paxos and also
                  provides a better foundation for building practical
                  systems. In order to enhance understandability, Raft
                  separates the key elements of consensus, such as
                  leader election, log replication, and safety, and it
                  enforces a stronger degree of coherency to reduce
                  the number of states that must be
                  considered. Results from a user study demonstrate
                  that Raft is easier for students to learn than
                  Paxos. Raft also includes a new mechanism for
                  changing the cluster membership, which uses
                  overlapping majorities to guarantee safety.},
}

@InProceedings{ryzhyk-datalog19,
   author =	{Leonid Ryzhyk and Mihai Budiu},
   title =	{Differential {Datalog}},
   booktitle =	{Datalog 2.0},
   address =	{Philadelphia, PA},
   month =	{June 4-5},
   year =	{2019},
   abstract =	{Many real-world applications based on deductive databases require
                 incrementally updating output relations (tables) in response to changes
                 to input relations. To make such applications easier to implement we
                 have created Differential Datalog (DDlog), a dialect of Datalog that
                 automates incremental computation. A DDlog programmer writes
                 traditional, non-incremental Datalog programs. The execution model of
                 DDlog is however fully incremental: at runtime DDlog programs receive
                 streams of changes to the input relations (insertions or deletions) and
                 produce streams of corresponding changes to derived relations. The
                 DDlog compiler translates DDlog programs to Differential Dataflow (DD)
                 programs; DD provides an incremental execution engine supporting all
                 the relational operators, including fixed-point. The DDlog runtime
                 automatically maintains the indexes required to efficiently compute
                 output updates. \par The DDlog language is targeted for system
                 builders. In consequence, the language emphasizes usability, by
                 providing a rich type system, a powerful expression language, a module
                 system, including string manipulation, arithmetic, and integration with
                 C, Rust, and Java. The code is open-source, available using an MIT
                 permissive license.},
   url =	{http://budiu.info/work/ddlog.pdf},
   confweb =	{https://sites.sju.edu/plw/datalog2/}
}

@Misc{ddlog,
  title =        {Differential Datalog},
  howpublished = {https://github.com/vmware/differential-datalog},
  note =         {Retrieved April 2021},
  abstract =     {DDlog is a programming language for incremental
                  computation. It is well suited for writing programs
                  that continuously update their output in response to
                  input changes. With DDlog, the programmer does not
                  need to worry about writing incremental
                  algorithms. Instead they specify the desired
                  input-output mapping in a declarative manner, using
                  a dialect of Datalog. The DDlog compiler then
                  synthesizes an efficient incremental
                  implementation.}
}

@book{kifer-book18,
  editor =       {Kifer, Michael and Liu, Yanhong Annie},
  title =        {Declarative Logic Programming: Theory, Systems, and
                  Applications},
  year =         2018,
  isbn =         9781970001990,
  publisher =    {Association for Computing Machinery and Morgan and
                  Claypool},
  volume =       20,
  abstract =     {Logic Programming (LP) is at the nexus of knowledge
                  representation, AI, mathematical logic, databases,
                  and programming languages. It allows programming to
                  be more declarative, by specifying “what” to do
                  instead of “how” to do it. This field is fascinating
                  and intellectually stimulating due to the
                  fundamental interplay among theory, systems, and
                  applications brought about by logic. Several books
                  cover the basics of LP but they focus mostly on the
                  Prolog language. There is generally a lack of
                  accessible collections of articles covering the key
                  aspects of LP, such as the well-founded vs. stable
                  semantics for negation, constraints, object-oriented
                  LP, updates, probabilistic LP, and implementation
                  methods, including top-down vs. bottom-up evaluation
                  and tabling.For systems, the situation is even less
                  satisfactory, lacking expositions of LP inference
                  machinery that supports tabling and other
                  state-of-the-art implementation techniques. There is
                  also a dearth of articles about systems that support
                  truly declarative languages, especially those that
                  tie into first-order logic, mathematical
                  programming, and constraint programming. Also rare
                  are surveys of challenging application areas of LP,
                  such as bioinformatics, natural language processing,
                  verification, and planning, as well as analysis of
                  LP applications based on language abstractions and
                  implementations methods.The goal of this book is to
                  help fill in the void in the literature with
                  state-of-the-art surveys on key aspects of LP. Much
                  attention was paid to making these surveys
                  accessible to researchers, practitioners, and
                  graduate students alike. }
}

@article{green-tcs11,
  title =	 {Reconcilable differences},
  author =	 {Green, Todd J and Ives, Zachary G and Tannen, Val},
  journal =	 {Theory of Computing Systems},
  volume =	 49,
  number =	 2,
  pages =	 {460--488},
  year =	 2011,
  publisher =	 {Springer},
  url =          {https://web.cs.ucdavis.edu/~green/papers/tocs11_differences.pdf},
  abstract =	 {In this paper we study a problem motivated by the
                  management of changes in databases. It turns out
                  that several such change scenarios, e.g., the
                  separately studied problems of view maintenance
                  (propagation of data changes) and view adaptation
                  (propagation of view definition changes) can be
                  unified as instances of query reformulation using
                  views provided that support for the relational
                  difference operator exists in the context of query
                  reformulation. Exact query reformulation using views
                  in positive relational languages is well understood,
                  and has a variety of applications in query
                  optimization and data sharing. Unfortunately, most
                  questions about queries become undecidable in the
                  presence of difference (or negation), whether we use
                  the foundational set semantics or the more practical
                  bag semantics.  We present a new way of managing
                  this difficulty by defining a novel semantics,
                  Z-relations, where tuples are annotated with
                  positive or negative integers. Z-relations
                  conveniently represent data, insertions, and
                  deletions in a uniform way, and can apply deletions
                  with the union operator (deletions are tuples with
                  negative counts). We show that under Z-semantics
                  relational algebra (RA) queries have a normal form
                  consisting of a single difference of positive
                  queries, and this leads to the decidability of their
                  equivalence. We provide a sound and complete
                  algorithm for reformulating RA queries, including
                  queries with difference, over
                  Z-relations. Additionally, we show how to support
                  standard view maintenance and view adaptation over
                  set or bag semantics, through an excursion into the
                  Z-semantics setting. Our algorithm turns out to be
                  sound and complete also for bag semantics, albeit
                  necessarily only for a subclass of RA. This subclass
                  turns out to be quite large and covers generously
                  the applications of interest to us. We also show a
                  subclass of RA where reformulation and evaluation
                  under Z-semantics can be combined with duplicate
                  elimination to obtain the answer under set
                  semantics. We investigate related complexity
                  questions, and we also extend our results to queries
                  with built-in predicates.},
  comments =	 {Develops an algebra of multisets using Z and proves
                  some interesting completeness theorems.  Lemma 6.3 is
	          crucial for DDlog.  Proposition 6.13 is about distinct.}
}

@Misc{broadcom-sdklt,
  author =       {{Broadcom Corporation}},
  title =        {{Broadcom} {SDKLT}},
  howpublished = {\url{https://github.com/Broadcom-Network-Switching-Software/SDKLT}},
  year =         {October 2017},
  note =         {Retrieved January 2021},
  comments =     {An API to almost anything that is on a switch that looks like a DB.}
}

@InProceedings{rogers-an02,
  author =       "Rogers, Craig Milo",
  title =        "{ANQL} --- An Active Networks Query Language",
  booktitle =    "Active Networks",
  year =         2002,
  publisher =    "Springer Berlin Heidelberg",
  address =      "Berlin, Heidelberg",
  pages =        "99--110",
  abstract =     "This paper discusses parallels between network
                  communication packets, when processed in bulk, and
                  relational database records. It introduces a newap
                  plication-specific language, ANQL (Active Networks
                  Query Language), that exploits a database metaphor
                  for packet processing. ANQL has been demonstrated in
                  Active Network control and management plane
                  activities, although it may also be used in many
                  other networking applications. In active networks,
                  ANQL is primarilly intended as a tool or adjunct for
                  use by Active Applications, and by control and
                  management code. Environments are discussed in which
                  ANQL or related languages might be utilized as
                  full-fledged active packet languages in
                  themselves. ANQL is applicable to both event-driven
                  and background processing activities, and may be
                  used in a single, centralized data collection and
                  analysis process, or, with little change, in
                  distributed implementations of packet analysis
                  activities.",
  url =          {https://www.google.com/books/edition/Active_Networks/fG2qCAAAQBAJ?hl=en&gbpv=1&pg=PA99&printsec=frontcover},
  comments =     {ANQL is based on SQL.  Author seems a bit confused
                  in introduction saying something about a packet
                  being a join of several tables.  He proposes using
                  views to filter packets; such filters can be
                  installed in the network.  Can interface directly
                  with Unix utilities running ont he system.
                  Window-based aggregates using GROUP-BY on "sysdate".
                  For active networks ANQL programs can be shipped
                  over the network.  Used for querying statistics or
                  filtering.  Proposed to also use it for forwarding
                  (select the shortest part from topology).}
}

@inproceedings {suresh-osdi20,
  author =       {Lalith Suresh and Jo{\~a}o Loff and Faria Kalim and
                  Sangeetha Abdu Jyothi and Nina Narodytska and Leonid
                  Ryzhyk and Sahan Gamage and Brian Oki and Pranshu
                  Jain and Michael Gasch},
  title =        {Building Scalable and Flexible Cluster Managers
                  Using Declarative Programming},
  booktitle =    OSDI,
  year =         2020,
  isbn =         {978-1-939133-19-9},
  pages =        {827--844},
  url =          {https://www.usenix.org/system/files/osdi20-suresh.pdf},
  month =        nov,
  abstract =     {Cluster managers like Kubernetes and OpenStack are
                  notoriously hard to develop, given that they
                  routinely grapple with hard combinatorial
                  optimization problems like load balancing,
                  placement, scheduling, and configuration. Today,
                  cluster manager developers tackle these problems by
                  developing system-specific best effort heuristics,
                  which achieve scalability by significantly
                  sacrificing the cluster manager's decision quality,
                  feature set, and extensibility over time. This is
                  proving untenable, as solutions for cluster
                  management problems are routinely developed from
                  scratch in the industry to solve largely similar
                  problems across different settings.  We propose DCM,
                  a radically different architecture where developers
                  specify the cluster manager's behavior
                  declaratively, using SQL queries over cluster state
                  stored in a relational database. From the SQL
                  specification, the DCM compiler synthesizes a
                  program that, at runtime, can be invoked to compute
                  policy-compliant cluster management decisions given
                  the latest cluster state. Under the covers, the
                  generated program efficiently encodes the cluster
                  state as an optimization problem that can be solved
                  using off-the-shelf solvers, freeing developers from
                  having to design ad-hoc heuristics.  We show that
                  DCM significantly lowers the barrier to building
                  scalable and extensible cluster managers. We
                  validate our claim by powering three
                  production-grade systems with it: a Kubernetes
                  scheduler, a virtual machine management solution,
                  and a distributed transactional datastore.},
  comments =     {Declarative control planes using SQL for clusters.
                  The intersting twist is that this generates
                  optimization problems that are passed to
                  general-purpose solvers.}
}

@article{bosshart-ccr14,
  author =       {Bosshart, Pat and Daly, Dan and Gibb, Glen and
                  Izzard, Martin and McKeown, Nick and Rexford,
                  Jennifer and Schlesinger, Cole and Talayco, Dan and
                  Vahdat, Amin and Varghese, George and Walker, David},
  title =        {{P4}: Programming Protocol-independent Packet
                  Processors},
  journal =      CCR,
  volume =       44,
  number =       3,
  month =        jul,
  year =         2014,
  pages =        {87--95},
  url =          {http://doi.acm.org/10.1145/2656877.2656890},
}

@inproceedings{pfaff-nsdi15,
  title =        "The design and implementation of {Open vSwitch}",
  author =       "Ben Pfaff and Justin Pettit and Teemu Koponen and
                  Ethan J. Jackson and Andy Zhou and Jarno Rajahalme
                  and Jesse Gross and Alex Wang and Jonathan Stringer
                  and Pravin Shelar and Keith Amidon and Mart\'{i}n
                  Casado",
  booktitle =    NSDI,
  pages =        "117--130",
  year =         2015,
  month =        {May},
  address =      {Oakland, CA},
  abstract =     {We describe the design and implementation of Open
                  vSwitch, a multi-layer, open source virtual switch
                  for all major hypervisor platforms. Open vSwitch was
                  designed de novo for networking in virtual
                  environments, resulting in major design departures
                  from traditional software switching
                  architectures. We detail the advanced flow
                  classification and caching techniques that Open
                  vSwitch uses to optimize its operations and conserve
                  hypervisor resources. We evaluate Open vSwitch
                  performance, drawing from our deployment experiences
                  over the past seven years of using and improving
                  Open vSwitch.},
  doi = {https://dl.acm.org/doi/10.5555/2789770.2789779},
}

@Misc{nicira-ext,
  author =       {Nicira Inc.},
  title =        {{OpenFlow} {Nicira} Extensions},
  howpublished = {\url{https://github.com/osrg/openvswitch/blob/master/include/openflow/nicira-ext.h}},
  month =        {December},
  year =         2012
}

@Misc{openstack-ovn,
  key =          {OpenStack},
  title =        {{OpenStack} {Neutron} integration with {OVN}},
  howpublished = {\url{https://docs.openstack.org/networking-ovn/latest/}},
  note =         {Retrieved March 2021}
}

@Misc{kubernetes-ovn,
  key =          {Kubernetes},
  title =        {How to Use Open Virtual Networking With
                  {Kubernetes}},
  howpublished = {\url{https://github.com/openvswitch/ovn-kubernetes}},
  note =         {Retrieved January 2021}
}

@article{murray-cacm16,
  author =       {Murray, Derek G. and McSherry, Frank and Isard,
                  Michael and Isaacs, Rebecca and Barham, Paul and
                  Abadi, Martin},
  title =        {Incremental, Iterative Data Processing with Timely
                  Dataflow},
  journal =      {Commun. ACM},
  volume =       59,
  number =       10,
  month =        sep,
  year =         2016,
  pages =        {75--83},
  url =          {http://doi.acm.org/10.1145/2983551},
  abstract =     {We describe the timely dataflow model for
                  distributed computation and its implementation in
                  the Naiad system. The model supports stateful
                  iterative and incremental computations. It enables
                  both low-latency stream processing and
                  high-throughput batch processing, using a new
                  approach to coordination that combines asynchronous
                  and fine-grained synchronous execution. We describe
                  two of the programming frameworks built on Naiad:
                  GraphLINQ for parallel graph processing, and
                  differential dataflow for nested iterative and
                  incremental computations. We show that a
                  general-purpose system can achieve performance that
                  matches, and sometimes exceeds, that of specialized
                  systems.}
}

@Misc{NSX,
  author =       {VMware Inc.},
  title =        {{VMware} {NSX} Network Virtualization and Security
                  Platform},
  howpublished = {\url{https://www.vmware.com/products/nsx.html}},
  note =         {Retrieved 2021}
}

@Misc{ovn,
  key =          {ovn},
  title =        {{OVN}: Oven Virtual Network for {Open vSwitch}},
  howpublished = {\url{https://github.com/openvswitch/ovs/tree/master/ovn}},
  note =         {Retrieved January 2021}
}

@Misc{ovn-manual,
  key =          {ovn-manual},
  title =        {{OVN}: Manual pages ovn-architecture(7),
                  ovn-controller(8), ovn-controller-vtep(8),
                  ovn-ctl(8), ovn-detrace(1), ovn-nb(5), ovn-nbctl(8),
                  ovn-northd(8), ovn-sb(5), ovn-sbctl(8),
                  ovn-trace(8)},
  howpublished = {\url{https://http://openvswitch.org/support/dist-docs/}},
  note =         {Retrieved January 2021}
}

@Misc{ovn-austin,
  author =       {Justin Pettit and Ben Pfaff and Han Zhou and Ryan
                  Moats},
  title =        {Practical {OVN}: Architecture, Deployment and Scale
                  of {OpenStack} Networking},
  howpublished = {\url{http://openvswitch.org/support/slides/OVN_Austin.pdf}},
  month =        {April 28},
  year =         2016,
  note =         {OpenStack Summit},
  address =      {Austin, TX}
}

@article{isard-osr07,
  author =       {Isard, Michael},
  title =        {{Autopilot}: Automatic Data Center Management},
  journal =      {SIGOPS Oper. Syst. Rev.},
  volume =       41,
  number =       2,
  month =        apr,
  year =         2007,
  pages =        {60--67},
  url =          {http://doi.acm.org/10.1145/1243418.1243426},
  abstract =     {Microsoft is rapidly increasing the number of
                  large-scale web services that it operates. Services
                  such as Windows Live Search and Windows Live Mail
                  operate from data centers that contain tens or
                  hundreds of thousands of computers, and it is
                  essential that these data centers function reliably
                  with minimal human intervention. This paper
                  describes the first version of Autopilot, the
                  automatic data center management infrastructure
                  developed within Microsoft over the last few
                  years. Autopilot is responsible for automating
                  software provisioning and deployment; system
                  monitoring; and carrying out repair actions to deal
                  with faulty software and hardware. A key assumption
                  underlying Autopilot is that the services built on
                  it must be designed to be manageable. We also
                  therefore outline the best practices adopted by
                  applications that run on Autopilot.}
}

@Misc{differential-rust,
  author =       {Frank McSherry},
  title =        {An implementation of differential dataflow using
                  {Timely Dataflow} on {Rust}},
  howpublished = {\url{https://github.com/frankmcsherry/differential-dataflow}},
  date =         {Retrieved January 2021}
}

@article{davie-ccr17,
  author =       {Davie, Bruce and Koponen, Teemu and Pettit, Justin
                  and Pfaff, Ben and Casado, Martin and Gude, Natasha
                  and Padmanabhan, Amar and Petty, Tim and Duda,
                  Kenneth and Chanda, Anupam},
  title =        {A Database Approach to {SDN} Control Plane Design},
  year =         2017,
  issue_date =   {January 2017},
  volume =       47,
  number =       1,
  doi =          {https://doi.org/10.1145/3041027.3041030},
  url =          {https://ccronline.sigcomm.org/wp-content/uploads/2017/01/p15-davie.pdf},
  abstract =     {Software-defined networking (SDN) is a well-known
                  example of a research idea that has been reduced to
                  practice in numerous settings. Network
                  virtualization has been successfully developed
                  commercially using SDN techniques. This paper
                  describes our experience in developing
                  production-ready, multi-vendor implementations of a
                  complex network virtualization system. Having
                  struggled with a traditional network protocol
                  approach (based on OpenFlow) to achieving
                  interoperability among vendors, we adopted a new
                  approach. We focused first on defining the control
                  information content and then used a generic database
                  protocol to synchronize state between the
                  elements. Within less than nine months of starting
                  the design, we had achieved basic interoperability
                  between our network virtualization controller and
                  the hardware switches of six vendors. This was a
                  qualitative improvement on our decidedly mixed
                  experience using OpenFlow. We found a number of
                  benefits to the database approach, such as speed of
                  implementation, greater hardware diversity, the
                  ability to abstract away implementation details of
                  the hardware, clarified state consistency model, and
                  extensibility of the overall system.},
  journal =      CCR,
  month =        jan,
  pages =        {15–26},
  numpages =     12,
  keywords =     {protocols, databases, interoperability, protocol
                  design, Software-Defined Networking (SDN)},
  comments =     {Describes OVS DB.  Focused mostly on how this
                  abstraction made it much easier to obtain
                  interoperability.  Points out some important
                  benefits of this approach: (1) instead of devising a
                  protocol or a wire representation you just model the
                  information schema, (2) rely on DB techniques to do
                  some work, like state synchronization,
                  serialization, (3) easier to evolve.  Expands on
                  Onix paper.  Claims that (distributed) state
                  synchronization and not state computation is the
                  main benefit, like in declarative networking.
                  Virtual networks do not support multicast; NSX uses
                  special service nodes to replicate packets.  "We
                  could treat switch management as a generic database
                  synchronization problem instead of as a specific
                  task of forwarding state management."  "A controller
                  provides a switch with control plane configuration
                  and expects each switch to locally compute the
                  detailed forwarding state." "Thus, the data model
                  that we developed was independent of the specific
                  hardware details."  Tables synchronize
                  bi-directionally; data ownership is per column.  How
                  is the connection bootstrapped when the network is
                  started?  On connection transfer entire state,
                  subsequently transfer only deltas.  Interesting
                  interaction with High Availability (HA) using MLAG
                  (Multi-chassis link aggregation), where a DB replica
                  has to failover.  DB logs are a useful debugging
                  technique.}
}

@inproceedings{Shirshanka-socc12,
  author =       {Das, Shirshanka and Botev, Chavdar and Surlaker,
                  Kapil and Ghosh, Bhaskar and Varadarajan, Balaji and
                  Nagaraj, Sunil and Zhang, David and Gao, Lei and
                  Westerman, Jemiah and Ganti, Phanindra and Shkolnik,
                  Boris and Topiwala, Sajid and Pachev, Alexander and
                  Somasundaram, Naveen and Subramaniam, Subbu},
  title =        {All Aboard the {Databus!} {Linkedin's} Scalable
                  Consistent Change Data Capture Platform},
  year =         2012,
  url =          {https://doi.org/10.1145/2391229.2391247},
  abstract =     {In Internet architectures, data systems are
                  typically categorized into source-of-truth systems
                  that serve as primary stores for the user-generated
                  writes, and derived data stores or indexes which
                  serve reads and other complex queries. The data in
                  these secondary stores is often derived from the
                  primary data through custom transformations,
                  sometimes involving complex processing driven by
                  business logic. Similarly data in caching tiers is
                  derived from reads against the primary data store,
                  but needs to get invalidated or refreshed when the
                  primary data gets mutated. A fundamental requirement
                  emerging from these kinds of data architectures is
                  the need to reliably capture, flow and process
                  primary data changes.We have built Databus, a
                  source-agnostic distributed change data capture
                  system, which is an integral part of LinkedIn's data
                  processing pipeline. The Databus transport layer
                  provides latencies in the low milliseconds and
                  handles throughput of thousands of events per second
                  per server while supporting infinite look back
                  capabilities and rich subscription
                  functionality. This paper covers the design,
                  implementation and trade-offs underpinning the
                  latest generation of Databus technology. We also
                  present experimental results from stress-testing the
                  system and describe our experience supporting a wide
                  range of LinkedIn production applications built on
                  top of Databus.},
  booktitle =    {ACM Symposium on Cloud Computing (SoCC)},
  articleno =    18,
  numpages =     14,
  keywords =     {replication, CDC, stream processing, change data
                  capture},
  location =     {San Jose, California},
  comments =     {Has some bibliography about change data capture
                  listing mostly commercial products.  Traditionally
                  changes are extracted for a database from the logs.
                  Properties: "* Pull-model, * Externally-clocked, *
                  Consumption from arbitrary point in the change
                  stream, * Isolation between sources and consumers."
                  Good description of semantics of changes
                  (transaction boundaries, commit order, state
                  consistency).  Works only for 1 DB.  Great
                  description of requirements.  Highly relevant for
                  the design of Mimar/D3log.  Relays keep log
                  fragments.  Boostrap services are like D3log
                  accumulators.  Adaptors to get data from Oracle and
                  MySQL; interesting discussion of preserving
                  transaction information.}
}

@Misc{rfc7047,
  author =       {Ben Pfaff and Bruce Davie},
  title =        {RFC 7047: The {Open vSwitch} Database Management
                  Protocol},
  howpublished = {\url{https://tools.ietf.org/html/rfc7047}},
  month =        {December},
  year =         2013,
  note =         {IETF},
  comments =     {The wire protocol for OVSDB management is JSON, and
                  it is based on JSON-RPC.  DB operations can
                  performs: CRUD of datapaths (bridges), config of set
                  of controllers that can control, CRUD of OF
                  datapaths, CRUD of tunnel interfaces, CRUD of queues
                  and QoS policies attached to queues, collection of
                  statistics.  But not per-flow operations.  DB schema
                  is also expressed in JSON.  Cells can contain lists
                  or key-value maps.  Cells can have a specified min
                  and max number of values.  Base types are integers,
                  reals, booleans, strings, uuids.  Specifies RPCs
                  supported: list_bds, get_schema, transact, cancel,
                  monitor, monitor_cancel, lock/steal/unlock, echo
                  (ping).  Monitor is for table synchronization; it
                  causes "update" messages to be sent.  Transact can
                  perform following operations: insert, select
                  (filter), update, mutate (using simple arithmetic or
                  set language specifying columns to mutate), delete,
                  wait, commit, abort, comment, assert.}
}

@Misc{rfc3411,
  author =       {D. Harrington and R. Preshun and B. Wijnen},
  title =        {{RFC} 3411: An Architecture for Describing Simple
                  Network Management Protocol ({SNMP}) Management
                  Frameworks},
  howpublished = {\url{https://tools.ietf.org/html/rfc3411}},
  month =        {December},
  year =         2002,
  note =         {IETF},
  comments =     {Pretty complicated; describes a distributed system
                  with many agent nodes, a command generator and
                  notification receiver, a management protocol.}
}

@inproceedings{wang-apnet19,
  author =       {Wang, Anduo and Shin, Seungwon and Dragut, Eduard},
  title =        {Rethinking Network Policy Coordination: A Database
                  Perspective},
  year =         2019,
  url =          {https://doi.org/10.1145/3343180.3343193},
  abstract =     {Database usage in the context of networking has been
                  focusing on managing factual data --- network
                  state. But database systems are also renowned for
                  mediating among semantic data --- data integrity
                  constraints (ICs) that capture network
                  policies. This paper asks if and how can database
                  systems help with coordinating network policies in
                  the semantically rich environment of SDN and BGP. We
                  identify several problems --- disparate policies
                  buried in the network that hinders rather than
                  facilitates coordination; manual control flow
                  orchestration of SDN policies that burdens the SDN
                  programmer; and overlooked conflicts among
                  interdomain routing policies that, though induced by
                  multiple ASes, are only manifested within a single
                  AS. Driven by these unique problems, we present a
                  preliminary database solution that, using ICs as a
                  unifying knowledge representation, employs automated
                  reasoning to anticipate and to adjust the interplay
                  between policies and the rest of the networking
                  world.},
  booktitle =    ApNet,
  pages =        {29–35},
  numpages =     7,
  keywords =     {BGP, residue method, SDN, knowledge representation},
  location =     {Beijing, China},
  url =          {http://anduowang.github.io/docs/apnet19.pdf},
  comments =     {Focused on using DB integrity constraints to
                  simplify network management.  If ICs are violated,
                  it has a management module (orchestrator) that
                  orders DB operations.  Conflict management by
                  adjusting policies (policy negotiator).  Rules are
                  ordered: e.g., security must precede routing
                  updates.  Using DB coordination is no longer done in
                  code, but using data.  Key is that policies are
                  declarative properties of state rather than code to
                  enforce behaviors.  Integrity constraints are
                  predicates with variables (they are also "violation
                  views" that are supposed to be empty).  Language is
                  Datalog with negation, aggregation, and external
                  functions.  Static dependency analysis based on
                  constraint solvers helps detect IC layering.  They
                  use partial subsumption from theorem proving to
                  reconcile conflicting ICs: they comopute a set of
                  additional conditions (residue, always a subset of
                  one of the ICs) that makes both ICs valid.  Residues
                  are injected as additional clauses - program changes
                  at runtime, based on data!  The paper is rather
                  thin, most hard problems are future work.}
}

@inproceedings{Wang-sosr19,
  author =       {Wang, Anduo and Chen, Zhijia and Yang, Tony and Yu,
                  Minlan},
  title =        {Enabling Policy Innovation in Interdomain Routing: A
                  Software-Defined Approach},
  year =         2019,
  url =          {https://doi.org/10.1145/3314148.3314359},
  abstract =     {BGP is known to restrict policy expressiveness and
                  induce uncontrolled policy interactions that are
                  hard to understand, reuse, and evolve. We argue that
                  the use of a path vector system as the carrier of
                  interdomain policies is the root cause of these
                  limitations. To this end, we propose an alternative
                  policy scheme built in a software-defined controller
                  to decouple policy making from the path vector
                  system. Rather than treating policies as hardwired
                  attributes of a route, that are configured and
                  consumed as the route goes through the path vector
                  decision process, we let policies flow, interact,
                  and combine to influence end to end routes. This new
                  software-defined scheme creates new space for policy
                  language, route decision, and conflict resolution
                  design, towards more flexible policies, cleaner
                  policy enforcement, and controlled policy
                  interaction. As a realization of our vision, we
                  present an implementation that uses data integrity
                  constraints for representing and reasoning about
                  routing policies, addressing unique challenges in
                  the decentralized interdomain environment.},
  booktitle =    SOSR,
  pages =        {62–68},
  numpages =     7,
  keywords =     {SDN, BGP, Path-vector system, Exchangeable logic
                  policy},
  location =     {San Jose, CA, USA},
  comment =      {System is called "Bolero", and is built on top of
                  the Ravel controller.  The goal is to express
                  policies for BGP, separated from the path vector
                  system.  Routing state stored in tables.  Use a
                  Datalog-like syntax for rules.  "Denial" rules
                  (headless) indicate integrity constraints.  Seems to
                  be an application of the subsumption technique from
                  wang-apnet19.}
}

@article{loo-cacm09,
  author =       {Loo, Boon Thau and Condie, Tyson and Garofalakis,
                  Minos and Gay, David E. and Hellerstein, Joseph
                  M. and Maniatis, Petros and Ramakrishnan, Raghu and
                  Roscoe, Timothy and Stoica, Ion},
  title =        {Declarative Networking},
  year =         2009,
  issue_date =   {November 2009},
  volume =       52,
  number =       11,
  issn =         {0001-0782},
  url =          {https://doi.org/10.1145/1592761.1592785},
  abstract =     {Declarative Networking is a programming methodology
                  that enables developers to concisely specify network
                  protocols and services, which are directly compiled
                  to a dataflow framework that executes the
                  specifications. This paper provides an introduction
                  to basic issues in declarative networking, including
                  language design, optimization, and dataflow
                  execution. We present the intuition behind
                  declarative programming of networks, including roots
                  in Datalog, extensions for networked environments,
                  and the semantics of long-running queries over
                  network state. We focus on a sublanguage we call
                  Network Datalog (NDlog), including execution
                  strategies that provide crisp eventual consistency
                  semantics with significant flexibility in
                  execution. We also describe a more general language
                  called Overlog, which makes some compromises between
                  expressive richness and semantic guarantees. We
                  provide an overview of declarative network
                  protocols, with a focus on routing protocols and
                  overlay networks. Finally, we highlight related work
                  in declarative networking, and new declarative
                  approaches to related problems.},
  journal =      CACM,
  month =        nov,
  pages =        {87–95},
  numpages =     9,
  comments =     {A summary of many papers they published.  No
                  management plane, just distributed control.  NDlog
                  does not support negation.  Relations support
                  annotating columns with location; link predicates
                  control where messages can flow.  Support
                  incremental updates.  Use magic set rewriting to
                  avoid computing entire state.  They use the queries
                  to compute routing protocol state.  They have some
                  proofs about eventual consistency given some
                  (strong) assumptions.  Two languages: NDlog for
                  routing, and Overlog for virtual (overlay)
                  networks.  Supports state expiration.}
}

@article{Burns-queue16,
  title =        {Borg, Omega, and Kubernetes: Lessons learned from
                  three container-management systems over a decade},
  author =       {Burns, Brendan and Grant, Brian and Oppenheimer,
                  David and Brewer, Eric and Wilkes, John},
  journal =      {Queue},
  volume =       14,
  number =       1,
  pages =        {70--93},
  year =         2016,
  abstract =     {Though widespread interest in software containers is
                  a relatively recent phenomenon, at Google we have
                  been managing Linux containers at scale for more
                  than ten years and built three different container-
                  management systems in that time. Each system was
                  heavily influenced by its predecessors, even though
                  they were developed for different reasons. This
                  article describes the lessons we’ve learned from
                  developing and operating them.},
  comments =     {Enabled by Linux control groups.  Borg is first
                  version.  Omega stores the state in a Paxos-based
                  transaction-oriented centralized DB; broke
                  Borgmaster into separate components.  Kubernetes
                  follows; state is accessed only through REST APIs.
                  Containers shift management from machines to
                  applications.  In K8S multiple containers in a pod
                  run independent functions (e.g., log rotation).  All
                  Kubernetes objects have Metadata, Specification
                  (desired state) and Status (realized state).
                  Reconciliation controller loop is shared among all
                  these systems: takes actions to converge the two
                  states.  Reconciliation is based on observations,
                  and not on a model state diagram.  Kubernetes uses
                  multiple small control loops instead of a big
                  monolithic controller; this is called
                  "orchestration".  Application-level configuration is
                  an unsolved problem; people build lots of custom
                  languages to manipulate configuration.  Dependency
                  management is also hard.}
}

@inproceedings{Rexford-hotnets04,
  title =        {Network-wide decision making: Toward a wafer-thin
                  control plane},
  author =       {Rexford, Jennifer and Greenberg, Albert and
                  Hjalmtysson, Gisli and Maltz, David A and Myers,
                  Andy and Xie, Geoffrey and Zhan, Jibin and Zhang,
                  Hui},
  booktitle =    {Proc. HotNets},
  pages =        {59--64},
  year =         2004,
  abstract =     {We argue for the refactoring of the IP control plane
                  to provide direct expressibility and support for
                  network-wide goals relating to all fundamental
                  functionality: reachability, performance,
                  reliability and security. This refactoring is
                  motivated by trends in operational practice and in
                  networking technology. We put forward a design that
                  decomposes functionality into information
                  dissemination and decision planes. The decision
                  plane is formed by lifting out of the routers all
                  decision making logic currently found there and
                  merging it with the current managementplane where
                  network-levelobjectivesare specified. What is left
                  on each router is a wafer-thin control plane focused
                  on information dissemination and response to
                  explicit instructions for configuring packet
                  forwarding mechanisms. We discuss the consequences,
                  advantages and challenges associated with this
                  design.},
  url =          {http://www2.cs.uh.edu/~jaspal/cosc7397/06papers/waferthin.pdf},
  comments =     {Seems to suggest a centralized management plane and
                  a very small local control plane on switches.
                  Discusses the three existing planes: data, control,
                  management.  Here the management plane also looks at
                  perf data and reacts.  Problem addressed: "we have
                  no framework that can predict how local
                  configuration decisions affect network-wide
                  behavior."  "Architectural intent and operational
                  constraints governing the network should be
                  expressed directly, and then automatically
                  translated to assign roles and functionality to
                  individual routers."  Proposes instead a
                  "dissemination plane" and a "decision plane".
                  Propose to eliminate control plane altogether (no
                  distributed control).  This is a design paper.
                  Sketches solutions for traffic engineering,
                  distributed firewalls, multi-path routing, routing.}
}

@article{gude-ccr08,
  author =       {Gude, Natasha and Koponen, Teemu and Pettit, Justin
                  and Pfaff, Ben and Casado, Mart\'{\i}n and McKeown,
                  Nick and Shenker, Scott},
  title =        {{NOX}: Towards an Operating System for Networks},
  year =         2008,
  volume =       38,
  number =       3,
  issn =         {0146-4833},
  url =          {https://doi.org/10.1145/1384609.1384625},
  journal =      CCR,
  month =        jul,
  pages =        {105–110},
  numpages =     6,
  keywords =     {management, architecture, network, security},
  abstract =     {As anyone who has operated a large network can
                  attest, enterprise networks are difficult to
                  manage. That they have remained so despite
                  significant commercial and academic efforts suggests
                  the need for a different network management
                  paradigm. Here we turn to operating systems as an
                  instructive example in taming management
                  complexity.},
  url =          {http://www.cs.yale.edu/homes/jf/nox.pdf},
  comments =     {Write "apps" for networks.  Centralized programming
                  model.  To control switches they must support OF.
                  Nox provides network topology, network services
                  (e.g., web servers, NFS), but not current network
                  state or traffic.  Flow-based control.  Pretty
                  extreme OF design, where all new packets are
                  forwarded to the controller.  Has libraries for
                  e.g., DHCP, DNS, routing.  No inter-application
                  isolation.  Example apps can lookup tables and
                  install rules (OF) actions in devices dynamically.
                  Apps can register to process each packet.  Defines
                  events that are invoked (packet_in, stats_in, etc),
                  and messages (install rule, send packet, query).}
}

@inproceedings{koponen-osdi10,
  author =       {Koponen, Teemu and Casado, Martin and Gude, Natasha
                  and Stribling, Jeremy and Poutievski, Leon and Zhu,
                  Min and Ramanathan, Rajiv and Iwata, Yuichiro and
                  Inoue, Hiroaki and Hama, Takayuki and Shenker,
                  Scott},
  title =        {{Onix}: A Distributed Control Platform for
                  Large-Scale Production Networks},
  year =         2010,
  address =      {USA},
  abstract =     {Computer networks lack a general control paradigm,
                  as traditional networks do not provide any
                  network-wide management abstractions. As a result,
                  each new function (such as routing) must provide its
                  own state distribution, element discovery, and
                  failure recovery mechanisms. We believe this lack of
                  a common control platform has significantly hindered
                  the development of flexible, reliable and
                  feature-rich network control planes.To address this,
                  we present Onix, a platform on top of which a
                  network control plane can be implemented as a
                  distributed system. Control planes written within
                  Onix operate on a global view of the network, and
                  use basic state distribution primitives provided by
                  the platform. Thus Onix provides a general API for
                  control plane implementations, while allowing them
                  to make their own trade-offs among consistency,
                  durability, and scalability.},
  booktitle =    OSDI,
  pages =        {351–364},
  numpages =     14,
  location =     {Vancouver, BC, Canada},
  comments =     {"The control platform handles state distribution –
                  collecting information from the switches and
                  distributing the appropriate control state to them,
                  as well as coordinating the state among the various
                  platform servers – and provides a programmatic
                  interface upon which developers can build a wide
                  variety of management applications."  Sits on top of
                  a DHT+DB and group membership (Zookeeper) for
                  distribution.  Onix runs on a cluster to scale to
                  millions of ports.  Control logic runs on top of
                  Onix.  State centric API to control physical
                  devices.  "The control logic can: read the current
                  state associated with that object; alter the network
                  state by operating on these objects; and register
                  for notifications of state changes to these
                  objects."  State kept in Network Information Base,
                  and OO DB, where entities have K-V pair attributes.
                  NIB is distributed and offers no concurrency
                  management.  DB is passive, and not used for control.}
}

@inproceedings{Wang-SOSR16,
  author =       {Wang, Anduo and Mei, Xueyuan and Croft, Jason and
                  Caesar, Matthew and Godfrey, Brighten},
  title =        {{Ravel}: A Database-Defined Network},
  year =         2016,
  url =          {https://doi.org/10.1145/2890955.2890970},
  abstract =     {SDN's logically centralized control provides an
                  insertion point for programming the network. While
                  it is generally agreed that higher-level
                  abstractions are needed to make that programming
                  easy, there is little consensus on what are the
                  "right" abstractions. Indeed, as SDN moves beyond
                  its initial specialized deployments to broader use
                  cases, it is likely that network control
                  applications will require diverse abstractions that
                  evolve over time.To this end, we champion a
                  perspective that SDN control fundamentally revolves
                  around data representation. We discard any
                  application-specific structure that might be
                  outgrown by new demands. Instead, we adopt a plain
                  data representation of the entire network ---
                  network topology, forwarding, and control
                  applications --- and seek a universal data language
                  that allows application programmers to transform the
                  primitive representation into any high-level
                  representations presented to applications or network
                  operators. Driven by this insight, we present a
                  system, Ravel, that implements an entire SDN network
                  control infrastructure within a standard SQL
                  database. In Ravel, network abstractions take the
                  form of user-defined SQL views expressed by SQL
                  queries that can be added on the fly. A key
                  challenge in realizing this approach is to
                  orchestrate multiple simultaneous abstractions that
                  collectively affect the same underlying data. To
                  achieve this, Ravel enhances the database with novel
                  data integration mechanisms that merge the multiple
                  views into a coherent forwarding behavior. Moreover,
                  Ravel is exposed to applications through the one
                  simple, familiar and highly interoperable SQL
                  interface. While this is an ambitious long-term
                  goal, our prototype built on the PostgreSQL database
                  exhibits promising performance even for large scale
                  networks.},
  booktitle =    SOSR,
  articleno =    5,
  numpages =     7,
  keywords =     {Software-Defined Networks, Views, Programming
                  Abstraction, SQL Database},
  location =     {Santa Clara, CA, USA},
  note =         {\url{http://ravel-net.org/}},
  comments =     {Ravel is a software-defined networking (SDN)
                  controller that uses a standard SQL database to
                  represent the network.  SDN fundamentally revolves
                  around data representation–representation of the
                  network topology and forwarding, as well as the
                  higher-level abstractions useful to applications.
                  In Ravel, the entire network control infrastructure
                  is implemented within a SQL database. Abstractions
                  of the network take the form of SQL views expressed
                  by SQL queries that can be instantiated and extended
                  on the fly. To allow multiple simultaneous
                  abstractions to collectively drive control, Ravel
                  automatically orchestrates the abstractions to merge
                  multiple views into a coherent forwarding behavior.
                  Uses Postgres.  Demo video available.  Apps
                  manipulate DB separately.  Orchestration controls
                  interaction between multiple apps, by ordering views
                  in order of "importance".  Applications are sorted
                  linearly and higher priority apps win on conflicts.
                  Explicitly discard application-specific structure
                  from representation.  Stacked views.  Triggers on
                  views realize the dataplane; they can contains
                  custom heuristics.  View maintenance refreshes
                  dynamic network views.  The DB is used to control,
                  not just to reflect and compute policies.  DB
                  operates on predefined tables and user-defined
                  views.  Apparently views are modifiable, and view
                  maintenance is bi-directional.  This does not always
                  work, so operators have to intervene.  They have a
                  DB for all flows (complete reachability matrix),
                  including flow volume!  For performance objects have
                  integer IDs mapped to real values in auxilliary
                  tables (e.g., IP address).  Base tables talk to
                  network using OF.  Use SQL rule processing of the
                  form ON event DO action WHERE condition to repair
                  violations.  Events can work directly on views;
                  manually written SQL RULEs convert operations on
                  view to operations on tables.  SQL triggers are used
                  to create a global priority ordering between
                  policies.  Uses Mininet.  1KLOC SQL + 100LOC Python
                  for base and 4 applications (routing, load
                  balancing, ACL, tenants).  Avoid recursive queries
                  by recursive triggers.}
}

@article{Chen-ccr10,
  author =       {Chen, Xu and Mao, Yun and Mao, Z. Morley and Van der
                  Merwe, Jacobus},
  title =        {{DECOR}: {DEClarative} Network Management and
                  {OpeRation}},
  journal =      CCR,
  volume =       40,
  number =       1,
  month =        jan,
  year =         2010,
  pages =        {61--66},
  url =          {http://web.eecs.umich.edu/~zmao/Papers/presto10.pdf},
  doi =          {http://doi.acm.org/10.1145/1672308.1672321},
  abstract =     {Network management operations are complicated,
                  tedious and error-prone, requiring significant human
                  involvement and expert knowledge. In this paper, we
                  first examine the fundamental components of
                  management operations and argue that the lack of
                  automation is due to a lack of programmability at
                  the right level of abstraction. To address this
                  challenge, we present DECOR, a database-oriented,
                  declarative framework towards automated network
                  management. DECOR models router configuration and
                  any generic network status as relational data in a
                  conceptually centralized database. As such, network
                  management operations can be represented as a series
                  of transactional database queries, which provide the
                  benefit of atomicity, consistency and isolation. The
                  rule-based language in DECOR provides the flexible
                  programmability to specify and enforce network-wide
                  management constraints, and achieve high-level task
                  scheduling. We describe the design rationale and
                  architecture of DECOR and present some preliminary
                  examples applying our approach to common network
                  management tasks.},
  comments =     {DB relations to represent networks.  Use DB
                  transactions to operate on the network.  Proposes
                  the idea that routers operate on views of the DB.
                  Tables reflect both configuration and status.
                  Status tables are maintained on demand only.  Uses
                  Mosaic, a variant of Datalog.  Three types of
                  statements in programs: execution (trigger changes),
                  constraint (enforce validity), and views.  Some
                  rules express plans with finite-state transition
                  rules triggered by status changes.  They have
                  "periodic" rules to trigger status collection.
                  "Rules" that can violate constraints are cancelled
                  (or postponed); not clear what happens if that's a
                  derived rule.  Rules can access current time.  The
                  "challenges" section is long and lists a series of
                  difficult problems: failure handling,
                  synchronization, constraints, rule execution order,
                  distributed computation.  This is not standard
                  Datalog, it has a more imperative flavor.}
}

@INPROCEEDINGS{wang-icnp16,
  author =       {Wen Wang and Wenbo He and Jinshu Su},
  booktitle =    {International Conference on Network
                  Protocols (ICNP)},
  title =        {{Redactor}: Reconcile network control with
                  declarative control programs In {SDN}},
  year =         2016,
  pages =        {1-10},
  doi =          {10.1109/ICNP.2016.7784433},
  url =          {http://www.jinshusu.net.cn/static/wenredactor.pdf},
  abstract =     {With SDN control programs from multi-domains
                  configuring the network, it is inevitable that
                  control programs make conflicting control decisions,
                  which probably lead to misconfiguration or
                  performance degradation. Existing control
                  coordination approaches either compose control
                  programs to derive consistent solutions jointly or
                  examine the generated rules of each control program
                  to ensure they are consistent. However, the former
                  is usually of great complexity and hard to be
                  conducted automatically, and the latter probably
                  results in suboptimal solutions due to the
                  independent execution of control programs. Moreover,
                  these approaches all fail to consider the control
                  utility of control programs. In this paper, we
                  propose Redactor to optimize the consistency and
                  utility of network control in an automatic and
                  dynamic manner. To make network control consistent,
                  we implement SDN control programs with declarative
                  language Prolog, and compose control programs
                  automatically to execute together to make consistent
                  decisions. When conflicts occur, we use a heuristic
                  approach to compromise a subset of control programs
                  to maximize the control utility. We compare Redactor
                  with the static priority mechanism and Athens [1],
                  and the results show that Redactor always satisfies
                  more control objectives to achieve better control
                  consistency and utility.},
  comments =     {Problem is conflicting decisions between multiple
                  control program.  Goal is to maximize "control
                  utility" (number of control objectives?).  The
                  language used is Prolog.  This paper is pretty badly
                  written.  Composing multiple programs: predicates
                  can just be and-ed.  If there are no solutions they
                  want to maximize the number of predicates satisfied;
                  they can add weights to predicates.  This does not
                  look well-defined or sound or useful.  Network
                  modeled as a database.}
}

@article{reich-login13,
  author =       {Joshua Reich and Christopher Monsanto and Nate
                  Foster and Jennifer Rexford and and David Walker},
  title =        {Modular {SDN} Programming with {Pyretic}},
  journal =      {USENIX ;login},
  volume =       38,
  number =       5,
  month =        oct,
  year =         2013,
  abstract =     {Software-Defined Networking (SDN) enables innovation
                  in network management by giving a programmable
                  controller direct control over the underlying
                  switches through an open, standard API, like
                  OpenFlow. However, existing SDN controllers offer
                  programmers a low-level programming interface akin
                  to assembly language. In this article, we present
                  Pyretic, a programming platform that raises the
                  level of abstraction and enables the creation of
                  modular software, allowing programmers to create
                  sophisticated SDN applications.},
  url =          {http://frenetic-lang.org/publications/pyretic-login13.pdf},
  comments =     {Part of the Frenetic project.  Pyretic is
                  Python-based.  Apps run on top of the controller
                  platform.  Controller talks OF to switches.  Pyretic
                  is the API between apps and controller.  Main
                  Pyretic object is a packet (which includes headers
                  and metadata such as switch and port).  Users write
                  functions from such packets to sets of packets.
                  Programs can use parallel and sequential function
                  composition.  Query API supports monitoring; uses
                  group_by to compute histograms.  Queries register
                  callbacks.  Policy = set of rules.  Policies can
                  update themselves; that's how round-robin scheduling
                  can be done.  A callback can replace a policy.  A
                  virtual switch is a topology abstraction of a set of
                  switches.  Quite elegant.  Initially implemented a
                  centralized controller, which installs only safe
                  rules (that cannot change) and routes every packet
                  to controller otherwise.  Code is 6x more concise
                  than NOX.}
}

@inproceedings{monsanto-nsdi13,
  author =       {Monsanto, Christopher and Reich, Joshua and Foster,
                  Nate and Rexford, Jennifer and Walker, David},
  title =        {Composing Software-Defined Networks},
  year =         2013,
  publisher =    {USENIX Association},
  address =      {USA},
  abstract =     {Managing a network requires support for multiple
                  concurrent tasks, from routing and traffic
                  monitoring, to access control and server load
                  balancing. Software-Defined Networking (SDN) allows
                  applications to realize these tasks directly, by
                  installing packet-processing rules on
                  switches. However, today's SDN platforms provide
                  limited support for creating modular
                  applications. This paper introduces new abstractions
                  for building applications out of multiple,
                  independent modules that jointly manage network
                  traffic. First, we define composition operators and
                  a library of policies for forwarding and querying
                  traffic. Our parallel composition operator allows
                  multiple policies to operate on the same set of
                  packets, while a novel sequential composition
                  operator allows one policy to process packets after
                  another. Second, we enable each policy to operate on
                  an abstract topology that implicitly constrains what
                  the module can see and do. Finally, we define a new
                  abstract packet model that allows programmers to
                  extend packets with virtual fields that may be used
                  to associate packets with high-level meta-data. We
                  realize these abstractions in Pyretic, an
                  imperative, domain-specific language embedded in
                  Python.},
  booktitle =    NSDI,
  pages =        {1–14},
  numpages =     14,
  location =     {Lombard, IL},
  comments =     {The serious version of reich-login13}
}

@inproceedings{foster-icfp11,
  author =       {Foster, Nate and Harrison, Rob and Freedman, Michael
                  J. and Monsanto, Christopher and Rexford, Jennifer
                  and Story, Alec and Walker, David},
  title =        {{Frenetic}: A Network Programming Language},
  booktitle =    ICFP,
  year =         2011,
  address =      {Tokyo, Japan},
  pages =        {279--291},
  url =          {http://www.cs.tufts.edu/comp/150PLD/Papers/Frenetic.pdf},
  abstract =     {Modern networks provide a variety of interrelated
                  services including routing, traffic monitoring, load
                  balancing, and access control.  Unfortunately, the
                  languages used to program today’s networks lack
                  modern features—they are usually defined at the low
                  level of abstraction supplied by the underlying
                  hardware and they fail to provide even rudimentary
                  support for modular programming. As a result,
                  network programs tend to be complicated,
                  error-prone, and difficult to maintain.  This paper
                  presents Frenetic, a high-level language for
                  programming distributed collections of network
                  switches. Frenetic provides a declarative query
                  language for classifying and aggregating network
                  traffic as well as a functional reactive combinator
                  library for describing high-level packet-forwarding
                  policies. Unlike prior work in this domain, these
                  constructs are-—by design-—fully compositional, which
                  facilitates modular reasoning and enables code
                  reuse. This important property is enabled by
                  Frenetic’s novel runtime system which manages all
                  of the details related to installing, uninstalling,
                  and querying low-level packet-processing rules on
                  physical switches.  Overall, this paper makes three
                  main contributions: (1) We analyze the
                  state-of-the art in languages for programming
                  networks and identify the key limitations; (2) We
                  present a language design that addresses these
                  limitations, using a series of examples to motivate
                  and validate our choices; (3) We describe an
                  implementation of the language and evaluate its
                  performance on several benchmarks.},
  note =         {\url{http://frenetic-lang.org/}},
  comments =     {Declarative query language for aggregating and
                  classifying packets and combinators for forwarding.
                  Modular.  Combines control and data-plane
                  manipulation of packets in one language.  Avoids
                  some races if packets arrive before rules are
                  installed.  Frenetic is embedded in Python.  The
                  paper describes the runtime: a centralized component
                  on top of the centralized NOX OF controller.
                  Runtime maintains shadow copies of all switch data
                  structures.  First packet is executed in runtime and
                  rules are sent and installed on switch.  For races
                  it installs temporary rules on controller to handle
                  racy packets.  Only use exact matches.  Can program
                  a whole metwork.}
}

@inproceedings{singh-sigcomm16,
  author =       {Singh, Arjun and Ong, Joon and Agarwal, Amit and
                  Anderson, Glen and Armistead, Ashby and Bannon, Roy
                  and Boving, Seb and Desai, Gaurav and Felderman, Bob
                  and Germano, Paulie and Kanagala, Anand and Liu,
                  Hong and Provost, Jeff and Simmons, Jason and Tanda,
                  Eiichi and Wanderer, Jim and H\"{o}lzle, Urs and
                  Stuart, Stephen and Vahdat, Amin},
  title =        {{Jupiter} Rising: A Decade of {CLOS} Topologies and
                  Centralized Control in {Google's} Datacenter Network},
  year =         2015,
  issue_date =   {August 2015},
  abstract =     {We present our approach for overcoming the cost,
                  operational complexity, and limited scale endemic to
                  datacenter networks a decade ago. Three themes unify
                  the five generations of datacenter networks detailed
                  in this paper. First, multi-stage Clos topologies
                  built from commodity switch silicon can support
                  cost-effective deployment of building-scale
                  networks. Second, much of the general, but complex,
                  decentralized network routing and management
                  protocols supporting arbitrary deployment scenarios
                  were overkill for single-operator, pre-planned
                  datacenter networks. We built a centralized control
                  mechanism based on a global configuration pushed to
                  all datacenter switches. Third, modular hardware
                  design coupled with simple, robust software allowed
                  our design to also support inter-cluster and
                  wide-area networks. Our datacenter networks run at
                  dozens of sites across the planet, scaling in
                  capacity by 100x over 10 years to more than 1 Pbps
                  of bisection bandwidth.},
  booktitle =    SIGCOMM,
  month =        aug,
  url =          {https://research.google/pubs/pub43837.pdf},
  comments =     {CLOS topologies, merchant silicon, centralized
                  control protocols.  Control looks more like storage
                  and compute control than network.  Power and load
                  require flat networks and distributed computation
                  rather than local.  Data access has little locality.
                  CLOS requires less reliability in each router.
                  Started in datacenters, but applied to WAN as well.
                  Building routers from servers didn't work -- long
                  reboots, low reliability.  Cabling complexity is
                  important.  Custom routing to support multi-path.
                  Use a separate reliable control-plane network.  Send
                  deltas to switches.  Control inspired by GFS.
                  Controller is replicated (master/slave).  Treat
                  switches much like servers: logging, image
                  deployment, alterting, monitoring.}
}


@inproceedings{Hyojoon-nsdi15,
  author =       {Kim, Hyojoon and Reich, Joshua and Gupta, Arpit and
                  Shahbaz, Muhammad and Feamster, Nick and Clark,
                  Russ},
  title =        {{Kinetic}: Verifiable Dynamic Network Control},
  year =         2015,
  address =      {USA},
  abstract =     {Network conditions are dynamic; unfortunately,
                  current approaches to configuring networks. Network
                  operators need tools to express how a network's
                  data-plane behavior should respond to a wide range
                  of events and changing conditions, ranging from
                  unexpected failures to shifting traffic patterns to
                  planned maintenance. Yet, to update the network
                  configuration today, operators typically rely on a
                  combination of manual intervention and ad hoc
                  scripts. In this paper, we present Kinetic, a domain
                  specific language and network control system that
                  enables operators to control their networks
                  dynamically in a concise, intuitive way. Kinetic
                  also automatically verifies the correctness of these
                  control programs with respect to user-specified
                  temporal properties. Our user study of Kinetic with
                  several hundred network operators demonstrates that
                  Kinetic is intuitive and usable, and our performance
                  evaluation shows that realistic Kinetic programs
                  scale well with the number of policies and the size
                  of the network.},
  booktitle =    NSDI,
  pages =        {59–72},
  numpages =     14,
  location =     {Oakland, CA},
  url =          {https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-kim.pdf},
  comments =     {Verifies that control program satisfy some
                  properties.  Languages like Frenetic do not automate
                  changes in reaction to dynamic conditions.  Express
                  network policies in terms of FSMs.  States =
                  forwarding behavior.  Group flows into equivalence
                  classes that are treated similarly.  Kinetic is
                  based on Pyretic.  Very impressive user study (877
                  people).  Use model checking for validation using
                  Computation Tree Logic to express properties.  A
                  group of equivalent flows is expressed by a filter.
                  FSMs can be composed with sequential or parallel
                  composition (like policies).  Network representation
                  is linear in number of hosts and policies.  Users
                  write CTL formulas that are automatically checked
                  for all specified policies.  I am not convinced of
                  the usefulness of CTL for this use case.}
}


@inproceedings{soule-hotnet13,
  author =       {Soul\'{e}, Robert and Basu, Shrutarshi and
                  Kleinberg, Robert and Sirer, Emin G\"{u}n and
                  Foster, Nate},
  title =        {Managing the Network with {Merlin}},
  year =         2013,
  url =          {https://doi.org/10.1145/2535771.2535792},
  abstract =     {This paper presents the Merlin network management
                  framework. With Merlin, administrators express
                  network policy using programs in a declarative
                  language based on logical predicates and regular
                  expressions. The Merlin compiler automatically
                  partitions these programs into components that can
                  be placed on a variety of devices including
                  switches, middleboxes, and end hosts. It uses a
                  constraint solver and parameterizable heuristics to
                  allocate resources such as paths and bandwidth. To
                  ease the administration of federated networks,
                  Merlin provides mechanisms for delegating management
                  of sub-policies to tenants, along with tools for
                  verifying that delegated sub-policies do not violate
                  global constraints. Overall, Merlin simplifies the
                  task of network administration by providing
                  high-level abstractions for directly specifying
                  network policy.},
  booktitle =    HotNets,
  articleno =    24,
  numpages =     7,
  keywords =     {verification, software-defined networking, program
                  partitioning, delegation, Merlin},
  location =     {College Park, Maryland},
  series =       {HotNets-XII},
  note =         {https://github.com/merlin-lang/merlin},
  url =          {https://www.cs.cornell.edu/~jnfoster/papers/merlin-hotnets13.pdf},
  comments =     {Program the whole network, not just one device.
                  Policies expressed in high-level language.  Merlin
                  partitions the programs to tenants.  Regexes
                  describe paths.  Expressions can represent bandwidth
                  constraints.  Predicates express sets of packets.
                  (Statement = predicate -> path transformations
                  bandwidth).  Transformations must only use local
                  state.  Policies are mapped to constraints that are
                  solved using linear programming.  3 execution
                  layers: OF switches for forwarding, Click boxes for
                  middleboxes, and Linux utilities for end-hosts
                  (filtering, rate limiting).  Administrators can
                  delegate policies to tenants, who can refine them.
                  The language can check policy inclusion using
                  language inclusion checks.}
}

@inproceedings{katta-xldi12,
  title =        {Logic programming for software-defined networks},
  author =       {Katta, Naga Praveen and Rexford, Jennifer and
                  Walker, David},
  booktitle =    {Workshop on Cross-Model Design and Validation
                  (XLDI)},
  year =         2012,
  url =          {http://frenetic-lang.org/publications/logic-programming-xldi12.pdf},
  abstract =     {In this paper, we present the preliminary design of
                  a new language, called Flog that combines ideas
                  found in both FML and in Frenetic. First, from FML,
                  we adopt the idea of using logic programming as the
                  central paradigm for controlling software-defined
                  networks. Logic programming appears to be a good fit
                  for this domain because of the success of FML and
                  because so much of SDN programming is table-driven
                  collection and processing of network statistics.},
  comments =     {Datalog specialized for SDNs.  3 components: query
                  network state, process data from queries, and
                  generate forwarding policies.  Event-based logic
                  programming.  This paper only handles 1 event:
                  packet arrival at controller.  Has a z^{+1}
                  operator, to save state for the "next" time step;
                  this must be chained to propagate forever.  (Not
                  clear how such facts are deleted; they can be
                  ignored by actions with higher priority).  Facts not
                  saved are deleted (so they are streams).  Some rules
                  have actions on packets in heads.  Examples:
                  learning firewall, ethernet learning switch.}
}

@inproceedings{nelson-nsdi14,
  author =       {Nelson, Tim and Ferguson, Andrew D. and Scheer,
                  Michael J. G. and Krishnamurthi, Shriram},
  title =        {Tierless Programming and Reasoning for
                  Software-defined Networks},
  booktitle =    NSDI,
  year =         2014,
  location =     {Seattle, WA},
  pages =        {519--531},
  url =          {https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-nelson.pdf},
  doi =          {http://dl.acm.org/citation.cfm?id=2616448.2616496},
  abstract =     {We present Flowlog, a tierless language for
                  programming SDN controllers. In contrast to
                  languages with different abstractions for each
                  program tier--the control-plane, data-plane, and
                  controller state--Flowlog provides a unified
                  abstraction for all three tiers. Flowlog is
                  reminiscent of both SQL and rule-based languages
                  such as Cisco IOS and JunOS; unlike these network
                  configuration languages, Flowlog supports
                  programming with mutable state. We intentionally
                  limit Flowlog's expressivity to enable built-in
                  verification and proactive compilation despite the
                  integration of controller state. To compensate for
                  its limited expressive power, Flowlog enables the
                  reuse of external libraries through callouts.
                  Flowlog proactively compiles essentially all
                  forwarding behavior to switch tables. For rules that
                  maintain controller state or generate fresh packets,
                  the compiler instructs switches to send the minimum
                  amount of necessary traffic to the controller. Given
                  that Flowlog programs can be stateful, this process
                  is non-trivial. We have successfully used Flowlog to
                  implement real network applications. We also compile
                  Flowlog programs to Alloy, a popular verification
                  tool. With this we have verified several properties,
                  including program-correctness properties that are
                  topology-independent, and have found bugs in our own
                  programs.},
   comments =    {Flowlog has no loops or recursion, or joins.
                  Compiles to NetCore.  Programs with events: on each
                  even can perform database actions.  On packet
                  receipt can modify packet.  Everything is a table,
                  including external functions.  Strongly-typed.
                  Events have a schema.  Events are stored in tables
                  (queues?)  Table entries can timeout (affects
                  caching).  SQL-like INSERT, DELETE statements and
                  triggers.  It uses a centralized database
                  abstraction with tables representing everything,
                  including events, data, external functions (like
                  getTime), and the packets themselves.  Packets are
                  forwarded or multicast by writing data into
                  corresponding tables ``forward'' or ``emit''.
                  Programs are similar to SQL programs with triggers
                  that execute when tables are changed.  No recursion
                  or iteration, but they are implemented using
                  timeouts that trigger iterations.  Not clear how
                  deletion is handled for transitive closure
                  implementations; their example does not.
                  State(next) = State(current) + (Inserts - Deletes).
                  Has a nice table summarizing other published netowrk
                  languages.  Uses a bunch of tools off the shelf: XSB
                  Prolog to evalute programs on the controller, Thrift
                  RPC, OpenFlow an Frenetic for runtime, including
                  NetCore, Allow for verification.  Implemented in
                  OCaml.  Even arithmetic is represented with "remote"
                  (in fact external) tables!}
}

@inproceedings{casado-sigcomm07,
  author =       {Casado, Martin and Freedman, Michael J. and Pettit,
                  Justin and Luo, Jianying and McKeown, Nick and
                  Shenker, Scott},
  title =        {{Ethane}: Taking Control of the Enterprise},
  year =         2007,
  doi =          {https://doi.org/10.1145/1282380.1282382},
  abstract =     {This paper presents Ethane, a new network
                  architecture for the enterprise. Ethane allows
                  managers to define a single network-wide fine-grain
                  policy, and then enforces it directly. Ethane
                  couples extremely simple flow-based Ethernet
                  switches with a centralized controller that manages
                  the admittance and routing of flows. While radical,
                  this design is backwards-compatible with existing
                  hosts and switches.We have implemented Ethane in
                  both hardware and software, supporting both wired
                  and wireless hosts. Our operational Ethane network
                  has supported over 300 hosts for the past four
                  months in a large university network, and this
                  deployment experience has significantly affected
                  Ethane's design.},
  url =          {http://www.icsi.berkeley.edu/pubs/networking/ethanetaking07.pdf},
  booktitle =    SIGCOMM,
  pages =        {1–12},
  numpages =     12,
  keywords =     {security, management, architecture, network},
  location =     {Kyoto, Japan},
  comments =     {Principles: policies should be expressed on
                  high-level names; policy should determine packet
                  paths; bind packets to their origin.  Inspired by 4D
                  - centralized architecture.  Can be deployed
                  incrementally.  Centralized controller looks at each
                  flow start packet and makes a decision.  Controller
                  maintains centralized network database required for
                  all decisions (e.g., user names, DNS, DHCP, etc.)
                  Controller keeps a log.  This predates OF, uses a
                  language called PolEth.  Everything authenticates at
                  the controller (hosts, switches, users).  Bootstrap
                  using a spanning tree to reach controller.
                  Routers/switches are dumb: they do not run any of
                  the complex protocols.  They claim smaller flow
                  tables; no flooding.  A flow table has header,
                  action, counters.  Entries may timeout.  Only two
                  tables: one for flows and one for hosts; just hash
                  tables.  Network does not offer reliable join and
                  leave events.  Discusses reliable distributed
                  controllers.  Actions: allow, deny, waypoints
                  (redirect), outbound-only.  Cannot handle multiple
                  users on a single machine.  Biggish code base
                  (>50KLOC); custom switches (Wireless, PC, NetFPGA).
                  Storm request on failure.  Interesting lessons.  Was
                  easy to manage.}
}

@article{greenberg-ccr05,
  author =       {Greenberg, Albert and Hjalmtysson, Gisli and Maltz,
                  David A. and Myers, Andy and Rexford, Jennifer and
                  Xie, Geoffrey and Yan, Hong and Zhan, Jibin and
                  Zhang, Hui},
  title =        {A Clean Slate {4D} Approach to Network Control and
                  Management},
  year =         2005,
  issue_date =   {October 2005},
  volume =       35,
  number =       5,
  issn =         {0146-4833},
  doi =          {https://doi.org/10.1145/1096536.1096541},
  abstract =     {Today's data networks are surprisingly fragile and
                  difficult to manage. We argue that the root of these
                  problems lies in the complexity of the control and
                  management planes--the software and protocols
                  coordinating network elements--and particularly the
                  way the decision logic and the distributed-systems
                  issues are inexorably intertwined. We advocate a
                  complete refactoring of the functionality and
                  propose three key principles--network-level
                  objectives, network-wide views, and direct
                  control--that we believe should underlie a new
                  architecture. Following these principles, we
                  identify an extreme design point that we call "4D,"
                  after the architecture's four planes: decision,
                  dissemination, discovery, and data. The 4D
                  architecture completely separates an AS's decision
                  logic from pro-tocols that govern the interaction
                  among network elements. The AS-level objectives are
                  specified in the decision plane, and en-forced
                  through direct configuration of the state that
                  drives how the data plane forwards packets. In the
                  4D architecture, the routers and switches simply
                  forward packets at the behest of the decision plane,
                  and collect measurement data to aid the decision
                  plane in controlling the network. Although 4D would
                  involve substantial changes to today's control and
                  management planes, the format of data packets does
                  not need to change; this eases the deployment path
                  for the 4D architecture, while still enabling
                  substantial innovation in network control and
                  management. We hope that exploring an extreme design
                  point will help focus the attention of the research
                  and industrial communities on this crucially
                  important and intellectually challenging area.},
  journal =      CCR,
  month =        oct,
  pages =        {41–54},
  numpages =     14,
  keywords =     {network management, control, robustness},
  url =          {http://www.cs.cmu.edu/~4D/papers/greenberg-ccr05.pdf},
  comments =     {Call "control plane" a "decision plane".  Separate
                  packets from protocols.  Principles: use high level
                  concepts ("network level objectives").  Network-wide
                  views "inspired by databases".  Direct control:
                  management system is the only one setting state in
                  dataplane.  "Dissemination plane" = control network.
                  Seems to be a paper design.  But quite forward
                  looking.  Predicts following problems can be
                  tackled: traffic engineering, optimal filtering for
                  reachability, planned maintenance, change management
                  while respecting optimization and policies.  For
                  dissemination three alternatives: flooding,
                  spanning-tree, or source routing.
                  Zero-configuration (fully automatic
                  discovery). "data plane could provide an integrated
                  mechanism that combines packet forwarding,
                  filtering, and transformation" --- hints at OF.}
}

@inproceedings{monsanto-popl12,
  author =       {Monsanto, Christopher and Foster, Nate and Harrison,
                  Rob and Walker, David},
  title =        {A Compiler and Run-time System for Network
                  Programming Languages},
  booktitle =    POPL,
  year =         2012,
  address =      {Philadelphia, PA, USA},
  pages =        {217--230},
  abstract =     {Software-defined networks (SDNs) are a new kind of
                  network architecture in which a controller machine
                  manages a distributed collection of switches by
                  instructing them to install or uninstall
                  packet-forwarding rules and report traffic
                  statistics. The recently formed Open Networking
                  Consortium, whose members include Google, Facebook,
                  Microsoft, Verizon, and others, hopes to use this
                  architecture to transform the way that enterprise
                  and datacenter networks are implemented.  In this
                  paper,we define a high-level,declarative
                  language,called NetCore, for expressing
                  packet-forwarding policies on SDNs. NetCore is
                  expressive, compositional, and has a formal
                  semantics.  To ensure that a majority of packets are
                  processed efficiently on switches—instead of on the
                  controller—we present new compilation algorithms for
                  NetCore and couple them with a new run-time system
                  that issues rule installation commands and
                  traffic-statistics queries to switches. Together,
                  the compiler and run-time system generate efficient
                  rules whenever possible and outperform the simple,
                  manual techniques commonly used to program SDNs
                  today. In addition, the algorithms we develop are
                  generic, assuming only that the packet-matching
                  capabilities available on switches satisfy some
                  basic algebraic laws.  Overall, this paper delivers
                  a new design for a high-level network programming
                  language; an improved set of compiler algo- rithms;
                  a new run-time system for SDN architectures; the
                  first formal semantics and proofs of correctness in
                  this domain; and an implementation and evaluation
                  that demonstrates the performance benefits over
                  traditional manual techniques.},
  url =          {https://www.cs.princeton.edu/~dpw/papers/ncore-popl12.pdf},
  comments =     {Reactive specialization: on each packet specialize
                  the switch program.  Successor to Frenetic.
                  Generates wildcard rules.  Invariant rules (that do
                  not change with time) are installed on switches;
                  programmers specify invariance by hand.  Predicates
                  are a function of state snapshots.  Two models of
                  distributed system state: instantaneous
                  (synchronous) and delayed (asynchronous, with queues
                  modelling delayed action).  Three-valued logic:
                  maybe indicates that a packet must be processed by
                  controller.  The actual implementation is "between"
                  the two machines (there are two simulation
                  relations).},
}

@article{McKeown-ccr08,
  author =       {McKeown, Nick and Anderson, Tom and Balakrishnan,
                  Hari and Parulkar, Guru and Peterson, Larry and
                  Rexford, Jennifer and Shenker, Scott and Turner,
                  Jonathan},
  title =        {{OpenFlow}: Enabling Innovation in Campus Networks},
  journal =      CCR,
  issue_date =   {April 2008},
  volume =       38,
  number =       2,
  month =        mar,
  year =         2008,
  issn =         {0146-4833},
  pages =        {69--74},
  url =          {http://doi.acm.org/10.1145/1355734.1355746},
  abstract =     {This whitepaper proposes OpenFlow: a way for
                  researchers to run experimental protocols in the
                  networks they use every day. OpenFlow is based on an
                  Ethernet switch, with an internal flow-table, and a
                  standardized interface to add and remove flow
                  entries. Our goal is to encourage networking vendors
                  to add OpenFlow to their switch products for
                  deployment in college campus backbones and wiring
                  closets. We believe that OpenFlow is a pragmatic
                  compromise: on one hand, it allows researchers to
                  run experiments on heterogeneous switches in a
                  uniform way at line-rate and with high port-density;
                  while on the other hand, vendors do not need to
                  expose the internal workings of their switches. In
                  addition to allowing researchers to evaluate their
                  ideas in real-world traffic settings, OpenFlow could
                  serve as a useful campus component in proposed
                  large-scale testbeds like GENI. Two buildings at
                  Stanford University will soon run OpenFlow networks,
                  using commercial Ethernet switches and routers. We
                  will work to encourage deployment at other schools;
                  and We encourage you to consider deploying OpenFlow
                  in your university network too.},
  url =          {http://ccr.sigcomm.org/online/files/p69-v38n2n-mckeown.pdf},
  comments =     {Original OpenFlow paper; not peer-reviewed.
                  Designed as a platform to enable experimentation.
                  An open protocol to program existing flow tables in
                  switches.  Uses lessons from Ethane casado-sigcomm07.}
}

@inproceedings{anderson-popl14,
  author =       {Anderson, Carolyn Jane and Foster, Nate and Guha,
                  Arjun and Jeannin, Jean-Baptiste and Kozen, Dexter
                  and Schlesinger, Cole and Walker, David},
  title =        {{NetKAT}: Semantic Foundations for Networks},
  booktitle =    POPL,
  year =         2014,
  location =     {San Diego, California, USA},
  pages =        {113--126},
  doi =          {http://doi.acm.org/10.1145/2535838.2535862},
  abstract =     {Recent years have seen growing interest in
                  high-level languages for programming networks. But
                  the design of these languages has been largely ad
                  hoc, driven more by the needs of applications and
                  the capabilities of network hardware than by
                  foundational principles. The lack of a semantic
                  foundation has left language designers with little
                  guidance in determining how to incorporate new
                  features, and programmers without a means to reason
                  precisely about their code.  This paper presents
                  NetKAT, a new network programming language that is
                  based on a solid mathematical foundation and comes
                  equipped with a sound and complete equational
                  theory. We describe the design of NetKAT, including
                  primitives for filtering, modifying, and
                  transmitting packets; union and sequential
                  composition operators; and a Kleene star operator
                  that iterates programs. We show that NetKAT is an
                  instance of a canonical and well-studied
                  mathematical structure called a Kleene algebra with
                  tests (KAT) and prove that its equational theory is
                  sound and complete with respect to its denotational
                  semantics. Finally, we present practical
                  applications of the equational theory including
                  syntactic techniques for checking reachability,
                  proving non-interference properties that ensure
                  isolation between programs, and establishing the
                  correctness of compilation algorithms.},
  url =          {http://www.cs.cornell.edu/~jnfoster/papers/frenetic-netkat.pdf},
  comments =     {Regular expressions denote network paths.  Switch
                  functionality consists of perdicates and actions.
                  Topologies are also simple policies of the form
                  switch=source and port=y and switch <- dest and port
                  <- in.  Given a topology t, and a routing policy p,
                  the general network policy is (in (p t)* out), where
                  in and out describe inputs and outputs.  Policy
                  equivalence is decidable.  The semantics maintains
                  for each packet its history (a list of versions).  A
                  policy is a function from history to a set of
                  histories.  This is very elegant.  Shows how to
                  encode reachability and traffic isolation as simple
                  formulas that are checked for equivalence with 0.
                  They provide a compiler to OpenFlow (of a subset of
                  the language that does not include the topology
                  information) by converting a a normal form where
                  each policy belongs to a separate switch.}
}

@inproceedings{reitblatt-hotsdn13,
  author =       {Reitblatt, Mark and Canini, Marco and Guha, Arjun
                  and Foster, Nate},
  title =        {{FatTire}: Declarative Fault Tolerance for
                  Software-Defined Networks},
  year =         2013,
  url =          {https://doi.org/10.1145/2491185.2491187},
  abstract =     {This paper presents FatTire, a new language for
                  writing fault-tolerant network programs. The central
                  feature of this language is a new programming
                  construct based on regular expressions that allows
                  developers to specify the set of paths that packets
                  may take through the network as well as the degree
                  of fault tolerance required. This construct is
                  implemented by a compiler that targets the
                  in-network fast-failover mechanisms provided in
                  recent versions of the OpenFlow standard, and
                  facilitates simple reasoning about network programs
                  even in the presence of failures. We describe the
                  design of FatTire, present algorithms for compiling
                  FatTire programs to OpenFlow switch configurations,
                  describe our prototype FatTire implementation, and
                  demonstrate its use on simple examples.},
  booktitle =    {ACM SIGCOMM Workshop on Hot Topics in Software
                  Defined Networking (HotSDN)},
  pages =        {109–114},
  numpages =     6,
  keywords =     {netcore, openflow, fast failover, frenetic, fault
                  tolerance},
  location =     {Hong Kong, China},
  url =          {http://www.cs.cornell.edu/~jnfoster/papers/frenetic-fattire.pdf},
  comments =     {Programs correct even during fault recovery.  Built
                  on top of NetCore.  Reactive installation of new
                  rules is too slow and may go through inconsistent
                  states.  Compiled to special OpenFlow constructs
                  called Fast Failover group tables.  Regular
                  expressions describe paths; a path can have a "with
                  N" construct indicating number of failed links is
                  must tolerate.  Seems to need to know topology at
                  compilation time to compute alternate paths.
                  Evaluated in mininet only.}
}

@InProceedings{vollemy-padl11,
  author =       "Voellmy, Andreas and Hudak, Paul",
  editor =       "Rocha, Ricardo and Launchbury, John",
  title =        "{Nettle}: Taking the Sting Out of Programming Network
                  Routers",
  booktitle =    "Practical Aspects of Declarative Languages",
  year =         2011,
  address =      "Berlin, Heidelberg",
  pages =        "235--249",
  abstract =     "We describe a language-centric approach to solving
                  the complex, low-level, and error-prone problem of
                  network control. Specifically, we have designed a
                  domain-specific language called Nettle, embedded in
                  Haskell, that allows programming OpenFlow networks
                  in an elegant, declarative style. Nettle is based on
                  the principles of functional reactive programming
                  (FRP), and as such has both continuous and discrete
                  abstractions, each of which is leveraged in the
                  design. We have implemented Nettle and tested it on
                  real OpenFlow switches. We demonstrate our
                  methodology by writing several non-trivial OpenFlow
                  controllers.",
  url =          {https://www.cs.duke.edu/courses/fall13/cps296.4/838-CloudPapers/Nettle.pdf},
  comments =     {"Don't configure the network, program it!"  On top
                  of Nettle they plan a family of DSLs for various
                  functions: access control, traffic enginnering, etc.
                  Streams of events; continuous measured magnitudes
                  (e.g. traffic volume on each link) are the problem
                  of control.  The main abstraction is similar to
                  circuits.  Signals are sampled into event streams.
                  Signal functions manipulate signals; accumulators
                  are possible.  Streams can be of OpenFlow commands.
                  Timer events allow controllers initiate periodic
                  queries to switches.  Programs seem to be customized
                  for a specific topology.}
}

@inproceedings{Hinrichs-wren09,
  author =       {Hinrichs, Timothy L. and Gude, Natasha S. and
                  Casado, Martin and Mitchell, John C. and Shenker,
                  Scott},
  title =        {Practical Declarative Network Management},
  booktitle =    {Workshop on Research on Enterprise Networking
                  (WREN)},
  year =         2009,
  location =     {Barcelona, Spain},
  pages =        {1--10},
  doi =          {http://doi.acm.org/10.1145/1592681.1592683},
  abstract =     {We present Flow-based Management Language (FML), a
                  declarative policy language for managing the
                  configuration of enterprise networks. FML was
                  designed to replace the many disparate configuration
                  mechanisms traditionally used to enforce policies
                  within the enterprise. These include ACLs, VLANs,
                  NATs, policy-routing, and proprietary admission
                  control systems. FML balances the desires to express
                  policies naturally and enforce policies
                  efficiently. We have implemented FML and have used
                  it to manage multiple operational enterprise
                  networks for over a year.},
  comments =     {Uses DB to synchronize network state.  Actuators are
                  written in C++.  Based on Datalog, no recursion, but
                  has negation.  State is read-only.  Built as a
                  policy language for NOX.  Policies per flow.  All
                  objects authenticated.  Same actions (Datalog
                  relations) as Ethane: allow, deny, waypoint, avoid.
                  May make SQL queries to retrieve some data from a
                  DB.  The four relations are ordered deny > waypoint,
                  etc.  Users can also add new orderings over
                  policies.  They use it for access control, quality
                  of service, NATs, and admission control.  Special
                  predicates to control QoS: latency, jitter,
                  bandwidth.  NAT uses a predicate that sets some
                  header fields.  Runtime in C++, compilation in
                  Python.  Routing is done through an external
                  library.  Evaluation is sped-up using a decision
                  tree on the 8 flow attributes to decide which rules
                  to evaluate.  Was deployed.  Work/flow is roughly
                  (log_2 rules).},
}

@Misc{arista-eos,
  author =       {Arista},
  title =        {{EOS}: The Next Generation Extensible Operating
                  System},
  howpublished = {https://www.arista.com/assets/data/pdf/EOSWhitepaper.pdf},
  year =         2016,
  abstract =     {Performance, resiliency and programmability across
                  the entire network are now fundamental business
                  requirements for next generation cloud and
                  enterprise data center networks. The need for
                  agility and deployment at scale with regards to
                  provisioning and network operations requires a new
                  level of automation and integration with current
                  data center infrastructure. The underlying design of
                  the network operating system provides the
                  architectural foundation to meet these requirements.
                  Arista Networks has designed and delivered EOS
                  (Extensible Operating System), the industry-leading,
                  Linux- based network operating system, to address
                  these requirements. EOS is a robust, programmable
                  and innovative operating system, featuring a single
                  software image that runs across the entire portfolio
                  of Arista’s award-winning network switches as well
                  as in a virtual machine instance (vEOS). This
                  guarantees consistent operations, workflow
                  automation and high availability, while
                  significantly reducing data center operational
                  expenses.  This whitepaper discusses current network
                  operating systems and explains how Arista’s EOS
                  architecture uniquely support next generation data
                  centers.},
  comments =     {Traditional switch software was monolithic, and thus
                  fragile (to crashes).  State was shared in memory.
                  System used polling (thus concurrency problems).
                  Isolation through processes; pub/sub DB model.
                  Inter-process coordinator is SysDB = in-memory DB
                  storing the entire system state; notifies processes
                  about changes.  Processes (agents) have only soft
                  state.  Every process (including drivers) run in
                  user space.  Even user agents are isolated.  Network
                  telemetry is in SysDB as well.}
}

@inproceedings{voellmy-sigcomm13,
  author =       {Voellmy, Andreas and Wang, Junchang and Yang, Y
                  Richard and Ford, Bryan and Hudak, Paul},
  title =        {{Maple}: Simplifying {SDN} Programming Using
                  Algorithmic Policies},
  booktitle =    SIGCOMM,
  year =         2013,
  location =     {Hong Kong, China},
  pages =        {87--98},
  url =          {http://doi.acm.org/10.1145/2486001.2486030},
  abstract =     {Software-Defined Networking offers the appeal of a
                  simple, centralized programming model for managing
                  complex networks. However, challenges in managing
                  low-level details, such as setting up and
                  maintaining correct and efficient forwarding tables
                  on distributed switches, often compromise this
                  conceptual simplicity. In this pa- per, we present
                  Maple, a system that simplifies SDN programming by
                  (1) allowing a programmer to use a standard
                  programming language to design an arbitrary,
                  centralized algorithm, which we call an algorithmic
                  policy, to decide the behaviors of an entire
                  network, and (2) providing an abstraction that the
                  programmer-defined, centralized policy runs,
                  conceptually, "afresh" on every packet entering a
                  network, and hence is oblivious to the challenge of
                  translating a high-level policy into sets of rules
                  on distributed individual switches. To implement
                  algorithmic policies efficiently, Maple includes not
                  only a highly-efficient multicore scheduler that can
                  scale efficiently to controllers with 40+ cores, but
                  more importantly a novel tracing runtime optimizer
                  that can automatically record reusable policy
                  decisions, offload work to switches when possible,
                  and keep switch flow tables up-to-date by
                  dynamically tracing the dependency of policy
                  decisions on packet contents as well as the
                  environment (system state). Evaluations using real
                  HP switches show that Maple optimizer reduces HTTP
                  connection time by a factor of 100 at high
                  load. During simulated benchmarking, Maple
                  scheduler, when not running the optimizer, achieves
                  a throughput of over 20 million new flow requests
                  per second on a single machine, with 95-percentile
                  latency under 10 ms.},
  url =           {http://conferences.sigcomm.org/sigcomm/2013/papers/sigcomm/p87.pdf},
  comments =      {Write one function that intercepts all packets,
                  then JIT it to be much more efficient.  f: Packet x
                  Env -> ForwardingPath.  ForwardingPath may be a tree
                  for multicast.  Implementation similar to a trace
                  cache.  Builds a trace tree: decision tree with
                  nodes indicating fields accessed and leaf is
                  outcome; a tree is a collection of merged traces;
                  each packet generates one trace.  Maintain one tree
                  per switch.  Tree is compiled to OF using a simple
                  in-order recursive traversal; negation in OF is not
                  supported, so it is implemented using priorities.
                  Functions can access Environment too.  Changes to
                  environment can invalidate trees; invalidation seems
                  to be manual (manually choose which parts of trees
                  have to be invalidate).  Highly parallel controller.
                  Various optimizations with correctness arguments.
                  Compilation of tree to OF is incremental.
                  Optimizations can be topology-dependant (not obvious
                  to me that that's safe.)}
}

@article{tennenhouse-cm97,
  author =       {Tennenhouse, D. L. and Smith, J. M. and Sincoskie,
                  W. D. and Wetherall, D. J. and Minden, G. J.},
  title =        {A Survey of Active Network Research},
  year =         1997,
  issue_date =   {January 1997},
  volume =       35,
  number =       1,
  issn =         {0163-6804},
  url =          {https://doi.org/10.1109/35.568214},
  abstract =     {Active networks are a novel approach to network
                  architecture in which the switches (or routers) of
                  the network perform customized computations on the
                  messages flowing through them. This approach is
                  motivated by both lead user applications, which
                  perform user-driven computation at nodes within the
                  network today, and the emergence of mobile code
                  technologies that make dynamic network service
                  innovation attainable. The authors discuss two
                  approaches to the realization of active networks and
                  provide a snapshot of the current research issues
                  and activities. They illustrate how the routers of
                  an IP network could be augmented to perform such
                  customized processing on the datagrams flowing
                  through them. These active routers could also
                  interoperate with legacy routers, which
                  transparently forward datagrams in the traditional
                  manner},
  journal =      {Comm. Mag.},
  month =        jan,
  pages =        {80–86},
  numpages =     7,
  url =          {http://www.ecs.umass.edu/ece/wolf/courses/ECE697J/Fall2002/papers/AN_survey_AN_research.pdf},
  comments =     {Started in 1994.  Two forms: programmable switches
                  pull programs from a separate source.  Capsules
                  contain miniature programs in packets.  New
                  applications that rely on: network-based merging of
                  information; user-aware network protection; and
                  active network management.  Applications make sense,
                  but solution does not.  Programs may manipulate
                  packets, environment, network, packet flow.  A list
                  of academic efforts.}
}

@TechReport{zheng-tr11,
  author =       {Zheng Cai and Alan L. Cox and T. S. Eugene Ng},
  title =        {{Maestro}: Balancing Fairness, Latency and
                  Throughput in the OpenFlow Control Plane},
  institution =  {Rice University},
  year =         2011,
  key =          {TR11-07},
  url =          {http://www.cs.rice.edu/~eugeneng/papers/Maestro-TR11.pdf},
  abstract =     {The fundamental feature of an OpenFlow network is
                  that the controller is responsible for the
                  configuration of switches for every traffic
                  flow. This feature brings programmability and
                  flexibility, but also puts the controller in a
                  critical role in the performance of an OpenFlow
                  network. To fairly service requests from different
                  switches, to achieve low request-handlinglatency,
                  and to scale effectively on multi-core processors
                  are fundamental controller design requirements. With
                  these require- ments in mind, we explore multiple
                  workload distribution designs within our system
                  called Maestro. These designs are evaluated against
                  the requirements, together with the static
                  partitioning and static batching design foundin
                  otheravailable multi-threadedcontrollers,NOX and
                  Beacon. We find that a Maestro design based on the
                  abstraction that each individual thread services
                  switches in a round-robin manner can achieve
                  excellent throughput scalability (second only to
                  another Maestro design) while maintaining far
                  superior and near optimal max-min fairness. At the
                  same time, low latency even at high throughput is
                  achieved thanks to Maestro’s workload adaptive
                  request batching.},
 comments =      {This paper is about making the centralized
                  controller fast and fair.  Not relevant to
                  this paper.}
}

@inproceedings {campbell-nsdi21,
  author =       {Eric Hayden Campbell and William T. Hallahan and
                  Priya Srikumar and Carmelo Cascone and Jed Liu and
                  Vignesh Ramamurthy and Hossein Hojjat and Ruzica
                  Piskac and Robert Soul{\'e} and Nate Foster},
  title =        {{Avenir}: Managing Data Plane Diversity with Control
                  Plane Synthesis},
  booktitle =    NSDI,
  year =         2021,
  url =          {https://www.usenix.org/conference/nsdi21/presentation/campbell},
  publisher =    {{USENIX} Association},
  month =        apr,
  abstract =     {The classical conception of software-defined
                  networking (SDN) is based on an attractive myth: a
                  logically centralized controller manages a
                  collection of homogeneous data planes. In reality,
                  however, SDN control planes must deal with
                  significant diversity in hardware, drivers,
                  interfaces, and protocols, all of which contribute
                  to idiosyncratic differences in forwarding behavior
                  that must be dealt with by hand.  To manage this
                  heterogeneity, we propose Avenir, a synthesis tool
                  that automatically generates control-plane
                  operations to ensure uniform behavior across a
                  variety of data planes. Our approach uses
                  counter-example guided inductive synthesis and
                  sketching, adding network-specific optimizations
                  that exploit domain insights to accelerate the
                  search. We prove that Avenir's synthesis algorithm
                  generates correct solutions and always finds a
                  solution, if one exists. We have built a prototype
                  implementation of Avenir using OCaml and Z3 and
                  evaluated its performance on realistic scenarios for
                  the ONOS SDN controller and on a collection of
                  benchmarks that illustrate the cost of retargeting a
                  control plane from one pipeline to another. Our
                  evaluation demonstrates that Avenir can manage data
                  plane heterogeneity with modest overheads.},
  comments =     {"automatically translates control plane operations
                  written against an abstract forwarding specification
                  into lower-level operations for a physical target."
                  P4 is the dataplane specification language, used to
                  describe a pipeline.  You write a full program for
                  an ideal pipeline and a program with holes for the
                  target pipeline and the compiler fills the holes.
                  Configurations are changed incrementally (but there
                  is no incremental view maintenance procedure).
                  Assumes identical fixed parsers.  Control plane
                  fills tables in the idealized pipeline, the system
                  generates table contents for the target pipeline
                  such that the two programs are equivalent.
                  Heuristics are very important for making the system
                  really work.}
}

@article{feamster-ccr14,
  author =       {Feamster, Nick and Rexford, Jennifer and Zegura,
                  Ellen},
  title =        {The Road to {SDN}: An Intellectual History of
                  Programmable Networks},
  year =         2014,
  issue_date =   {April 2014},
  volume =       44,
  number =       2,
  url =          {https://doi.org/10.1145/2602204.2602219},
  url =          {https://www.cs.princeton.edu/courses/archive/fall13/cos597E/papers/sdnhistory.pdf},
  abstract =     {Software Defined Networking (SDN) is an exciting
                  technology that enables innovation in how we design
                  and manage networks. Although this technology seems
                  to have appeared suddenly, SDN is part of a long
                  history of efforts to make computer networks more
                  programmable. In this paper, we trace the
                  intellectual history of programmable networks,
                  including active networks, early efforts to separate
                  the control and data plane, and more recent work on
                  OpenFlow and network operating systems. We highlight
                  key concepts, as well as the technology pushes and
                  application pulls that spurred each
                  innovation. Along the way, we debunk common myths
                  and misconceptions about the technologies and
                  clarify the relationship between SDN and related
                  technologies such as network virtualization.},
  journal =      CCR,
  month =        apr,
  pages =        {87–98},
  numpages =     12,
  keywords =     {programmable networking, network virtualization,
                  software defined networking},
  comments =     {A survey of early research on SDN.}
}

@inproceedings {koponen-nsdi14,
  author =       {Teemu Koponen and Keith Amidon and Peter Balland and
                  Martin Casado and Anupam Chanda and Bryan Fulton and
                  Igor Ganichev and Jesse Gross and Paul Ingram and
                  Ethan Jackson and Andrew Lambeth and Romain Lenglet
                  and Shih-Hao Li and Amar Padmanabhan and Justin
                  Pettit and Ben Pfaff and Rajiv Ramanathan and Scott
                  Shenker and Alan Shieh and Jeremy Stribling and
                  Pankaj Thakkar and Dan Wendlandt and Alexander Yip
                  and Ronghua Zhang},
  title =        {Network Virtualization in Multi-tenant Datacenters},
  booktitle =    NSDI,
  year =         2014,
  address =      {Seattle, WA},
  pages =        {203--216},
  url =          {https://www.usenix.org/conference/nsdi14/technical-sessions/presentation/koponen},
  month =        apr,
  abstract =     {Multi-tenant datacenters represent an extremely
                  challenging networking environment. Tenants want the
                  ability to migrate unmodified workloads from their
                  enterprise networks to service provider datacenters,
                  retaining the same networking configurations of
                  their home network. The service providers must meet
                  these needs without operator intervention while
                  preserving their own operational flexibility and
                  efficiency. Traditional networking approaches have
                  failed to meet these tenant and provider
                  requirements. Responding to this need, we present
                  the design and implementation of a network
                  virtualization solution for multi-tenant
                  datacenters.},
  comments =     {"build our architecture around a network
                  hypervisor."  "Provides control planes with a
                  control abstraction and VMs with a packet
                  abstraction."  Logical datapath implemented in
                  software switches.  Pairs of tunnels between every
                  hypervisor pair.  Central SDN controller configures
                  the virtual switches at each endpoint.  Tunnels are
                  good for point-to-point communication, but broadcast
                  and multicast need additional support.  They build a
                  multicast overlay using service nodes.  Can also
                  broadcast directly throguh all tunnels.  Gateweays
                  can connect the logical network with a physical one.
                  Virtual switches (OvS) are called "network edge".
                  Two OvS protocols: manage flow tables, and manage
                  overlay tunnels and VMs.  Each OvS has a pipeline of
                  tables (not just one table).  Learning is done
                  through actions that can insert tabl entries.
                  Encapsulation interferes with hw offloading -- so
                  they trick the NIC by inserting some fake TCP
                  headers before the encapsulated headers.  Broacast
                  traffic is load-balanced using ECMP to replicated
                  appliances/gateways for reliability; hypervisors act
                  as failure detectors for the appliances.  Controller
                  is written in Nlog.  The OvS configuration protocol
                  gives vNIC location information and MAC addresses to
                  controller; controller computes logical fw tables.
                  Controller does not process any packets; this also
                  ensures connectivity when controller is transiently
                  lost.  123 input types, 81 output types in
                  controller.  State is large, and it frequently
                  changes.  Nlog is not exposed to users except
                  through APIs.  Nlog is incrementally evaluated; 1200
                  declarations and 900 tables.  No negation,
                  recursion; most functions are extern C++ functions.
                  Parallelized using sharding.  Two-level controller
                  hierarchy; top level (logical) compute abstract
                  paths, bottom level (physical) fill in configuration
                  as OpenFlow.  Controller has hot standbys.  Built on
                  top of ONIX and the ONIX DB to keep state.
                  Zookeeper for leader election.  Zookeeper also used
                  to allocate GUIDs.  Huge resource requirements.
                  Cold start takes 1 hour!}
}


@inproceedings{rahman-im11,
  title =        {A declarative approach for global network security
                  configuration verification and evaluation},
  author =       {Rahman, Mohammad Ashiqur and Al-Shaer, Ehab},
  booktitle =    {IFIP/IEEE International Symposium on Integrated
                  Network Management (IM 2011)},
  pages =        {531--538},
  year =         2011,
  organization = {IEEE},
  url =          {https://acyd.fiu.edu/wp-content/uploads/A-Declarative-Approach-for-Global-Network-Security-Configuration-Verification-and-Evaluation.pdf},
  abstract =     {With the increasing number of security devices and
                  rules in the network, the complexity of detecting
                  and tracing network security configuration errors
                  become a very challenging task. This in turn
                  increases the potential of security breaches due to
                  rule conflicts, requirement violations or lack of
                  security hardening. Most of the existing tools are
                  either limited in scope as they do not offer a
                  global analysis of different network devices or hard
                  to comprehensively use because these tools are not
                  declarative. Declarative logic programming can
                  readily express network configurations and security
                  requirements for verification analysis. In this
                  paper, we use Prolog to model the entire network
                  security configurations including topology, routing,
                  firewall and IPSec. This is implemented in a tool
                  called ConfigAnalyzer, which was also evaluated with
                  large network and policy sizes. The tool allows for
                  verifying reachability and security properties in
                  flexible and expressive manner. It also allows for
                  evaluating security configurations in terms of
                  accessibilities credentials and rules.},
  comments =     {Multiple security policies in network must be
                  consistent (.e.g firewalls, IPsec, routing).  Write
                  queries to find backdoors that can bypass firewalls,
                  compatible IPsec policies, reachable subnets.  They
                  evaluate query time as a function of the network
                  size.}
}

@inproceedings{sherwood-osdi10,
  author =       {Sherwood, Rob and Gibb, Glen and Yap, Kok-Kiong and
                  Appenzeller, Guido and Casado, Martin and McKeown,
                  Nick and Parulkar, Guru},
  title =        {Can the Production Network Be the Testbed?},
  year =         2010,
  abstract =     {A persistent problem in computer network research is
                  validation. When deciding how to evaluate a new
                  feature or bug fix, a researcher or operator must
                  trade-off realism (in terms of scale, actual user
                  traffic, real equipment) and cost (larger scale
                  costs more money, real user traffic likely requires
                  downtime, and real equipment requires vendor
                  adoption which can take years). Building a realistic
                  testbed is hard because "real" networking takes
                  place on closed, commercial switches and routers
                  with special purpose hardware. But if we build our
                  testbed from software switches, they run several
                  orders of magnitude slower. Even if we build a
                  realistic network testbed, it is hard to scale,
                  because it is special purpose and is in addition to
                  the regular network. It needs its own location,
                  support and dedicated links. For a testbed to have
                  global reach takes investment beyond the reach of
                  most researchers.In this paper, we describe a way to
                  build a testbed that is embedded in--and thus grows
                  with--the network. The technique--embodied in our
                  first prototype, FlowVisor--slices the network
                  hardware by placing a layer between the control
                  plane and the data plane. We demonstrate that
                  FlowVisor slices our own production network, with
                  legacy protocols running in their own protected
                  slice, alongside experiments created by
                  researchers. The basic idea is that if unmodified
                  hardware supports some basic primitives (in our
                  prototype, Open-Flow, but others are possible), then
                  a worldwide testbed can ride on the coat-tails of
                  deployments, at no extra expense. Further, we
                  evaluate the performance impact and describe how
                  FlowVisor is deployed at seven other campuses as
                  part of a wider evaluation platform.},
  booktitle =    OSDI,
  pages =        {365–378},
  numpages =     14,
  location =     {Vancouver, BC, Canada},
  url =          {https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Sherwood.pdf},
  comments =     {Slice network hardware.  User-defined control-plane
                  running on deployed production hardware.  VLANs do
                  not control the forwarding plane.  Slices are
                  isolated from each other.  Real deployment.
                  FlowVisor intercepts the control-plane to data-plane
                  communication, enabling a single data plane to be
                  controlled by multiple control planes.  Slices have
                  separate topology, bandwidth, device CPU, forwarding
                  entries quotas.  Users "opt-in" to a slice by
                  registering some set of flows.  A flowspace is
                  defined like firewall rules.  Messages to the
                  controller are filtered based on topology.  OpenFlow
                  rules down from controller are interestected with
                  the slice definition.  Bandwidth is isolated using
                  per-slice per port queues.  Rate-limits NewFlow
                  messages to prevent CPU starvation.  Implemented on
                  top of NOX.  A network-level hypervisor.}
}

@inproceedings{Voellmy-hotsdn12,
  author =       {Voellmy, Andreas and Kim, Hyojoon and Feamster,
                  Nick},
  title =        {{Procera}: A Language for High-Level Reactive
                  Network Control},
  year =         2012,
  url =          {https://doi.org/10.1145/2342441.2342451},
  abstract =     {Our previous experience building systems for
                  implementing network policies in home and enterprise
                  networks has revealed that the intuitive notion of
                  network policy in these domains is inherently
                  dynamic and stateful. Current configuration
                  languages, both in traditional network architectures
                  and in OpenFlow systems, are not expressive enough
                  to capture these policies. As a result, most
                  prototype OpenFlow systems lack a configurable
                  interface and instead require operators to program
                  in the system implementation language, often C++. We
                  describe Procera, a control architecture for
                  software-defined networking (SDN) that includes a
                  declarative policy language based on the notion of
                  functional reactive programming; we extend this
                  formalism with both signals relevant for expressing
                  high-level network policies in a variety of network
                  settings, including home and enterprise networks,
                  and a collection of constructs expressing temporal
                  queries over event streams that occur frequently in
                  network policies. Although sophisticated users can
                  take advantage of Procera's full expressiveness by
                  expressing network policies directly in Procera,
                  simpler configuration interfaces (e.g., graphical
                  user interfaces) can also easily be built on top of
                  this formalism.},
  booktitle =    HotSDN,
  url =          {http://conferences.sigcomm.org/sigcomm/2012/paper/hotsdn/p43.pdf},
  pages =        {43–48},
  numpages =     6,
  keywords =     {software-defined networking, functional reactive
                  programming, haskell, network configuration,
                  openflow},
  location =     {Helsinki, Finland},
  comments =     {Based on functional reactive programming.  Very
                  similar to Nettle, although the paper claims that
                  Nettle is a controller.  Supports windowing and
                  aggregation.  Core construct is a function that
                  computes flow constraints as a function of the world
                  "signals".  Can express complex policies, like data
                  usage caps.  The paper does not have an
                  implementation section; that is left as future
                  work.}
}

@InProceedings{alvaro-datalog11,
  author =       "Alvaro, Peter and Marczak, William R.  and Conway,
                  Neil and Hellerstein, Joseph M.  and Maier, David
                  and Sears, Russell",
  title =        "{Dedalus}: {Datalog} in Time and Space",
  booktitle =    "Datalog Reloaded",
  year =         2011,
  publisher =    "Springer Berlin Heidelberg",
  address =      "Berlin, Heidelberg",
  pages =        "262--281",
  abstract =     "Recent research has explored using Datalog-based
                  languages to express a distributed system as a set
                  of logical invariants. Two properties of distributed
                  systems proved difficult to model in Datalog. First,
                  the state of any such system evolves with its
                  execution. Second, deductions in these systems may
                  be arbitrarily delayed, dropped, or reordered by the
                  unreliable network links they must
                  traverse. Previous efforts addressed the former by
                  extending Datalog to include updates, key
                  constraints, persistence and events, and the latter
                  by assuming ordered and reliable delivery while
                  ignoring delay. These details have a semantics
                  outside Datalog, which increases the complexity of
                  the language and its interpretation, and forces
                  programmers to think operationally. We argue that
                  the missing component from these previous languages
                  is a notion of time.  In this paper we present
                  Dedalus, a foundation language for programming and
                  reasoning about distributed systems. Dedalus reduces
                  to a subset of Datalog with negation, aggregate
                  functions, successor and choice, and adds an
                  explicit notion of logical time to the language. We
                  show that Dedalus provides a declarative foundation
                  for the two signature features of distributed
                  systems: mutable state, and asynchronous processing
                  and communication. Given these two features, we
                  address two important properties of programs in a
                  domain-specific manner: a notion of safety
                  appropriate to non-terminating computations, and
                  stratified monotonic reasoning with negation over
                  time. We also provide conservative syntactic checks
                  for our temporal notions of safety and
                  stratification. Our experience implementing
                  full-featured systems in variants of Datalog
                  suggests that Dedalus is well-suited to the
                  specification of rich distributed services and
                  protocols, and provides both cleaner semantics and
                  richer tests of correctness.",
  url =          {http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf},
  comments =     {Declarative programming for distributed systems.
                  Successor relation models time.  Time is an explicit
                  attribute of a relation.  Deductive rule = same
                  time, inductive rule = successor time.  Syntactic
                  sugar for these, using @next attached to a head to
                  indicate inductive rule.  Allow "timestamped" facts.
                  Cannot join across different times.  Persistent
                  rules are valid at all times.  Mutable state: facts
                  are removed in time.  Add counters, queues.
                  Deductively stratifiable => has a perfect model.
                  There are no "cycles" in time.  Some programs are
                  quiescent: after some time they derive no new facts.
                  Add a non-deterministic "choice" construct.  Also
                  add "location" like Loo's work.  Add "async" to
                  indicate that something happens at an unspecified
                  time (possibly never).  Nice collection of related
                  work with dialects of Datalog.  Discusses Overlog
                  execution model using a "chain of fixedpoints"; but
                  Overlog semantics is not well-specified.}
}

@inproceedings{alvaro-cidr11,
  title =        {Consistency Analysis in {Bloom}: a {CALM} and
                  Collected Approach},
  author =       {Alvaro, Peter and Conway, Neil and Hellerstein,
                  Joseph M and Marczak, William R},
  booktitle =    CIDR,
  pages =        {249--260},
  year =         2011,
  url =          {http://db.cs.berkeley.edu/papers/cidr11-bloom.pdf},
  note =         {http://bloom-lang.net/features/},
  comments =     {Distributed programming has become a topic of
                  widespread interest, and many programmers now
                  wrestle with tradeoffs between data consistency,
                  availability and latency. Distributed transactions
                  are often rejected as an undesirable tradeoff today,
                  but in the absence of transactions there are few
                  concrete principles or tools to help programmers
                  design and verify the correctness of their
                  applications.  We address this situation with the
                  CALM principle, which connects the idea of
                  distributed consistency to program tests for logical
                  monotonicity. We then introduce Bloom, a distributed
                  programming language that is amenable to high-level
                  consistency analysis and encourages
                  order-insensitive programming. We present a
                  prototype implementation of Bloom as a
                  domain-specific language in Ruby.  We also propose a
                  program analysis technique that identifies points of
                  order in Bloom programs: code locations where
                  programmers may need to inject coordination logic to
                  ensure consistency. We illustrate these ideas with
                  two case studies: a simple key-value store and a
                  distributed shopping cart service.},
  comments =     {Based on Dedalus alvaro-datalog11, a form of
                  Datalog.  Not really about networks.  Non-monotonic
                  programs (negation or aggregation) require blocking
                  and do not provide eventual consistency.  "Counting
                  requires waiting."  Waiting = coordination.
                  "Monotonic programs guarantee eventual consistency
                  under any interleaving of delivery and computation."
                  Base types are Ruby types, including collections.
                  Table collections are integrated, scratch
                  collections are streams.  Language reuses Ruby
                  collections and class inheritance.  Bud is itself
                  implemented in Ruby.  Communication is done through
                  collections: write to one, look for result in
                  another.}
}

@inproceedings{volpano-hotsdn14,
  author =       {Volpano, Dennis M. and Sun, Xin and Xie, Geoffrey
                  G.},
  title =        {Towards Systematic Detection and Resolution of
                  Network Control Conflicts},
  year =         2014,
  url =          {https://doi.org/10.1145/2620728.2620745},
  abstract =     {The problem of detecting and resolving control
                  conflicts has started to receive attention from the
                  networking community. Corybantic is an example of
                  recent work in this area. We argue that it is too
                  coarse grain in that it does not model the combined
                  operational objectives of multiple controller
                  functions. This paper proposes a finer grain
                  approach where a network control function is
                  represented as a deterministic finite-state
                  transducer. The machine runs on inputs provided by
                  an SDN controller and outputs instructions that
                  update the network as needed to meet
                  objectives. Standard proof techniques and algorithms
                  can be leveraged to analyze properties of these
                  machines. Specifically, their intersection describes
                  precisely the stable operating region of a network
                  when the machines operate in parallel. The e region
                  comprises conditions under which no control function
                  is in the process of updating the network.},
  booktitle =    {Workshop on Hot Topics in Software Defined
                  Networking (HotSDN)},
  pages =        {67–72},
  numpages =     6,
  keywords =     {SDN, transducers, controller function interaction},
  location =     {Chicago, Illinois, USA},
  url =          {https://core.ac.uk/download/pdf/36738276.pdf},
  comments =     {Assumes a "clock" defining transition times.  A
                  problem is that these product automata can be very
                  large and hard to interpret.  They do not seem to
                  actually solve the problem of stability that they
                  motivate with.}
}

@inproceedings{kazemian-nsdi13,
  author =       {Peyman Kazemian and Michael Chang and Hongyi Zeng
                  and George Varghese and Nick McKeown and Scott
                  Whyte},
  title =        {Real Time Network Policy Checking Using Header Space
                  Analysis},
  booktitle =    NSDI,
  year =         2013,
  address =      {Lombard, IL},
  pages =        {99--111},
  url =          {https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/kazemian},
  month =        apr,
  abstract =     {Network state may change rapidly in response to
                  customer demands, load conditions or conﬁguration
                  changes. But the network must also ensure
                  correctness conditions such as isolating tenants
                  from each other and from critical services. Existing
                  policy checkers cannot verify compliance in real
                  time because of the need to collect “state” from the
                  entire network and the time it takes to analyze this
                  state. SDNs provide an opportunity in thisrespect as
                  they provide a logically centralized view from which
                  every proposed change can be checked for compliance
                  with policy. But there remains the need for a fast
                  compliance checker.  Our paper introduces a real
                  time policy checking tool called NetPlumber based on
                  Header Space Analysis (HSA). Unlike HSA, however,
                  NetPlumber incrementally checks for compliance of
                  state changes, using a novel set of conceptual tools
                  that maintain a dependency graph between
                  rules. While NetPlumber is a natural ﬁt for SDNs,
                  its abstract intermediate form is conceptually
                  applicable to conventional networks as well. We have
                  tested NetPlumber on Google’s SDN, the Stanford
                  backbone and Internet 2. With NetPlumber, checking
                  the compliance of a typical rule update against a
                  single policy on these networks takes 50-500s on
                  average.},
  comments =     {This is not the original HSA paper.  It is just an
                  incremental version of it.  NetPlumber intercepts OF
                  messages, and also needs the network topology.  Uses
                  a policy specification language FlowExp based on
                  regular expressions, like FML.  Inject an
                  "all-wildcad" flow at some switch and see what is
                  reached.  Switches apply a "transfer function".
                  Bidirectional processing.  FlowExp checks
                  constraints on the full path (history) traversed by
                  a flow.  Expose language to users through a Prolog
                  wrapper.  Parellelize on clusters of related rules.
                  Evaluated on some very large networks.}
}

@inproceedings{berde-hotsdn14,
  author =       {Berde, Pankaj and Gerola, Matteo and Hart, Jonathan
                  and Higuchi, Yuta and Kobayashi, Masayoshi and
                  Koide, Toshio and Lantz, Bob and O'Connor, Brian and
                  Radoslavov, Pavlin and Snow, William and Parulkar,
                  Guru},
  title =        {{ONOS}: Towards an Open, Distributed {SDN} {OS}},
  year =         2014,
  url =          {https://doi.org/10.1145/2620728.2620744},
  abstract =     {We present our experiences to date building ONOS
                  (Open Network Operating System), an experimental
                  distributed SDN control platform motivated by the
                  performance, scalability, and availability
                  requirements of large operator networks. We describe
                  and evaluate two ONOS prototypes. The first version
                  implemented core features: a distributed, but
                  logically centralized, global network view;
                  scale-out; and fault tolerance. The second version
                  focused on improving performance. Based on
                  experience with these prototypes, we identify
                  additional steps that will be required for ONOS to
                  support use cases such as core network traffic
                  engineering and scheduling, and to become a usable
                  open source, distributed network OS platform that
                  the SDN community can build upon.},
  booktitle =    {Workshop on Hot Topics in Software Defined
                  Networking (HotSDN)},
  pages =        {1–6},
  numpages =     6,
  keywords =     {onos, openflow, controller, distributed controller,
                  sdn, software defined networking, network operating
                  system},
  location =     {Chicago, Illinois, USA},
  comments =     {Follows ONIX, but is O/S.  Identified requirements:
                  high throughput, low latency, global network size,
                  high availability.  First version based on
                  Floodlight controller, Titan graph DB, Cassandra.
                  Distibuted controllers: each for a set of switches,
                  their views are merged in a single DB, Zookeeper for
                  master election; each switch talks to multiple
                  controllers, but only one master in each group.  DB
                  is passive, and not used for control.  Initial
                  version was slow.  Second version used RAMCloud.
                  Added notifications to replace polling.  One table
                  per network object; no referential integrity.
                  Events for network notifications.  Has some
                  interesting benchmarks.}
}

@inproceedings{chen-conext10,
  author =       {Chen, Xu and Mao, Yun and Mao, Z. Morley and Van der
                  Merwe, Jacobus},
  title =        {Declarative Configuration Management for Complex and
                  Dynamic Networks},
  year =         2010,
  doi =          {https://doi.org/10.1145/1921168.1921176},
  url =          {http://web.eecs.umich.edu/~zmao/Papers/06-Chen.pdf},
  abstract =     {Network management and operations are complicated,
                  tedious, and error-prone, requiring signifcant human
                  involvement and domain knowledge. As the complexity
                  involved inevitably grows due to larger scale
                  networks and more complex protocol features, human
                  operators are increasingly short-handed, despite the
                  best effort from existing support systems to make it
                  otherwise. This paper presents Coolaid, a system
                  under which the domain knowledge of device vendors
                  and service providers is formally captured by a
                  declarative language. Through effcient and powerful
                  rule-based reasoning on top of a database-like
                  abstraction over a network of devices, coolaid
                  enables new management primitives to perform
                  network-wide reasoning, prevent misconfguration, and
                  automate network confguration, while requiring
                  minimum operator effort. We describe the design and
                  prototype implementation of coolaid, and demonstrate
                  its effectiveness and scalability through various
                  realistic network management tasks.},
  booktitle =    CoNEXT,
  articleno =    6,
  numpages =     12,
  location =     {Philadelphia, Pennsylvania},
  comments =     {Long motivation: knowledge about network management
                  is scattered.  Three kinds of input tables: facts,
                  configuration, status.  Rules define views,
                  formalizing domain knowledge.  The controller is a
                  database engine.  Datalog is the rule language, with
                  stratified negation and recursion.  Constraints can
                  reject incorrect updates.  Transactions that violate
                  constraints cannot commit.  Allows mutations to
                  views.  Transactions can enforce atomic updates.  To
                  invert views they use a search procedure.  Two-phase
                  commit for distributed transactions.  Implemented in
                  Python.  Wraps a Juniper router config as a database
                  RouterDB; the wrapper evaluates prepare statements
                  before participating in 2PC.  Very similar to this work.}
}

@article{Wawrzoniak-ccr04,
  author =       {Wawrzoniak, Mike and Peterson, Larry and Roscoe,
                  Timothy},
  title =        {{Sophia}: An Information Plane for Networked
                  Systems},
  year =         2004,
  volume =       34,
  number =       1,
  issn =         {0146-4833},
  url =          {https://doi.org/10.1145/972374.972378},
  abstract =     {This paper motivates and describes an example
                  network Information Plane, called Sophia, currently
                  deployed on PlanetLab. Sophia is a distributed
                  system that collects, stores, propagates,
                  aggregates, and reacts to observations about the
                  network's current conditions. Sophia's approach is
                  novel: it can be viewed as a multi-user distributed
                  expression evaluator in which sensors and actuators
                  form the ground terms, and statements take on the
                  complete expressiveness of a logic language like
                  Prolog. This paper argues that this approach has
                  several advantages in managing and controlling a
                  complex, federated, and evolving network: (1) a
                  declarative logic language provides a natural way to
                  express the kinds of statements that are common to
                  this application domain, through temporal and
                  positional logic rules, facts and expressions; and
                  (2) distributed evaluation of such logic expressions
                  provides many opportunities for performance
                  optimization yielding an efficient system.},
  journal =      {SIGCOMM Comput. Commun. Rev.},
  month =        jan,
  pages =        {15–20},
  numpages =     6,
  url =          {http://www.cs.princeton.edu/courses/archive/fall03/cs597B/handouts/pdn03-014.pdf},
  comments =     {Sensors, distributed evaluator (Prolog), actuators.
                  Location and time are explicit parts of each term.
                  Location and time are part of a an "env" predicate.
                  Time is continuous, and can be in the past.  This
                  paper is very vagues in many respects, including
                  semantics.  No measurements.}
}

@inproceedings{guha-pldi13,
  author =       {Guha, Arjun and Reitblatt, Mark and Foster, Nate},
  title =        {Machine-Verified Network Controllers},
  year =         2013,
  issn =         {0362-1340},
  doi =          {https://doi.org/10.1145/2499370.2462178},
  abstract =     {In many areas of computing, techniques ranging from
                  testing to formal modeling to full-blown
                  verification have been successfully used to help
                  programmers build reliable systems. But although
                  networks are critical infrastructure, they have
                  largely resisted analysis using formal
                  techniques. Software-defined networking (SDN) is a
                  new network architecture that has the potential to
                  provide a foundation for network reasoning, by
                  standardizing the interfaces used to express network
                  programs and giving them a precise semantics.This
                  paper describes the design and implementation of the
                  first machine-verified SDN controller. Starting from
                  the foundations, we develop a detailed operational
                  model for OpenFlow (the most popular SDN platform)
                  and formalize it in the Coq proof assistant. We then
                  use this model to develop a verified compiler and
                  run-time system for a high-level network programming
                  language. We identify bugs in existing languages and
                  tools built without formal foundations, and prove
                  that these bugs are absent from our system. Finally,
                  we describe our prototype implementation and our
                  experiences using it to build practical
                  applications.},
  booktitle =    PLDI,
  month =        jun,
  pages =        {483–494},
  numpages =     12,
  keywords =     {software-defined networking, openflow,
                  domain-specific languages, frenetic, formal
                  verification, netcore, coq},
  url =          {http://www.cs.cornell.edu/~jnfoster/papers/verified-controllers-pldi13.pdf},
  comments =     {The language is NetCore.  They verify the NetCore
                  compiler.  Compiler verified in Coq; optimizations
                  certified; translates NetCore to Flow Tables.
                  Modeled lightweight OpenFlow.  Added a notion of
                  barrier to enforce ordering of rule application at
                  devices.  Nework model includes message queues for
                  modelling delays and arbitrary orders.}
}

@inproceedings{Huebsch-vldb03,
  author =       {Huebsch, Ryan and Hellerstein, Joseph M. and Lanham,
                  Nick and Loo, Boon Thau and Shenker, Scott and
                  Stoica, Ion},
  title =        {Querying the Internet with {PIER}},
  year =         2003,
  publisher =    {VLDB Endowment},
  abstract =     {The database research community prides itself on
                  scalable technologies. Yet database systems
                  traditionally do not excel on one important
                  scalability dimension: the degree of
                  distribution. This limitation has hampered the
                  impact of database technologies on massively
                  distributed systems like the Internet. In this
                  paper, we present the initial design of PIER, a
                  massively distributed query engine based on overlay
                  networks, which is intended to bring database query
                  processing facilities to new, widely distributed
                  environments. We motivate the need for massively
                  distributed queries, and argue for a relaxation of
                  certain traditional database research goals in the
                  pursuit of scalability and widespread adoption. We
                  present simulation results showing PIER gracefully
                  running relational queries across thousands of
                  machines, and show results from the same software
                  base in actual deployment on a large experimental
                  cluster.},
  booktitle =    VLDB,
  pages =        {321–332},
  numpages =     12,
  location =     {Berlin, Germany},
  url =          {https://cs.uwaterloo.ca/~tozsu/courses/cs856/W05/Presentations/pier_wdm.pdf},
  comments =     {Built on top of DHTs.  Use for network monitoring,
                  e.g., distributed intrusion detection.  Data seems
                  to be stored in the DHT.  Only query capabilities.
                  Similar to map-reduce operations; joins redistribute
                  data.  Synthetic benchmarks (data and query).}
}

@inproceedings{renesse-iptps02,
  author =       {Renesse, Robbert van and Birman, Kenneth P. and
                  Dumitriu, Dan and Vogels, Werner},
  title =        {Scalable Management and Data Mining Using
                  {Astrolabe}},
  year =         2002,
  abstract =     {Astrolabe is a new kind of peer-to-peer system
                  implementing a hierarchical distributed database
                  abstraction. Although deigned for scalable
                  management and data mining, the system can also
                  support wide-area multicast and offers powerful
                  aggregation mechanisms that permit applications to
                  build customized virtual databases by extracting and
                  summarizing data located throughout a large
                  network. In contrast to other peer-to-peer systems,
                  the Astrolabe hierarchy is purely an abstraction
                  constructed by running our protocol on the
                  participating hosts - there are no servers, and the
                  system doesn't superimpose a specialized routing
                  infrastructure or employ a DHT. This paper focuses
                  on wide-area implementation challenges.},
  booktitle =    {Revised Papers from the First International Workshop
                  on Peer-to-Peer Systems},
  pages =        {280–294},
  numpages =     15,
  url =          {http://www.cs.cornell.edu/home/rvr/papers/ScalableManagement.pdf},
  comments =     {Seems to maintain views over distributed data.
                  Computes mainly aggregates.  Machines organized in a
                  hierarchy.  Uses gossip for communication.
                  Versioned data, per source.  Used to implement
                  multicast!  This is a terrible design.  The writing
                  is atrocious too.  No measurements.}
}

@article{caldwell-ccr04,
  author =       {Caldwell, Don and Gilbert, Anna and Gottlieb, Joel
                  and Greenberg, Albert and Hjalmtysson, Gisli and
                  Rexford, Jennifer},
  title =        {The Cutting {EDGE} of {IP} Router Configuration},
  year =         2004,
  volume =       34,
  number =       1,
  issn =         {0146-4833},
  url =          {https://doi.org/10.1145/972374.972379},
  abstract =     {Human error in configuring routers undermines
                  attempts to provide reliable, predictable end-to-end
                  performance on IP networks. Manual configuration,
                  while expensive and error-prone, is the dominant
                  mode of operation, especially for large enterprise
                  networks. These networks often lack the basic
                  building blocks---an accurate equipment inventory, a
                  debugged initial configuration, and a specification
                  of local configuration policies---to support the
                  holy grail of automation. We argue the migrating an
                  existing network to automated configuration is a
                  rich and challenging research problem rooted in data
                  analysis and in the modeling of network protocols
                  and operational practices. We propose a novel,
                  bottom-up approach that proceeds in three phases:
                  (i) analysis of configuration data to summarize the
                  existing network state and uncover configuration
                  problems; (ii) data mining to identify the network's
                  local configuration policies and violations of these
                  policies; and ultimately (iii) boot-strapping of a
                  database to drive future configuration changes. The
                  first stage reduces the number of errors, the second
                  normalizes the local policies, and the third
                  prevents new errors and reduces the manpower needed
                  to configure the network. We describe the
                  architecture of our EDGE tool for steps (i) and
                  (ii), and present some examples from our experiences
                  applying the tool to several large enterprise
                  networks.},
  journal =      CCR,
  month =        jan,
  pages =        {21–26},
  numpages =     6,
  url =          {http://nms.lcs.mit.edu/HotNets-II/papers/ip_router.pdf},
  comments =     {Manual network configuration is hard and expensive.
                  "Today" the configuration of routers is the
                  database.  Store data in database, generate
                  configuration.  The database schema is constructed
                  from existing configurations using custom Perl
                  scripts.  DB is used for web reports.  Hand-written
                  queries and data mining can detect
                  misconfigurations.}
}

@INPROCEEDINGS{sieber-netsoft16,
  author =       {Sieber, Christian and Blenk, Andreas and Basta,
                  Arsany and Hock, David and Kellerer, Wolfgang},
  booktitle =    {IEEE NetSoft Conference and Workshops (NetSoft)},
  title =        {Towards a programmable management plane for {SDN} and
                  legacy networks},
  year =         2016,
  pages =        {319-327},
  doi =          {10.1109/NETSOFT.2016.7502428},
  abstract =     {Software-defined Networking (SDN) and one of its
                  most known realization, namely OpenFlow, enabled
                  wide-spread and vendor-neutral programmability of
                  the control plane of modern network
                  equipment. However, despite research and
                  standardization efforts, the management plane is
                  still eluding device-neutral and vendor-neutral
                  programmability. Thus, innovation in the management
                  plane is hampered by a dependency on human experts,
                  domain knowledge that is hidden in human-centered
                  manuals, and the huge amount of diverse device
                  capabilities and configuration interfaces. Recent
                  proposals for vendor-neutral data-models, such as
                  OFCONF, are still lacking majority and do not
                  provide a standardized way of device capability
                  discovery and device status monitoring. Accordingly,
                  we present an architecture that provides a unified
                  interface to the management plane of heterogeneous
                  devices, i.e., SDN and legacy devices. We discuss
                  the properties of the chosen level of configuration
                  abstraction and show how applications northbound of
                  the abstraction layer are well prepared against
                  undesired side-effects of management actions. By
                  example of a popular approach for enabling Open-Flow
                  in mixed-SDN/legacy networks, i.e., Panopticon, we
                  provide a proof-of-concept implementation of the
                  proposed architecture in a real test-bed. We show
                  how a management application can use the abstraction
                  layer to discover and configure QoS options in the
                  network, monitor the devices, and prevent undesired
                  traffic interruptions in the legacy domain, while
                  being operated in parallel with an SDN controller.},
  url =          {https://mediatum.ub.tum.de/doc/1415923/1415923.pdf},
  comments =     {Network Management System (NSM) = Managment Plane.
                  Promised open/source code is missing.  This
                  architecture seems to be a mess; it mixes
                  layers/interfaces/implementations.  It puts together
                  a bunch of open-source components.  One concern is
                  planning complex activities, like upgrades.}
}

@inproceedings{Sun-sigcomm14,
  author =       {Sun, Peng and Mahajan, Ratul and Rexford, Jennifer
                  and Yuan, Lihua and Zhang, Ming and Arefin, Ahsan},
  title =        {A Network-state Management Service},
  booktitle =    SIGCOMM,
  year =         2014,
  location =     {Chicago, Illinois, USA},
  pages =        {563--574},
  url =          {http://doi.acm.org/10.1145/2619239.2626298},
  abstract =     {We present Statesman, a network-state management
                  service that allows multiple network management
                  applications to operate independently, while
                  maintaining network-wide safety and performance
                  invariants. Network state captures various aspects
                  of the network such as which links are alive and how
                  switches are forwarding traffic. Statesman uses
                  three views of the network state. In observed state,
                  it maintains an up-to-date view of the actual
                  network state. Applications read this state and
                  propose state changes based on their individual
                  goals. Using a model of dependencies among state
                  variables, Statesman merges these proposed states
                  into a target state that is guaranteed to maintain
                  the safety and performance invariants. It then
                  updates the network to the target state. Statesman
                  has been deployed in ten Microsoft Azure datacenters
                  for several months, and three distinct applications
                  have been built on it. We use the experience from
                  this deployment to demonstrate how Statesman enables
                  each application to meet its goals, while
                  maintaining network-wide invariants.},
  url =          {https://www2.cs.duke.edu/courses/fall14/compsci590.4/Papers/sigcomm2014-statesman.pdf},
  comments =     {Need to run multiple control applications.  Apps
                  separately modify state, and StatesMan acts as an
                  invariant guardian, merging multiple "proposed"
                  states into a "target" state.  Needs a detailed
                  model of the network depedencies; represents network
                  as key-value pairs.  Three apps managing 1.5M state
                  variables deployed.  Depedency = controllability of
                  a variable as a function of other variables (a
                  Boolean value).  Monitor produces observed state,
                  checker produces target state from all other states,
                  and updater produces commands from observed and
                  target state.  Dependency model is relatively simple
                  and device-independent (Figure 4).  Conflict
                  resolution is relatively "syntactic": either
                  last-writer wins, or based on priorities.
                  Invariants: full connectivity of TOR switches and
                  available network capacity.  Hand-partitioned
                  variables for scalability.  Violations reported to
                  humans.  Built on top of Paxos.  50KLOC C\# and C++.
                  Command templates for actuators Caching layers in
                  front of Paxos, with 5 minute staleness; relatively
                  slow control loop.  Deployed in production.  No
                  change tracking; needs to poll entire state.}
}

@ARTICLE{chen-ic14,
  author =       {Chen, Chao-Chih and Sun, Peng and Yuan, Lihua and
                  Maltz, David A. and Chuah, Chen-Nee and Mohapatra,
                  Prasant},
  journal =      {IEEE Internet Computing},
  title =        {{SWIM}: A Switch Manager for Datacenter Networks},
  year =         2014,
  volume =       18,
  number =       4,
  pages =        {30-36},
  doi =          {10.1109/MIC.2014.41},
  abstract =     {Datacenter networks are rapidly increasing the
                  number of servers they support, making equipment
                  management highly complex. Network attributes are
                  scattered among network engineering groups, making
                  troubleshooting cumbersome. Meanwhile, network
                  vendor diversity leads to an explosion of
                  vendor-specific management systems or single-use
                  automation scripts, limiting network scalability and
                  increasing management time and effort. Switch
                  Manager (SWIM) copes with this growth by
                  standardizing the language for describing network
                  attributes and unifying the interface for executing
                  management actions on the network equipment.},
  url =           {https://www.ece.ucdavis.edu/~chuah/rubinet/paper/2014/ic14-swim.pdf},
  comments =      {"standard language for network descriptions and
                  network implementations".  Description language is
                  based on a fixed grammar plus attributes.  Very
                  complex data model.  Stores data in XML.
                  Implementation only supports two operations: SetIP
                  and AddRoute.}
}

@InProceedings{ballani-sigcomm07,
  author =       {Ballani, Hitesh and Francis, Paul},
  title =        {{CONMan}: A Step Towards Network Manageability},
  booktitle =    SIGCOMM,
  year =         2007,
  month =        {August},
  abstract =     {Networks are hard to manage and in spite of all the
                  so called holistic management packages, things are
                  getting worse. We argue that the difficulty of
                  network management can partly be attributed to a
                  fundamental flaw in the existing architecture:
                  protocols expose all their internal details and
                  hence, the complexity of the ever-evolving data
                  plane encumbers the management plane. Guided by this
                  observation, in this paper we explore an alternative
                  approach and propose Complexity Oblivious Network
                  Management (CONMan), a network architecture in which
                  the management interface of data-plane protocols
                  includes minimal protocol-specific information. This
                  restricts the operational complexity of protocols to
                  their implementation and allows the management plane
                  to achieve high level policies in a structured
                  fashion. We built the CONMan interface of a few
                  protocols and a management tool that can achieve
                  high-level configuration goals based on this
                  interface. Our preliminary experience with applying
                  this tool to real world VPN configuration indicates
                  the architecture’s potential to alleviate the
                  difficulty of configuration management},
  url =          {http://www.sigcomm.org/sites/default/files/ccr/papers/2007/October/1282427-1282404.pdf},
  comments =     {Relatively low-level object model of network.}
}

@InProceedings{kim-noms12,
  author =       {W. Kim and P. Sharma},
  title =        {{Hercules}: Integrated Control Framework for
                  Datacenter Traffic Management},
  booktitle =    {IEEE Network Operations and Management Symposium},
  year =         2012,
  month =        {April},
  url =          {https://www.cse.iitd.ac.in/~siy107537/csl374/a5/files/hercules.pdf},
  abstract =     {The large scale and high performance requirements of
                  Cloud computing pose many challenges to the data
                  center network operators. These networks typically
                  require high bisection bandwidth, strict performance
                  isolation, and power-efficient operation. Recently,
                  many researchers have proposed various network
                  controller systems for programming networks, each of
                  them to individually address only one of these
                  challenges. In this paper, however, we show that
                  running multiple controllers in a shared network
                  fabric independently is not only inefficient but
                  conflicting control decisions by different
                  controllers can also lead to serious network
                  performance degradation. We present HERCULES , an
                  integrated control framework, to enable coexistence
                  and operation of multiple controllers. As an initial
                  proof of concept, we have integrated four existing
                  controllers into HERCULES framework. Our evaluation
                  of the integrated controller shows that it can
                  enable multiple controllers to leverage each other
                  and collectively achieve the multiple goals of the
                  controllers simultaneously.},
  comments =     {You need multiple controllers because your network
                  is heterogeneous.  Shared network state.
                  Notification mechanism between controllers.  4 types
                  of controllers: multi-path, QoS, elephant flows,
                  power management.  Some data comes from end hosts
                  (not network).  End hosts are also controlled.
                  Centralized network state.  Each controller can only
                  update some of the state.}
}

@inproceedings{roscoe-sigopsew02,
  author =       {Roscoe, Timothy and Mortier, Richard and Jardetzky,
                  Paul and Hand, Steven},
  title =        {{InfoSpect}: Using a Logic Language for System
                  Health Monitoring in Distributed Systems},
  year =         2002,
  url =          {https://doi.org/10.1145/1133373.1133379},
  abstract =     {Dependable systems cannot be built without a
                  monitoring and management component. In this paper
                  we propose using a wide variety of information
                  gathering tools coupled with custom scripts and a
                  Prolog language engine to aggregate information from
                  multiple sources. Complex queries, difficult to
                  express in standard database languages, can then be
                  used to answer questions about the system (e.g. the
                  health of individual components) or to discover
                  contradictions (e.g. inconsistent
                  configurations). We describe our prototype
                  implementation and present some early results.},
  booktitle =    {Proceedings of the 10th Workshop on ACM SIGOPS
                  European Workshop},
  pages =        {31–37},
  numpages =     7,
  location =     {Saint-Emilion, France},
  url =          {https://planetlab.cs.princeton.edu/files/pdn/PDN-02-008/pdn-02-008.pdf},
  comments =     {Read-only system: answer queries about distributed
                  system.  No control.  Prolog is touted for not
                  having a schema; the system is described as being
                  different from databases, but this is some confusion
                  in authors' minds.  Tools collect data.  Prolog
                  rules can discover inconsistencies.  Database
                  (facts) tend to be stale by a few minutes.  Does not
                  really support changes.}
}


@InProceedings{el-hassany-cav17,
  author =       "El-Hassany, Ahmed and Tsankov, Petar and Vanbever,
                  Laurent and Vechev, Martin",
  editor =       "Majumdar, Rupak and Kun{\v{c}}ak, Viktor",
  title =        "Network-Wide Configuration Synthesis",
  booktitle =    CAV,
  year =         2017,
  publisher =    "Springer International Publishing",
  address =      "Heidelberg, Germany",
  pages =        "261--281",
  abstract =     "Computer networks are hard to manage. Given a set of
                  high-level requirements (e.g., reachability,
                  security), operators have to manually figure out the
                  individual configuration of potentially hundreds of
                  devices running complex distributed protocols so
                  that they, collectively, compute a compatible
                  forwarding state. Not surprisingly, operators often
                  make mistakes which lead to downtimes.  To address
                  this problem, we present a novel synthesis approach
                  that automatically computes correct network
                  configurations that comply with the operator’s
                  requirements. We capture the behavior of existing
                  routers along with the distributed protocols they
                  run in stratified Datalog. Our key insight is to
                  reduce the problem of finding correct input
                  configurations to the task of synthesizing inputs
                  for a stratified Datalog program.  To solve this
                  synthesis task, we introduce a new algorithm that
                  synthesizes inputs for stratified Datalog
                  programs. This algorithm is applicable beyond the
                  domain of networks.  We leverage our synthesis
                  algorithm to construct the first network-wide
                  configuration synthesis system, called SyNET, that
                  support multiple interacting routing protocols (OSPF
                  and BGP) and static routes. We show that our system
                  is practical and can infer correct input
                  configurations, in a reasonable amount time, for
                  networks of realistic size (>50 routers) that
                  forward packets for multiple traffic classes.",
  url =          {https://arxiv.org/abs/1611.02537},
  comments =     {Uses Datalog programs to express network (routing)
                  state, and models the network control problem as a
                  synthesis problem: synthesize the inputs to a
                  Datalog program (the inputs are the router
                  configurations) that entail a state that satisfies
                  some specified requirements (also specified in
                  Datalog).  Decidable for finite parameters.
                  Synthesis algorithm operates on strata backwards.
                  Supports aggregation.  Algorithm may backtrack to
                  higher strata on failures.  Uses an SMT solver.  The
                  key contribution is this encoding of Datalog
                  semantics into a formula.  They unroll positive
                  loops and write predicates for a fixed number of
                  loop iterations (e.g., derived in 3 iterations).}
}

@inproceedings {ferguson-hotice12,
  author =       {Andrew D. Ferguson and Arjun Guha and Jordan Place
                  and Rodrigo Fonseca and Shriram Krishnamurthi},
  title =        {Participatory Networking},
  booktitle =    {Workshop on Hot Topics in Management of Internet,
                  Cloud, and Enterprise Networks and Services (Hot-ICE)},
  year =         2012,
  address =      {San Jose, CA},
  url =          {https://www.usenix.org/conference/hot-ice12/workshop-program/presentation/ferguson},
  publisher =    {{USENIX} Association},
  month =        apr,
  abstract =     {Software Defined Networks, which provide a
                  programmable, logically centralized abstraction of
                  network control, offer an escape from the current
                  state of enterprise and datacenter network
                  configuration, plagued by brittle, static solutions
                  involving manual setting of myriad devices. But if
                  SDNs provide an operating system for the network, we
                  are missing the analog to system calls – an API for
                  end-users and their applications to take part in
                  network configuration. In response, we propose
                  participatory networking, a new paradigm for network
                  configuration in which users submit requests or
                  hints for current and future network properties such
                  as quality of service, access control, and path
                  selection. We describe the initial design and
                  implementation of a participatory networking system,
                  PANE, and its solutions to the challenges of
                  resource arbitration and privilege delegation.},
  comments =     {PANE is the API to the control-plane.  Implemented
                  on top of Nettle \cite{vollemy-padl11}.  Has a
                  mechanism to delegate privileges to end-users who
                  attempt to use the netowrk.  Users have requests,
                  hints and queries.  All messages are about
                  flowgroups.}
}


@inproceedings{mao-conext08,
  author =       {Mao, Yun and Loo, Boon Thau and Ives, Zachary and
                  Smith, Jonathan M.},
  title =        {{MOSAIC}: Unified Declarative Platform for Dynamic
                  Overlay Composition},
  year =         2008,
  url =          {https://doi.org/10.1145/1544012.1544017},
  abstract =     {Overlay networks create new networking services
                  across nodes that communicate using pre-existing
                  networks. MOSAIC is a unified declarative platform
                  for constructing new overlay networks from multiple
                  existing overlays, each possessing a subset of the
                  desired new network's characteristics. MOSAIC
                  overlays are specified using Mozlog, a new
                  declarative language for expressing overlay
                  properties independently from their particular
                  implementation or underlying network.This paper
                  focuses on the runtime aspects of MOSAIC:
                  composition and deployment of control and/or data
                  plane functions of different overlay networks,
                  dynamic compositions of overlay networks to meet
                  changing application needs and network conditions,
                  and seamless support for legacy applications. MOSAIC
                  is validated experimentally using compositions
                  specified in Mozlog: we combine an indirection
                  overlay that supports mobility (i3), a resilient
                  overlay (RON), and scalable lookups (Chord), to
                  provide new overlay networks with new
                  functions. MOSAIC uses runtime composition to
                  simultaneously deliver application-aware mobility,
                  NAT traversal and reliability. We further
                  demonstrate MOSAIC'S dynamic composition
                  capabilities by Chord switching its underlay from IP
                  to RON at runtime. These benefits are obtained at a
                  low performance cost, as demonstrated by
                  measurements on both a local cluster and PlanetLab.},
  booktitle =    CoNEXT,
  articleno =    5,
  numpages =     12,
  location =     {Madrid, Spain},
  url =          {https://www.cis.upenn.edu/~zives/research/mosaic_conext08.pdf},
  comments =     {Stacks or bridges overlays. "Mozlog provides several
                  novel language features essential for dynamic
                  composition: dynamic location specifiers, combined
                  with runtime types, enable flexible naming anda
                  ddressing; composable virtual views support
                  modularity and composability; data and control plane
                  extensibility supports composition; declarative
                  tunneling and proxying enable support for legacy
                  applications."  Bridging is done using gateway nodes
                  that belong to two overlays.  Centralized directory
                  service has information about all deployed overlays.
                  Mozlog seems to be a target language, specifying the
                  dataplane.  Overlay compositions specified in XML.
                  Requires replacing IP with their own custom protocol
                  with custom addressing schemes.  Mozlog based on
                  NDLog (with locations).  Built on a previous
                  framework, called P2; Mozlog is compiled into P2 --
                  similar to click single-node code.  Not a very good
                  paper.}
}

@inproceedings{mogul-hotnets13,
  author =       {Mogul, Jeffrey C. and AuYoung, Alvin and Banerjee,
                  Sujata and Popa, Lucian and Lee, Jeongkeun and
                  Mudigonda, Jayaram and Sharma, Puneet and Turner,
                  Yoshio},
  title =        {{Corybantic}: Towards the Modular Composition of
                  {SDN} Control Programs},
  year =         2013,
  url =          {https://doi.org/10.1145/2535771.2535795},
  abstract =     {Software-Defined Networking (SDN) promises to enable
                  vigorous innovation, through separation of the
                  control plane from the data plane, and to enable
                  novel forms of network management, through a
                  controller that uses a global view to make
                  globally-valid decisions. The design of SDN
                  controllers creates novel challenges; much previous
                  work has focused on making them scalable, reliable,
                  and efficient.However, prior work has ignored the
                  problem that multiple controller functions may be
                  competing for resources (e.g., link bandwidth or
                  switch table slots). Our Corybantic design supports
                  modular composition of independent controller
                  modules, which manage different aspects of the
                  network while competing for resources. Each module
                  tries to optimize one or more objective functions;
                  we address the challenge of how to coordinate
                  between these modules to maximize the overall value
                  delivered by the controllers' decisions, while still
                  achieving modularity.},
  booktitle =    HOTNETS,
  articleno =    1,
  numpages =     7,
  keywords =     {software-defined networking},
  location =     {College Park, Maryland},
  url =          {http://www.hpl.hp.com/techreports/2013/HPL-2013-62.pdf},
  comments =     {Centralized coordinator.  Higher level than Pyretic
                  or Frenetic: helps in the planning process, not in
                  the execution.  Constrained multi-objective
                  optimization.  Converts it into a single-objective
                  by using a single currency.  It uses fast heuristic
                  using domain knowledge.  Main tool is a "virtual
                  subset topology": a subgraph of the full network
                  graph.  4-phases in protocol: (1) each controlled
                  proposes "topology" changes to central coordinator;
                  (2) express benefit in terms of costs, (3)
                  coordinator chooses a proposal, (4) controllers
                  instantiate chosen one.  For this to work proposals
                  must be "good" (tractable).  They implemented 3
                  modules in Python.  On rejection modules need to do
                  some blind search.  There are time-related
                  expressivity issues (time-dependent costs,
                  deadlines) not handled.}
}

@inproceedings{xu-cenet09,
  author =       {Chen, Xu and Mao, Z. Morley and Van der Merwe,
                  Jacobus},
  title =        {{PACMAN}: A Platform for Automated and Controlled
                  Network Operations and Configuration Management},
  year =         2009,
  url =          {https://doi.org/10.1145/1658939.1658971},
  abstract =     {The lack of automation associated with network
                  operations in general and network configuration
                  management in particular, is widely recognized as a
                  significant contributing factor to user-impacting
                  network events. In this paper we present our work on
                  the PACMAN system, a Platform for Automated and
                  Controlled network operations and configuration
                  MANagement. PACMAN realizes network operations by
                  executing active documents, which systematically
                  capture the dynamics in network management
                  tasks. Active documents not only enable the complete
                  execution of low-level configuration management
                  tasks, but also allow the construction of more
                  sophisticated tasks, while imposing additional
                  reasoning logic to realize network-wide management
                  objectives. We present the design, realization and
                  evaluation of the PACMAN framework and illustrate
                  its utility by presenting the implementation of
                  several sophisticated operational tasks.},
  booktitle =    {International Conference on Emerging Networking
                  Experiments and Technologies},
  pages =        {277–288},
  numpages =     12,
  keywords =     {automation, network management, petri net},
  location =     {Rome, Italy},
  url =          {http://web.eecs.umich.edu/~zmao/Papers/pacman.pdf},
  comments =     {"active documents" = scripts.  Petri nets model
                  events that trigger document evaluation.
                  Implemented in Java; manages Juniper routers.  Goal
                  is to automate manual processes.  Not relevant for
                  this paper.}
}

@inproceedings{xin-nsdi15,
  author =       {Jin, Xin and Gossels, Jennifer and Rexford, Jennifer
                  and Walker, David},
  title =        {{CoVisor}: A Compositional Hypervisor for
                  Software-Defined Networks},
  year =         2015,
  abstract =     {We present CoVisor, a new kind of network hypervisor
                  that enables, in a single network, the deployment of
                  multiple control applications written in different
                  programming languages and operating on different
                  controller platforms. Unlike past hypervisors, which
                  focused on slicing the network into disjoint parts
                  for separate control by separate entities, CoVisor
                  allows multiple controllers to cooperate on managing
                  the same shared traffic. Consequently, network
                  administrators can use CoVisor to assemble a
                  collection of independently-developed "best of
                  breed" applications--a firewall, a load balancer, a
                  gateway, a router, a traffic monitor--and can apply
                  those applications in combination, or separately, to
                  the desired traffic. CoVisor also abstracts concrete
                  topologies, providing custom virtual topologies in
                  their place, and allows administrators to specify
                  access controls that regulate the packets a given
                  controller may see, modify, monitor, or reroute. The
                  central technical contribution of the work is a new
                  set of efficient algorithms for composing controller
                  policies, for compiling virtual networks into
                  concrete OpenFlow rules, and for efficiently
                  processing controller rule updates. We have built a
                  CoVisor prototype, and shown that it is several
                  orders of magnitude faster than a naive
                  implementation.},
  booktitle =    NSDI,
  pages =        {87–101},
  numpages =     15,
  location =     {Oakland, CA},
  url =          {https://www.cs.princeton.edu/~jrex/papers/covisor.pdf},
  comments =     {Assumes a single OF table on each device.  (1)
                  assembles multiple controllers by intercepting OF
                  messages; (2) presents abstract topologies to
                  controllers; (3) protect against misbehaving
                  controllers (using administrator-specified ACLs for
                  each controller; ACLs are packet headers that can be
                  matched).  Intercepts OF messages.  Incrementally
                  updates rules using a rule algebra based on
                  priorities; incremental compilation of rule
                  composition and topology mapping.  Virtual
                  topologies are specified by indicating corresponding
                  switches, ports, and links.  Explicit rules for
                  compiling composition operators: parallel,
                  sequential, and override.  Involves cartesian
                  products of OF rules.  Priority assignment is
                  important for incrementality: add for parallel
                  composition, concatenate for sequential, stack for
                  override (lexicographic).  Addition and deletion
                  only need to touch rules that were produced from the
                  source.  Topology compilation is done using symbolic
                  evaluation on all possible paths and sequentially
                  composing rules on each path (similar to Header
                  Space Analysis).  Keep symbolic paths around for
                  incremental recompilation.  Use ACLs to reduce
                  search space in compilation; use tries on header
                  fields.  Evaluate compilation time.  Relatively
                  simple evaluation.}
}

@inproceedings{Wen-hotsdn14,
  author =       {Wen, Xitao and Diao, Chunxiao and Zhao, Xun and
                  Chen, Yan and Li, Li Erran and Yang, Bo and Bu, Kai},
  title =        {Compiling Minimum Incremental Update for Modular {SDN}
                  Languages},
  year =         2014,
  url =          {https://doi.org/10.1145/2620728.2620733},
  abstract =     {Measurement results show that updating rules on
                  switches poses major latency overhead during the
                  course of the policy update. However, current SDN
                  policy compilers do not handle policy updates well
                  and generate large amount of redundant rule updates,
                  most of which modify only the priority field. Our
                  analysis shows that the lack of knowledge on the
                  rule dependency and the consecutively distributed
                  priority numbers are the fundamental problems behind
                  the redundancy. In this paper, we propose to tackle
                  the problems through 1) an extended policy compiler
                  that builds rule dependency along with the
                  compilation, and 2) an online optimization algorithm
                  that maintains a scattered priority
                  distribution. Our preliminary evaluation
                  demonstrates that our proposed patch can eliminate
                  nearly all the priority updates.},
  booktitle =    HotSDN,
  pages =        {193–198},
  numpages =     6,
  keywords =     {compiler, openflow, incremental update,
                  software-defined networking},
  location =     {Chicago, Illinois, USA},
  url =          {http://www.cs.northwestern.edu/~xwe334/papers/compact_update_hotsdn.pdf},
  comments =     {This is about OpenFlow rules updating.  Switches
                  cannot apply too many rules quickly.  Small changes
                  to input program can generate many rules changes,
                  esp. in priorities.  One should represent true
                  dependences between rules explicitly, and maintain
                  them explicitly, and leave gaps in priorities
                  allocated.  Implemented in NetKAT.  Looks very
                  useful.  Propagate dependencies through
                  compilation.}
}

@inproceedings{prakash-sigcomm15,
  author =       {Prakash, Chaithan and Lee, Jeongkeun and Turner,
                  Yoshio and Kang, Joon-Myung and Akella, Aditya and
                  Banerjee, Sujata and Clark, Charles and Ma, Yadi and
                  Sharma, Puneet and Zhang, Ying},
  title =        {{PGA}: Using Graphs to Express and Automatically
                  Reconcile Network Policies},
  year =         2015,
  url =          {https://doi.org/10.1145/2785956.2787506},
  abstract =     {Software Defined Networking (SDN) and cloud
                  automation enable a large number of diverse parties
                  (network operators, application admins,
                  tenants/end-users) and control programs (SDN Apps,
                  network services) to generate network policies
                  independently and dynamically. Yet existing policy
                  abstractions and frameworks do not support natural
                  expression and automatic composition of high-level
                  policies from diverse sources. We tackle the open
                  problem of automatic, correct and fast composition
                  of multiple independently specified network
                  policies. We first develop a high-level Policy Graph
                  Abstraction (PGA) that allows network policies to be
                  expressed simply and independently, and leverage the
                  graph structure to detect and resolve policy
                  conflicts efficiently. Besides supporting ACL
                  policies, PGA also models and composes service
                  chaining policies, i.e., the sequence of middleboxes
                  to be traversed, by merging multiple service chain
                  requirements into conflict-free composed chains. Our
                  system validation using a large enterprise network
                  policy dataset demonstrates practical composition
                  times even for very large inputs, with only
                  sub-millisecond runtime latencies.},
  booktitle =    {Proceedings of the 2015 ACM Conference on Special
                  Interest Group on Data Communication},
  pages =        {29–42},
  numpages =     14,
  keywords =     {policy graphs, network domains, middleboxes,
                  software-defined networks, network programming
                  interfaces, network appliances, data center
                  networks, network manageability, programmable
                  networks, network management},
  location =     {London, United Kingdom},
  url =          {http://pages.cs.wisc.edu/~akella/papers/pga-sigcomm15.pdf},
  comments =     {Express policies on endpoints separately for
                  administrative sub-domains.  Merge policies
                  automatically.  Built on top of Pyretic.  Existing
                  policy composition languages are not powerful enough
                  for some practical use cases; they need to
                  "understand" more of the policy's meaning.  They
                  specialize for firewalls and service chaining.
                  Policies expressed as graphs augmented with a
                  database of principals and their relationships.
                  Graphs model: network endpoints and service chains
                  required between them.  Groups are expressed as
                  labels.  Behavior of service functions expressed in
                  Pyretic and allows automatic composition.
                  Additional constraints can be expressed besides
                  graphs.  Labels can change dynamically.  Edges are
                  "positive" (whitelists); they can also have
                  conditions attached.  PGA cannot express some NFV
                  scenarios (e.g. packet duplication).  Conflicts are
                  detected statically.  When merging graphs the order
                  of chains must be inferred from the specifications
                  of their behaviors.  Implemented in Python; takes 10
                  minutes for an enterprise network.  Does not seem to
                  be incremental.}
}

@inproceedings{Reitblatt-sigcomm12,
  author =       {Reitblatt, Mark and Foster, Nate and Rexford,
                  Jennifer and Schlesinger, Cole and Walker, David},
  title =        {Abstractions for Network Update},
  booktitle =    SIGCOMM,
  year =         2012,
  address =      {Helsinki, Finland},
  pages =        {323--334},
  abstract =     {Configuration changes are a common source of
                  instability in networks, leading to outages,
                  performance disruptions, and security
                  vulnerabilities. Even when the initial and final
                  configurations are correct, the update process
                  itself often steps through intermediate
                  configurations that exhibit incorrect
                  behaviors. This paper introduces the notion of
                  consistent network updates --- updates that are
                  guaranteed to preserve well-defined behaviors when
                  transitioning mbetween configurations. We identify
                  two distinct consistency levels, per-packet and
                  per-flow, and we present general mechanisms for
                  implementing them in Software-Defined Networks using
                  switch APIs like OpenFlow. We develop a formal model
                  of OpenFlow networks, and prove that consistent
                  updates preserve a large class of properties. We
                  describe our prototype implementation, including
                  several optimizations that reduce the overhead
                  required to perform consistent updates. We present a
                  verification tool that leverages consistent updates
                  to significantly reduce the complexity of checking
                  the correctness of network control
                  software. Finally, we describe the results of some
                  simple experiments demonstrating the effectiveness
                  of these optimizations on example applications.},
  url =          {http://reitblatt.com/papers/consistent-updates-sigcomm12.pdf},
  comments =     {Per-packet and per-flow consistency.  Two-phase
                  distributed updates.  Trace properties hold
                  throughout the update process.  Verified in Coq.
                  Packets carry versions.  Packets cannot transit
                  through uncontrolled environments.  Packet trace =
                  sequence of ports.  Assumes all transitions are the
                  ones specified by controller (but what about
                  failures?)  A trace property is a prefix-closed set
                  of traces.  The main value of the paper is in the
                  formal definition and proofs of some very strong
                  properties.  Use CTL formulas to verify properties
                  using a model checker.  Per flow consistency is much
                  harder to achieve -- may need to keep rules alive
                  forever.  Implemented in a system called Kinetic, but
                  seems unrelated to the other Kinetic paper.}
}

@inproceedings{chen-ppdp15,
  author =       {Chen, Chen and Loh, Lay Kuan and Jia, Limin and
                  Zhou, Wenchao and Loo, Boon Thau},
  title =        {Automated Verification of Safety Properties of
                  Declarative Networking Programs},
  year =         2015,
  url =          {https://doi.org/10.1145/2790449.2790516},
  abstract =     {Networks are complex systems that unfortunately are
                  ridden with errors. Such errors can lead to
                  disruption of services, which may have grave
                  consequences. Verification of networks is key to
                  eliminating errors and building robust networks. In
                  this paper, we propose an approach to verify
                  networks using declarative networking, where
                  networks are specified in NDlog, a declarative
                  language. We focus on analyzing safety
                  properties. We develop a technique to statically
                  analyze NDlog programs: first, we build a dependency
                  graph of the predicates of NDlog programs; then, we
                  build a summary data structure called a derivation
                  pool to represent all possible derivations and their
                  associated constraints for predicates in the
                  program; finally, properties specified in
                  first-order logic are checked on the data structure
                  with the help of the SMT solver Z3. We build a
                  prototype tool and demonstrate the effectiveness of
                  the tool in validating and debugging several SDN
                  applications.},
  booktitle =    {International Symposium on Principles and Practice
                  of Declarative Programming (PPDP)},
  pages =        {79–90},
  numpages =     12,
  keywords =     {static analysis, declarative networking},
  location =     {Siena, Italy},
  url =          {https://netdb.cis.upenn.edu/papers/ppdp15.pdf},
  comments =     {Not directly relevant to OVN.  Has a good
                  bibliography for declarative languages used for
                  distributed systems (not just networks).}
}

@ARTICLE{banikazemi-cm13,
  author =       {Banikazemi, Mohammad and Olshefski, David and
                  Shaikh, Anees and Tracey, John and Wang, Guohui},
  journal =      {IEEE Communications Magazine},
  title =        {{Meridian}: an {SDN} platform for cloud network
                  services},
  year =         2013,
  volume =       51,
  number =       2,
  pages =        {120-127},
  doi =          {10.1109/MCOM.2013.6461196},
  url =          {http://rboutaba.cs.uwaterloo.ca/Courses/CS856-F14/Papers/06461196.pdf},
  abtract =      {As the number and variety of applications and
                  workloads moving to the cloud grows, networking
                  capabilities have become increasingly
                  important. Over a brief period, networking support
                  offered by both cloud service providers and cloud
                  controller platforms has developed rapidly. In most
                  of these cloud networking service models, however,
                  users must configure a variety of network-layer
                  constructs such as switches, subnets, and ACLs,
                  which can then be used by their cloud
                  applications. In this article, we argue for a
                  service-level network model that provides higher-
                  level connectivity and policy abstractions that are
                  integral parts of cloud applications. Moreover, the
                  emergence of the software-defined networking (SDN)
                  paradigm provides a new opportunity to closely
                  integrate application provisioning in the cloud with
                  the network through programmable interfaces and
                  automation. We describe the architecture and
                  implementation of Meridian, an SDN controller
                  platform that supports a service-level model for
                  application networking in clouds. We discuss some of
                  the key challenges in the design and implementation,
                  including how to efficiently handle dynamic updates
                  to virtual networks, orchestration of network tasks
                  on a large set of devices, and how Meridian can be
                  integrated with multiple cloud controllers.},
  comments =     {Built on top of OF controller Floodlight.  Abstract
                  network schema.  Operations on abstract schema
                  trigger (nested) plans.  Includes endpoint
                  information (VMs) obtained using libvirt.  Not
                  really declarative.}
}

@article{shieh-sigcomm11,
  author =       {Shieh, Alan and Sirer, Emin G\"{u}n and Schneider,
                  Fred B.},
  title =        {{NetQuery}: A Knowledge Plane for Reasoning about
                  Network Properties},
  year =         2011,
  issue_date =   {August 2011},
  volume =       41,
  number =       4,
  issn =         {0146-4833},
  url =          {https://doi.org/10.1145/2043164.2018469},
  abstract =     {This paper presents the design and implementation of
                  NetQuery, a knowledge plane for federated networks
                  such as the Internet. In such networks, not all
                  administrative domains will generate information
                  that an application can trust and many
                  administrative domains may have restrictive policies
                  on disclosing network information. Thus, both the
                  trustworthiness and accessibility of network
                  information pose obstacles to effective
                  reasoning. NetQuery employs trustworthy computing
                  techniques to facilitate reasoning about the
                  trustworthiness of information contained in the
                  knowledge plane while preserving confidentiality
                  guarantees for operator data. By characterizing
                  information disclosure between operators, NetQuery
                  enables remote verification of advertised claims and
                  contractual stipulations; this enables new
                  applications because network guarantees can span
                  administrative boundaries. We have implemented
                  NetQuery, built several NetQuery-enabled devices,
                  and deployed applications for cloud datacenters,
                  enterprise networks, and the Internet. Simulations,
                  testbed experiments, and a deployment on a
                  departmental network indicate NetQuery can support
                  hundreds of thousands of operations per second and
                  can thus scale to large ISPs.},
  journal =      SIGCOMM,
  month =        aug,
  pages =        {278–289},
  numpages =     12,
  keywords =     {knowledge plane, tpm, trustworthy computing},
  url =          {http://www.cs.cornell.edu/people/egs/papers/netquery-sigcomm.pdf},
  comments =     {Information is bound to a principal (public/private
                  key) that originates it.  Uses TPM modules for root
                  of trust.  Each fact has an attribution (who
                  produced it) and an export (who can access it).  The
                  system provides a unified schema participants must
                  adhere to.  Federated DB only provides scans (no
                  recursive queries or aggregations).  Triggers are
                  used for notifications.  Use a special logic "Nexus
                  Authorization Logic" to reason about "factoids".
                  Sanitizers allow third parties to run code in a TPM
                  to analyze data that cannot be released.}
}

@inproceedings{ahmad-ideas12,
  author =       {Ahmad-Kassem, Ahmad and Bobineau, Christophe and
                  Collet, Christine and Dubl\'{e}, Etienne and
                  Grumbach, St\'{e}phane and Ma, Fuda and Martinez,
                  Lourdes and Ub\'{e}da, St\'{e}phane},
  title =        {{UBIQUEST}, for Rapid Prototyping of Networking
                  Applications},
  year =         2012,
  url =          {https://doi.org/10.1145/2351476.2351498},
  abstract =     {An UBIQUEST system provides a high level programming
                  abstraction for rapid prototyping of heterogeneous
                  and distributed applications in a dynamic
                  environment. Such a system is perceived as a
                  distributed database and the applications interact
                  through declarative queries including declarative
                  networking programs (e.g. routing) and/or specific
                  data-oriented distributed algorithms
                  (e.g. distributed join). Case-Based Reasoning is
                  used for optimization of distributed queries when as
                  there is no prior knowledge on data (sources) in
                  networking applications, and certainly no related
                  metadata such as data statistics.},
  booktitle =    {International Database Engineering and
                  Applications Sysmposium (IDEAS)},
  pages =        {187–192},
  numpages =     6,
  keywords =     {programming abstraction, declarative networking,
                  case-based distributed query optimization},
  location =     {Prague, Czech Republic},
  url =          {https://hal.inria.fr/docs/00/81/60/34/PDF/UBIQUEST_For_Rapid_Prototyping_of_Networking_Applications.pdf},
  comments =     {The network information base is a database federated
                  between participant nodes.  Network management is
                  done through queries.  Federated query engine.
                  Ad-hoc design.  DLAQL is an extension of SQL.
                  Algorithms are also expressed in Netlog and
                  Questlog, extensions of Datalog.}
}

@inproceedings{Ryzhyk-nsdi17,
  title =        {Correct by Construction Networks Using Stepwise
                  Refinement},
  author =       {Ryzhyk, Leonid and Bj{\"o}rner, Nikolaj and Canini,
                  Marco and Jeannin, Jean-Baptiste and Schlesinger,
                  Cole and Terry, Douglas B. and Varghese, George},
  booktitle =    NSDI,
  pages =        {683--698},
  year =         2017,
  month =        {March},
  address =      {Boston, MA},
  abstract =     {Building software-defined network controllers is an
                  exercise in software development and, as such,
                  likely to introduce bugs. We present Cocoon, a
                  framework for SDN development that facilitates both
                  the design and verification of complex networks
                  using stepwise refinement to move from a high-level
                  specification to the final network implementation.
                  A Cocoon user specifies intermediate design levels
                  in a hierarchical design process that delineates the
                  modularity in complicated network forwarding and
                  makes verification extremely efficient. For example,
                  an enterprise network, equipped with VLANs, ACLs,
                  and Level 2 and Level 3 Routing, can be decomposed
                  cleanly into abstractions for each mechanism, and
                  the resulting stepwise verification is over 200x
                  faster than verifying the final
                  implementation. Cocoon further separates static
                  network design from its dynamically changing
                  configuration. The former is verified at design
                  time, while the latter is checked at run time using
                  statically defined invariants. We present six
                  different SDN use cases including B4 and F10. Our
                  performance evaluation demonstrates that Cocoon is
                  not only faster than existing verification tools but
                  can also find many bugs statically before the
                  network design has been fully specified. },
  url =          {https://www.usenix.org/system/files/conference/nsdi17/nsdi17-ryzhyk.pdf}
}

@inproceedings{smolka-icfp15,
  author =       {Smolka, Steffen and Eliopoulos, Spiridon and Foster,
                  Nate and Guha, Arjun},
  title =        {A Fast Compiler for {NetKAT}},
  booktitle =    ICFP,
  year =         2015,
  location =     {Vancouver, BC, Canada},
  pages =        {328--341},
  numpages =     14,
  url =          {http://doi.acm.org/10.1145/2784731.2784761},
  abstract =     {High-level programming languages play a key role in
                  a growing number of networking platforms,
                  streamlining application develop- ment and enabling
                  precise formal reasoning about network
                  behavior. Unfortunately, current compilers only
                  handle “local” programs that specify behavior in
                  terms of hop-by-hop forwarding behavior, or modest
                  extensions such as simple paths. To encode richer
                  “global” behaviors, programmers must add extra
                  state—something that is tricky to get right and
                  makes programs harder to write and maintain. Making
                  matters worse, existing compilers can take tens of
                  minutes to generate the forwarding state for the
                  network, even on relatively small inputs. This
                  forces programmers to waste time working around
                  performance issues or even revert to using
                  hardware-level API s.  This paper presents a new
                  compiler for the Net KAT language that handles rich
                  features including regular paths and virtual
                  networks, and yet is several orders of magnitude
                  faster than previous compilers. The compiler uses
                  symbolic automata to calculate the extra state
                  needed to implement “global” programs, and an
                  intermediate representation based on binary decision
                  diagrams to dramatically improve performance. We
                  describe the design and implementation of three
                  essential compiler stages: from virtual programs
                  (which specify behavior in terms of virtual
                  topologies) to global programs (which specify
                  network-wide behavior in terms of physical
                  topologies), from global programs to local programs
                  (which specify behavior in terms of single-switch
                  behavior), and from local programs to hardware-level
                  forwarding tables. We present results from
                  experiments on real-world benchmarks that quantify
                  performance in terms of compilation time and
                  forwarding table size.},
  comments =     {Compiles for a given topology.  Forwarding decision
                  diagrams generalize BDDs.  FDDs match on header bits
                  and have at leaves packet modifications.  Ordered
                  FDDs; smart composition algorithms.  Seems like a
                  very nice piece of work.}
}

@inproceedings{jain-sigcomm13,
  author =       {Jain, Sushant and Kumar, Alok and Mandal, Subhasree
                  and Ong, Joon and Poutievski, Leon and Singh, Arjun
                  and Venkata, Subbaiah and Wanderer, Jim and Zhou,
                  Junlan and Zhu, Min and Zolla, Jon and H\"{o}lzle,
                  Urs and Stuart, Stephen and Vahdat, Amin},
  title =        {{B4}: Experience with a Globally-deployed Software
                  Defined {WAN}},
  booktitle =    SIGCOMM,
  year =         2013,
  location =     {Hong Kong, China},
  pages =        {3--14},
  url =          {http://doi.acm.org/10.1145/2486001.2486019},
  url =          {http://cseweb.ucsd.edu/~vahdat/papers/b4-sigcomm13.pdf},
  abstract =     {We present the design, implementation, and
                  evaluation of B4, a private WAN connecting Google’s
                  data centers across the planet. B4 has a number of
                  unique characteristics: i) massive bandwidth
                  requirements deployed to a modest number of sites,
                  ii) elastic traffc demand that seeks to maximize
                  average bandwidth, and iii) full control over the
                  edge servers and network, which enables ratel
                  imiting and demand measurement at the edge. Tese
                  characteristics led to a Sofware Defned Networking
                  architecture using OpenFlow to control relatively
                  simple switches built from merchant silicon. B4’s
                  centralized trafc engineering service drives links
                  to near 100\% utilization, while splitting
                  application fows among multiple paths to balance
                  capacity against application priority/demands. We
                  describe experience with three years of B4
                  production deployment, lessons learned, and areas
                  for future work.},
  comments =     {It's all about high utilization.  This can be
                  achieved if you can react quickly to failures
                  without overprovisioning.  Centralized control for
                  supporting traffic engineering.  Key is controlling
                  all traffic at the edge of the WAN.  Simulate on
                  clusters.  TE is done as an overlay.  BGP packets
                  forwarded to controller.  Controllers run on Paxos.
                  Onix used for OpenFlow control, with Network
                  Information Base.  TE does not operate on flows, but
                  on flow groups.  A flow is characterized by its
                  source site (not source machine!).  How QoS is
                  enforced is not discussed.  Tunnels are used for
                  creating flow groups, so outer IP header is used for
                  flow group.  Trafic enginnering and OF coordinate
                  through a database.  Very nice experience section.}
}

@inproceedings{yap-sigcomm17,
  author =       {Yap, Kok-Kiong and Motiwala, Murtaza and Rahe,
                  Jeremy and Padgett, Steve and Holliman, Matthew and
                  Baldus, Gary and Hines, Marcus and Kim, Taeeun and
                  Narayanan, Ashok and Jain, Ankur and Lin, Victor and
                  Rice, Colin and Rogan, Brian and Singh, Arjun and
                  Tanaka, Bert and Verma, Manish and Sood, Puneet and
                  Tariq, Mukarram and Tierney, Matt and Trumic, Dzevad
                  and Valancius, Vytautas and Ying, Calvin and
                  Kallahalla, Mahesh and Koley, Bikash and Vahdat,
                  Amin},
  title =        {Taking the Edge off with {Espresso}: Scale,
                  Reliability and Programmability for Global Internet
                  Peering},
  booktitle =    SIGCOMM,
  year =         2017,
  location =     {Los Angeles, CA, USA},
  pages =        {432--445},
  url =          {http://doi.acm.org/10.1145/3098822.3098854},
  abstract =     {We present the design of Espresso, Google’s
                  SDN-based Internet peering edge routing
                  infrastructure. This architecture grew out of a need
                  to exponentially scale the Internet edge
                  cost-effectively and to enable application-aware
                  routing at Internet-peering scale. Espresso utilizes
                  commodity switches and host-based routing/packet
                  processing to implement a novel fine-grained traffic
                  engineering capability.  Overall, Espresso provides
                  Google a scalable peering edge that is programmable,
                  reliable, and integrated with global traffic
                  systems.  Espresso also greatly accelerated
                  deployment of new networking features at our peering
                  edge. Espresso has been in production for two years
                  and serves over 22\% of Google’s total traffic to
                  the Internet.},
  comments =     {This is the network that isolates B4 from the
                  internet.  The devices in this network are connected
                  by B2.  Principles: hierarchical control (not just
                  two-level), fail static (continue operating when
                  control is down), software programmable, testable,
                  intent-manageable.  Espresso routers create the
                  tunnels needed for B4.  Intent-driven management.
                  Global controller solves some hard optimization
                  problems.  Do not necessarily trust all inputs
                  (e.g., if some change simultaneously keep using the
                  old versions).  Old states are archived to make
                  reverting easy.  Raven = custom multithreaded BGP
                  implementation.  ACL list is very large, so routers
                  only cache 5\% of it, rest is on servers.
                  Declarative configuration language.  Roll out
                  changes incrementally.  Continuously monitor and
                  probe.}
}

@inproceedings{sung-sigcomm16,
  author =       {Sung, Yu-Wei Eric and Tie, Xiaozheng and Wong,
                  Starsky H.Y. and Zeng, Hongyi},
  title =        {{Robotron}: Top-down Network Management at
                  {Facebook} Scale},
  year =         2016,
  url =          {https://doi.org/10.1145/2934872.2934874},
  abstract =     {Network management facilitates a healthy and
                  sustainable network. However, its practice is not
                  well understood outside the network engineering
                  community. In this paper, we present Robotron, a
                  system for managing a massive production network in
                  a top-down fashion. The system's goal is to reduce
                  effort and errors on management tasks by minimizing
                  direct human interaction with network
                  devices. Engineers use Robotron to express
                  high-level design intent, which is translated into
                  low-level device configurations and deployed
                  safely. Robotron also monitors devices' operational
                  state to ensure it does not deviate from the desired
                  state. Since 2008, Robotron has been used to manage
                  tens of thousands of network devices connecting
                  hundreds of thousands of servers globally at
                  Facebook.},
  booktitle =    SIGCOMM,
  pages =        {426–439},
  numpages =     14,
  keywords =     {Facebook, Network Management, Robotron},
  location =     {Florianopolis, Brazil},
  series =       SIGCOMM,
  url =          {https://research.fb.com/wp-content/uploads/2016/11/robotron_top-down_network_management_at_facebook_scale.pdf},
  comments =     {Goals: configuration as code, validation,
                  extensibilty.  Deployed since 2008.  POPs cache
                  content.  FBNet is an object store for high-level
                  intent; configurations are generated from it.  A
                  Python Django framework does object-relational
                  mapping for FBNet down to MySQL.  Queries are
                  generic, but APIs to mutate are domain-specific;
                  each mutation is a transaction.  MySQL replication
                  provides availability.  Has validation rules.  They
                  have "desired" state and "derived" (same as
                  "realized") state.  Use the Django template language
                  to generate configurations.  Staged rollouts.
                  Syslog used for monitoring.  Check deployed config
                  against expected ones.  Also offer network-design
                  tools.  Sometimes engineers need to modify lowest
                  levels of network manually; not easy to do.
                  Rougly 250 distinct entities.}
}

@inproceedings{alshabibi-hotnets14,
  author =       {Al-Shabibi, Ali and De Leenheer, Marc and Gerola,
                  Matteo and Koshibe, Ayaka and Parulkar, Guru and
                  Salvadori, Elio and Snow, Bill},
  title =        {{OpenVirteX}: Make Your Virtual {SDNs} Programmable},
  year =         2014,
  url =          {https://doi.org/10.1145/2620728.2620741},
  abstract =     {We present OpenVirteX, a network virtualization
                  platform that enables operators to create and manage
                  virtual Software Defined Networks (vSDNs). Tenants
                  are free to specify the topology and addressing
                  scheme of their vSDN, and run their own Network
                  Operating System (NOS) to control it. Since
                  OpenVirteX logically decouples vSDNs from the
                  infrastructure, it also enables the introduction of
                  features such as link and switch resiliency, and
                  network snapshotting and migration of these tenant
                  networks. OpenVirteX builds on the design of
                  FlowVisor, and functions as an OpenFlow controller
                  proxy between an operator's network and the tenants'
                  network OSes. Our evaluations of this implementation
                  show that i) OpenVirteX is capable of presenting
                  tenants with configurable vSDNs while incurring a
                  modest overhead to the control channel, and ii) that
                  our architecture enables the introduction of
                  features and enhancements such as link resilience to
                  tenant networks.},
  booktitle =    HOTNETS,
  pages =        {25–30},
  numpages =     6,
  keywords =     {software-defined network, topology virtualization,
                  virtual links, address virtualization, control
                  function virtualization, network virtualization,
                  openflow, resiliency},
  location =     {Chicago, Illinois},
  url =          {http://www.cs.columbia.edu/~lierranli/coms6998-10SDNFall2014/papers/openvirtex-HotSDN2014.pdf},
  comments =     {OVX is network hypervisor, offering virtual networks
                  to customers while multiplexing them below,
                  extending the FlowVisor work.  Each tenant can use a
                  separate controller on top.  Unlike FlowVisor,
                  header space is not sliced; each virtual network has
                  a full header space.  Does not seem to use tunnels,
                  but instead rewrites MAC+IP addresses.  Cute demo
                  running 3 independent NOSes.}
}

@inproceedings {mogul-nsdi20,
  author =       {Jeffrey C. Mogul and Drago Goricanec and Martin Pool
                  and Anees Shaikh and Douglas Turk and Bikash Koley
                  and Xiaoxue Zhao},
  title =        {Experiences with Modeling Network Topologies at
                  Multiple Levels of Abstraction },
  booktitle =    NSDI,
  year =         2020,
  address =      {Santa Clara, CA},
  pages =        {403--418},
  url =          {https://www.usenix.org/conference/nsdi20/presentation/mogul},
  publisher =    {{USENIX} Association},
  month =        feb,
  url =          {https://www.usenix.org/system/files/nsdi20-paper-mogul.pdf},
  abstract =     {Network management is becoming increasingly
                  automated, and automation depends on detailed,
                  explicit representations of data about the state of
                  a network and about an operator's intent for its
                  networks. In particular, we must explicitly
                  represent the desired and actual topology of a
                  network. Almost all other network-management data
                  either derives from its topology, constrains how to
                  use a topology, or associates resources (e.g.,
                  addresses) with specific places in a topology.
                  MALT, a Multi-Abstraction-Layer Topology
                  representation, supports virtually all network
                  management phases: design, deployment,
                  configuration, operation, measurement, and
                  analysis. MALT provides interoperability across our
                  network-management software, and its support for
                  abstraction allows us to explicitly tie low-level
                  network elements to high-level design intent. MALT
                  supports a declarative style, simplifying what-if
                  analysis and testbed support.  We also describe the
                  software base that supports efficient use of MALT,
                  as well as numerous, sometimes painful lessons we
                  have learned about curating the taxonomy for a
                  comprehensive, and evolving, representation for
                  topology.},
  comments =     {Must use multiple abstraction levels.  Schema must
                  evolve easily.  Models must be declarative.  Uses:
                  operating WAN, capacity planning and design, DC
                  fabric design and operation.  An entity-relationship
                  model, but not a relational database.  Roughly 250
                  entities.  Only 20 relationship kinds, including
                  "contains", "controls", "originates", "aggregates",
                  "traverses".  About 700 relationships. Binary and
                  human-readable forms for models.  Profiles help with
                  schema evolution.  No one DB, but many shards;
                  queries can work across shards; entities can appear
                  in multiple shards.  Profiles, shards are versioned.
                  Data stored in Spanner.  MALT schema changes do not
                  require Spanner schema changes.  Clients can cache
                  data to reduce latency.  Why not a DB?  No types.
                  Easier to change schemas (both MALT and SQL).  Query
                  language is hard to do: a custom graph-traversal
                  language.  Multi-shard queries use consistent shard
                  snapshots.  What is not in MALT?  Generated configs,
                  policies, forwarding tables, allocated resources,
                  inventory, monitoring data.  Schema design is very
                  hard and it requires a committee.  Create a new
                  entity when you notice you need new relations.}
}

@inproceedings{liu-selfdn18,
  author =       {Liu, Hongqiang Harry and Wu, Xin and Zhou, Wei and
                  Chen, Weiguo and Wang, Tao and Xu, Hui and Zhou, Lei
                  and Ma, Qing and Zhang, Ming},
  title =        {Automatic Life Cycle Management of Network
                  Configurations},
  year =         2018,
  url =          {https://doi.org/10.1145/3229584.3229585},
  abstract =     {Managing the life cycle of network configurations,
                  including the generation, update, transition and
                  diagnosis of the configurations, is the primary task
                  of network operators and a critical process for the
                  reliability and efficiency of the networks. This
                  paper presents NetCraft, a framework which automates
                  the life cycle management of network configurations
                  with a unified network model. Designed for life
                  cycle automation, NetCraft's network model can
                  expressively encode all parts and protocols in the
                  network; It can be converted to or constructed from
                  configurations with interoperability; It is able to
                  perform fine-grained configurations with flexibility
                  to deactivate or undo any configurations for safe
                  configuration updates; And it can work without
                  cooperations from device vendors. We have built and
                  deployed an initial version of NetCraft in Alibaba's
                  global WAN. Evaluations in real environments show
                  that NetCraft can reduce the network incidents
                  caused by configurations by 95\% and cut the average
                  time to plan and execute a network update by up to
                  93\%.},
  booktitle =    {Workshop on Self-Driving Networks (SelfDN)},
  pages =        {29–35},
  numpages =     7,
  keywords =     {Configuration, Self-driving Network, Automation,
                  Lifecycle},
  location =     {Budapest, Hungary},
  series =       {SelfDN 2018},
  url =          {http://www.hongqiangliu.com/uploads/5/2/7/4/52747939/netcraft.pdf},
  comments =     {Big system (100KLOC).  Mostly about routing;
                  representations are all graphs of the network at
                  various levels.  The main point seems to be
                  versioning.  Graphs generate vendor-specific
                  configurations.  Planner starts with a diff between
                  two networks and computes a transition plan.
                  Changes in 4 stages: deactivate, configure,
                  activate, and perhaps undo.  Realized state computed
                  by a configuration parser.  Some parts are not
                  automated; some transition state machines are
                  written by hand.  Rebooting a router is very
                  expensive, so perhaps reconfiguring incrementally is
                  better.}
}

@Misc{openstack-congress,
  author =       {OpenStack},
  howpublished = {https://wiki.openstack.org/wiki/Congress},
  note =         {Retrieved May 2021},
  year =         {2014},
  code =         {\url{https://github.com/openstack-archive/congress}},
  comments =     {The policy language for Congress is Datalog.  "With
                  Congress, a cloud operator can declare, monitor,
                  enforce, and audit "policy" in a heterogeneous cloud
                  environment. Congress gets inputs from a cloud's
                  various cloud services; for example in OpenStack,
                  Congress fetches information about VMs from Nova,
                  and network state from Neutron, etc. Congress then
                  feeds input data from those services into its policy
                  engine where Congress verifies that the cloud's
                  actual state abides by the cloud operator's
                  policies. Congress is designed to work with any
                  policy and any cloud service."  Performs monitoring,
                  enforcement, auditing.  Consumes policies from a
                  variety of sources.  Tables express policies.  error
                  table.  Input tables are called "built-in".  Actions
                  can be taken for enforcement ("execute" table
                  contains actions).  Some form of reflection: the
                  "actions" table describes the bodies of actions (in
                  Datalog as well); actions can insert or delete rows
                  in other tables.  Has a search process: to remedy
                  misconfiguration the system searches for actions
                  that would eliminate the rows that cause
                  misconfigurations.  Explored integration with LP
                  solver for optimizations.}
}


@inproceedings{gupta-sigcomm14,
  author =       {Gupta, Arpit and Vanbever, Laurent and Shahbaz,
                  Muhammad and Donovan, Sean P. and Schlinker, Brandon
                  and Feamster, Nick and Rexford, Jennifer and
                  Shenker, Scott and Clark, Russ and Katz-Bassett,
                  Ethan},
  title =        {{SDX}: A Software Defined Internet Exchange},
  year =         2014,
  url =          {https://doi.org/10.1145/2619239.2626300},
  abstract =     {BGP severely constrains how networks can deliver
                  traffic over the Internet. Today's networks can only
                  forward traffic based on the destination IP prefix,
                  by selecting among routes offered by their immediate
                  neighbors. We believe Software Defined Networking
                  (SDN) could revolutionize wide-area traffic
                  delivery, by offering direct control over
                  packet-processing rules that match on multiple
                  header fields and perform a variety of
                  actions. Internet exchange points (IXPs) are a
                  compelling place to start, given their central role
                  in interconnecting many networks and their growing
                  importance in bringing popular content closer to end
                  users. To realize a Software Defined IXP (an "SDX"),
                  we must create compelling applications, such as
                  "application-specific peering"---where two networks
                  peer only for (say) streaming video traffic. We also
                  need new programming abstractions that allow
                  participating networks to create and run these
                  applications and a runtime that both behaves
                  correctly when interacting with BGP and ensures that
                  applications do not interfere with each
                  other. Finally, we must ensure that the system
                  scales, both in rule-table size and computational
                  overhead. In this paper, we tackle these challenges
                  and demonstrate the flexibility and scalability of
                  our solutions through controlled and in-the-wild
                  experiments. Our experiments demonstrate that our
                  SDX implementation can implement representative
                  policies for hundreds of participants who advertise
                  full routing tables while achieving sub-second
                  convergence in response to configuration changes and
                  routing updates.},
  booktitle =    SIGCOMM,
  pages =        {551–562},
  numpages =     12,
  keywords =     {software defined networking (SDN), BGP, internet
                  exchange point (IXP)},
  location =     {Chicago, Illinois, USA},
  url =          {https://www.cs.princeton.edu/~jrex/papers/sdx14.pdf},
  comments =     {BGP is not a good tool for fine-grained control.
                  SDNs should be better.  Core abstraction: a virtual
                  switch for each autonomous system.  Programmed in
                  Pyretic.  Evaluated using Mininet.}
}

@inproceedings{Khurshid-ccr12,
  author =       {Khurshid, Ahmed and Zhou, Wenxuan and Caesar,
                  Matthew and Godfrey, P. Brighten},
  title =        {{Veriflow}: Verifying Network-Wide Invariants in Real
                  Time},
  year =         2013,
  url =          {https://doi.org/10.1145/2377677.2377766},
  abstract =     {Networks are complex and prone to bugs. Existing
                  tools that check configuration files and data-plane
                  state operate offline at timescales of seconds to
                  hours, and cannot detect or prevent bugs as they
                  arise. Is it possible to check network-wide
                  invariants in real time, as the network state
                  evolves? The key challenge here is to achieve
                  extremely low latency during the checks so that
                  network performance is not affected. In this paper,
                  we present a preliminary design, VeriFlow, which
                  suggests that this goal is achievable. VeriFlow is a
                  layer between a software-defined networking
                  controller and network devices that checks for
                  network-wide invariant violations dynamically as
                  each forwarding rule is inserted. Based on an
                  implementation using a Mininet OpenFlow network and
                  Route Views trace data, we find that VeriFlow can
                  perform rigorous checking within hundreds of
                  microseconds per rule insertion or deletion.},
  booktitle =    NSDI,
  month =        {April 2--5},
  location =     {Lombard, IL},
  keywords =     {forwarding, debugging, software-defined networking,
                  openflow, real time},
  url =          {https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final100.pdf},
  comments =     {Described version does not support rules that modify
                  packet headers.  Network is divided into equivalence
                  classes of packets and only changed classes are
                  reevaluated.  For each class it maintains the entire
                  forwarding graph.  A trie on header bits is used for
                  fast operations.  Some changes, such as link
                  failures, cause big modifications.  Intercepts OF
                  messages.}
}

@inproceedings{liu-socc11,
  author =       {Liu, Changbin and Loo, Boon Thau and Mao, Yun},
  title =        {Declarative Automated Cloud Resource Orchestration},
  year =         2011,
  url =          {https://doi.org/10.1145/2038916.2038942},
  abstract =     {As cloud computing becomes widely deployed, one of
                  the challenges faced involves the ability to
                  orchestrate a highly complex set of subsystems
                  (compute, storage, network resources) that span
                  large geographic areas serving diverse clients. To
                  ease this process, we present COPE (Cloud
                  Orchestration Policy Engine), a distributed platform
                  that allows cloud providers to perform declarative
                  automated cloud resource orchestration. In COPE,
                  cloud providers specify system-wide constraints and
                  goals using COPElog, a declarative policy language
                  geared towards specifying distributed constraint
                  optimizations. COPE takes policy specifications and
                  cloud system states as input and then optimizes
                  compute, storage and network resource allocations
                  within the cloud such that provider operational
                  objectives and customer SLAs can be better met. We
                  describe our proposed integration with a cloud
                  orchestration platform, and present initial
                  evaluation results that demonstrate the viability of
                  COPE using production traces from a large hosting
                  company in the US. We further discuss an
                  orchestration scenario that involves geographically
                  distributed data centers, and conclude with an
                  ongoing status of our work.},
  booktitle =    {ACM Symposium on Cloud Computing (SoCC)},
  numpages =     8,
  keywords =     {declarative queries, cloud computing, resource
                  orchestration, distributed optimizations},
  location =     {Cascais, Portugal},
  url =          {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.228.9857&rep=rep1&type=pdf},
  comments =     {"In COPE, we envision a distributed network of
                  controllers, each of which resides over a cloud
                  orchestration platform, coordinating resources
                  across multiple data centers."  Use a constraint
                  solver.  Distributed query engine among nodes.
                  COPElog is based on Datalog.  Extend Datalog with
                  constraints, variables, and goals.  Use aggregation
                  operations.  Constraints are like rules, but they
                  operate on the variables whose values need to be
                  computed.}
}


@inproceedings{ferguson-hotsdn12,
  author =       {Ferguson, Andrew D. and Guha, Arjun and Liang, Chen
                  and Fonseca, Rodrigo and Krishnamurthi, Shriram},
  title =        {Hierarchical Policies for Software Defined Networks},
  year =         2012,
  url =          {https://doi.org/10.1145/2342441.2342450},
  abstract =     {Hierarchical policies are useful in many contexts in
                  which resources are shared among multiple
                  entities. Such policies can easily express the
                  delegation of authority and the resolution of
                  conflicts, which arise naturally when
                  decision-making is decentralized. Conceptually, a
                  hierarchical policy could be used to manage network
                  resources, but commodity switches, which match
                  packets using flow tables, do not realize
                  hierarchies directly. This paper presents
                  Hierarchical Flow Tables (HFT), a framework for
                  specifying and realizing hierarchical policies in
                  software defined networks. HFT policies are
                  organized as trees, where each component of the tree
                  can independently determine the action to take on
                  each packet. When independent parts of the tree
                  arrive at conflicting decisions, HFT resolves
                  conflicts with user-defined conflict-resolution
                  operators, which exist at each node of the tree. We
                  present a compiler that realizes HFT policies on a
                  distributed network of OpenFlow switches, and prove
                  its correctness using the Coq proof assistant. We
                  then evaluate the use of HFT to improve performance
                  of networked applications.},
  booktitle =    HotSDN,
  pages =        {37–42},
  numpages =     6,
  keywords =     {hierarchical policies, participatory networking,
                  openflow, software defined networks},
  location =     {Helsinki, Finland},
  url =          {https://cs.brown.edu/~sk/Publications/Papers/Published/fglfk-hier-pol-sdn/paper.pdf},
  comments =     {Policy atom = match+action.  Tree=hierarchy of
                  policies.  Multiple conflict resolution operators
                  (parent-child, child-child, etc.)  Conflict
                  resolution operator +_D combines multiple actions;
                  must form a commutative monoid.  +_P handles
                  parent-child conflict.  They evaluate only 2
                  policies: Guaranteed Minimum Bandwidth (a number),
                  and admission control.  Some formal definitions of
                  correctness in terms of flow tables and the relation
                  between their contents and these operators; compiler
                  proved correctly in Coq.  An implementation of PANE
                  \cite{ferguson-hotice12}.  Not clear that this
                  algebra can be extended to other kinds of
                  operations.}
}

@INPROCEEDINGS{halle-noms12,
  author =       {Hall\'{e}, Sylvain and Ngoup\'{e}, \'{E}ric Lunaud
                  and Nijdam, Gaëtan and Cherkaoui, Omar and Valtchev,
                  Petko and Villemaire, Roger},
  booktitle =    {Network Operations and Management Symposium},
  title =        {{ValidMaker}: A tool for managing device
                  configurations using logical constraints},
  year =         2012,
  pages =        {1111-1118},
  doi =          {10.1109/NOMS.2012.6212037},
  abstract =     {Configuration Logic (CL) is a formal language that
                  allows a network engineer to express constraints in
                  terms of the actual parameters found in the
                  configuration of network devices. There exists an
                  efficient algorithm that can automatically check a
                  pool of devices for conformance to a set of CL
                  constraints; moreover, this algorithm can point to
                  the part of the configuration responsible for the
                  error when a constraint is violated. A CL validation
                  engine has been integrated into a network management
                  tool called ValidMaker. We show on a simple use case
                  scenario based on Virtual Local Area Networks how
                  representative formal constraints can be expressed
                  with CL and efficiently validated with ValidMaker.},
  url =          {https://www.labunix.uqam.ca/~villemaire_r/Articles/shelngnocpvrvManFI12.pdf},
  comments =     {Configuration expressed in Meta-CLI, and constraints
                  expressed in CL.  External device configurations are
                  translated to Meta-CLI.  A config is a tree where
                  each node is a key-value pair.  (Nodes = fields).
                  Formulas: Boolean conectives, paths, quantifiers.  A
                  path in a tree is of the form \vec{k} = \vec{v},
                  where v are either constants or variables.
                  Universal and existential quantifier.  Claim it's
                  more expressive than Prolog due to quantifiers. No
                  details about modeling switches as Meta-CLI.  When
                  validation fails you get a counterexample.}
}


@inproceedings{schlesinger-icfp14,
  author =       {Schlesinger, Cole and Greenberg, Michael and Walker,
                  David},
  title =        {Concurrent {NetCore}: From Policies to Pipelines},
  booktitle =    ICFP,
  year =         2014,
  location =     {Gothenburg, Sweden},
  pages =        {11--24},
  url =          {http://doi.acm.org/10.1145/2628136.2628157},
  abstract =     {In a Software-Defined Network (SDN), a central,
                  computationally powerful controller manages a set of
                  distributed, computationally simple switches. The
                  controller computes a policy describing how each
                  switch should route packets and populates
                  packet-processing tables on each switch with rules
                  to enact the routing policy. As network conditions
                  change, the controller continues to add and remove
                  rules from switches to adjust the policy as needed.
                  Recently, the SDN landscape has begun to change as
                  several proposals for new, reconfigurable switching
                  architectures, such as RMT [5] and FlexPipe [14]
                  have emerged. These platforms provide switch
                  programmers with many, flexible tables for storing
                  packet-processing rules, and they offer programmers
                  control over the packet fields that each table can
                  analyze and act on. These reconfigurable switch
                  architectures support a richer SDN model in which a
                  switch configuration phase precedes the rule
                  population phase [4]. In the configuration phase,
                  the controller sends the switch a graph describing
                  the layout and capabilities of the packet processing
                  tables it will require during the population
                  phase. Armed with this foreknowledge, the switch can
                  allocate its hardware (or software) resources more
                  efficiently.  We present a new, typed language,
                  called Concurrent NetCore, for specifying routing
                  policies and graphs of packet-processing
                  tables. Concurrent NetCore includes features for
                  specifying sequential, conditional and concurrent
                  control-flow between packet-processing tables. We
                  develop a fine-grained operational model for the
                  language and prove this model coincides with a
                  higher-level denotational model when programs are
                  well-typed. We also prove several additional
                  properties of well-typed programs, including strong
                  normalization and determinism. To illustrate the
                  utility of the language, we develop linguistic
                  models of both the RMT and FlexPipe architectures
                  and we give a multi-pass compilation algorithm that
                  translates graphs and routing policies to the RMT
                  model.},
  url =          {http://www.cs.princeton.edu/~dpw/papers/icfp2014sub_cnc.pdf},
  comments =     {Single-switch language.  Expresses both policies and
                  also switch architectures.  Concurrent composition:
                  act in parallel on the same packet.  Type system
                  controls interference.  Policies map a packet to a
                  set of packets.  Sequential composition, concurrent
                  composition, packet copy, field assignment.  Typed
                  table variables summarize all possible reads/writes
                  performed by a table+actions.  Language can model
                  switch pipeline.  Prove a strong normalization
                  theorem.  A nice strong normalization theorem for
                  the language.  Semantics seems to be specified only
                  for programs that have tables filled.  Compilation:
                  consolidate multicast (so that it's performed in a
                  single stage, using metadata).  Dynamic programming
                  for allocating memory to tables.}
}

@inproceedings{loo-sigmod06,
  author =       {Loo, Boon Thau and Condie, Tyson and Garofalakis,
                  Minos and Gay, David E. and Hellerstein, Joseph
                  M. and Maniatis, Petros and Ramakrishnan, Raghu and
                  Roscoe, Timothy and Stoica, Ion},
  title =        {Declarative Networking: Language, Execution and
                  Optimization},
  year =         2006,
  url =          {https://doi.org/10.1145/1142473.1142485},
  abstract =     {The networking and distributed systems communities
                  have recently explored a variety of new network
                  architectures, both for application-level overlay
                  networks, and as prototypes for a next-generation
                  Internet architecture. In this context, we have
                  investigated declarative networking: the use of a
                  distributed recursive query engine as a powerful
                  vehicle for accelerating innovation in network
                  architectures [23, 24, 33]. Declarative networking
                  represents a significant new application area for
                  database research on recursive query processing. In
                  this paper, we address fundamental database issues
                  in this domain. First, we motivate and formally
                  define the Network Datalog (NDlog) language for
                  declarative network specifications. Second, we
                  introduce and prove correct relaxed versions of the
                  traditional semi-na\"{\i}ve query evaluation
                  technique, to overcome fundamental problems of the
                  traditional technique in an asynchronous distributed
                  setting. Third, we consider the dynamics of network
                  state, and formalize the iheventual consistencyl. of
                  our programs even when bursts of updates can arrive
                  in the midst of query execution. Fourth, we present
                  a number of query optimization opportunities that
                  arise in the declarative networking context,
                  including applications of traditional techniques as
                  well as new optimizations. Last, we present
                  evaluation results of the above ideas implemented in
                  our P2 declarative networking system, running on 100
                  machines over the Emulab network testbed.},
  booktitle =    SIGMOD,
  pages =        {97–108},
  numpages =     12,
  keywords =     {recursive queries, declarative networks},
  location =     {Chicago, IL, USA},
  url =          {http://db.cs.berkeley.edu/papers/sigmod06-declar.pdf},
  comments =     {Formal specification of NDlog and proof of
                  properties.  Link relation is an input and is
                  special: reflects system topology, and communication
                  patterns.  Locally evaluatable rules have the same
                  location in all terms.  Link-restricted rules must
                  have locations at either endpoint of a link.  NDLog
                  is a subset of Datalog => same semantics.  They do
                  keep track of the number of derivation for
                  incremental evaluation.  P2 is a system implementing
                  this.  This is really a database paper.  Negation is
                  not supported at this time.}
}

@Misc{istio,
  title =        {{Istio}},
  howpublished = {https://github.com/istio/istio},
  year =         {Retrieved April 2021},
  abstract =     {An open platform to connect, manage, and secure
                  microservices.},
}

@inproceedings{lopes-nsdi15,
  author =       {Lopes, Nuno P. and Bj\o{}rner, Nikolaj and
                  Godefroid, Patrice and Jayaraman, Karthick and
                  Varghese, George},
  title =        {Checking Beliefs in Dynamic Networks},
  year =         2015,
  abstract =     {Network Verification is a form of model checking in
                  which a model of the network is checked for
                  properties stated using a specification
                  language. Existing network verification tools lack a
                  general specification language and hardcode the
                  network model. Hence they cannot, for example, model
                  policies at a high level of abstraction. Neither can
                  they model dynamic networks; even a simple packet
                  format change requires changes to
                  internals. Standard verification tools (e.g., model
                  checkers) have expressive specification and modeling
                  languages but do not scale to large header
                  spaces. We introduce Network Optimized Datalog (NoD)
                  as a tool for network verification in which both the
                  specification language and modeling languages are
                  Datalog. NoD can also scale to large to large header
                  spaces because of a new filter-project operator and
                  a symbolic header representation.As a consequence,
                  NoD allows checking for beliefs about network
                  reachability policies in dynamic networks. A belief
                  is a high-level invariant (e.g., "Internal
                  controllers cannot be accessed from the Internet")
                  that a network operator thinks is true. Beliefs may
                  not hold, but checking them can uncover bugs or
                  policy exceptions with little manual effort. Refuted
                  beliefs can be used as a basis for revised
                  beliefs. Further, in real networks, machines are
                  added and links fail; on a longer term, packet
                  formats and even forwarding behaviors can change,
                  enabled by OpenFlow and P4. NoD allows the analyst
                  to model such dynamic networks by adding new Datalog
                  rules.For a large Singapore data center with 820K
                  rules, NoD checks if any guest VM can access any
                  controller (the equivalent of 5K specific
                  reachability invariants) in 12 minutes. NoD checks
                  for loops in an experimental SWAN backbone network
                  with new headers in a fraction of a second. NoD
                  generalizes a specialized system, SecGuru, we
                  currently use in production to catch hundreds of
                  configuration bugs a year. NoD has been released as
                  part of the publicly available Z3 SMT solver.},
  booktitle =    NSDI,
  pages =        {499–512},
  numpages =     14,
  location =     {Oakland, CA},
  comments =     {The paper is mostly about specifying network
                  properties in datalog.  The interesting part of NoD
                  is some domain-specific optimization.  The most
                  important one is compressed table representation;
                  there are two different implementations, using BDDs
                  or using ternary bits and differences of cubes.
                  These can make possible representations of very
                  large tables.}
}

@InProceedings{ovn-incremental,
  author = 	 {Han Zhou},
  title = 	 {{OVN} Controller Incremental Processing},
  booktitle = {{Open vSwitch} 2018 Fall Conference},
  year = 	 2018,
  address = 	 {San Jose, California},
  note = 	 {\url{http://www.openvswitch.org/support/ovscon2018/}}}

@Misc{moats16,
  author = 	 {Ryan Moats},
  title = 	 {ovn-controller: Back out incremental processing},
  howpublished = {\url{https://github.com/openvswitch/ovs/commit/926c34fd7c2080543bf3ee63a4830e0dc5c4af12}},
  month = 	 {August},
  year = 	 2016}

@INPROCEEDINGS{6918985,
  author={Medved, Jan and Varga, Robert and Tkacik, Anton and Gray, Ken},
  booktitle={Proceeding of IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks 2014},
  title={OpenDaylight: Towards a Model-Driven SDN Controller architecture},
  year={2014},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/WoWMoM.2014.6918985}}
